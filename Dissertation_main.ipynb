{"metadata":{"colab":{"provenance":[],"toc_visible":true,"name":"Dissertation_main","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":72713,"databundleVersionId":7984788,"sourceType":"competition"},{"sourceId":8102095,"sourceType":"datasetVersion","datasetId":4767099},{"sourceId":8102129,"sourceType":"datasetVersion","datasetId":4765873},{"sourceId":8794455,"sourceType":"datasetVersion","datasetId":4766711}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/trduc97/siamese_semantic_similarity/blob/main/Dissertation_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"# Overview\nThis study goes into text mining using machine learning techniques, primarily focusing on deep learning. We aimed to accurately identify relevant pairing between presented document and search topics, a task with widespread application, via pairing Q&A directly, or coupled with a RAG system to improve responses quality from LLM, .... The project involved exploration and cleaning of the dataset, followed by tuning parameters and alternating different deep learning architeciture.\n\n# Method\nWe began with an analysis of the dataset to determine the cleaning process and understand the distribution of the binary classes to determin the right metrics.\n\nIn data splitting, we used a 85% training, 10% validation, and 5% testing split, ensuring we can have optimal sample for our training process. Given the high level of complexity and high dimensionality of the data we are working with, most of the deep neural models are run on a P100 GPU\n\n# Models\n\n1. Deep Neural Networks (DNNs): We then experimented with various DNN configurations, adjusting layers count and nodes count, along with different activation functions. And find that aligned with current believe, gelu work particularly well for textual task.\nWe developed several complex CNN architectures, employing Siamese architecture with different neural layers\n\n  - **Model 1**: traditional multi-layer Dense deep neural network with GLoVe embedding\n  - **Model 2**: RNN + GloVe embedding\n  - **Model 3**: GRU and Bidirectional GRU + GloVe embedding\n  - **Model 4**: LSTM and Bidirectional LSTM + GloVe embedding\n  - **Model 5**: LSTM + GloVe embedding + Siamese architecture (Paragraph<>Topic) + measure distance to determine similarity\n  - **Model 5.1**: Testing with Manthantan/Euclidean/Cosine distance\n  - **Model 6**: LSTM + BERT + Siamese architecture(Manhattan distance)\n\n  Other potential tests:\n    - **Model 7**: Using CNN in a Siamese architecture. While CNN is primarily applicable for images, it can also potentially find pattern in local pattern within the paragraph\n    - **Model 8**: Using BSSM model architecture as suggest in \"Bert-based Siamese Network for Semantic Similarity\"\n    https://iopscience.iop.org/article/10.1088/1742-6596/1684/1/012074/pdf\n\n\n\n","metadata":{"id":"L-M5vvd35HlN"}},{"cell_type":"markdown","source":"### 1. Data Setup","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"UJC2Wgw4pxTD"}},{"cell_type":"markdown","source":"tensorflow and keras require consistency, and pandas may behave drastically different with different version so we need to specify here\n","metadata":{"id":"NXlCkOer3UzI"}},{"cell_type":"code","source":"# @title\n!pip install keras==2.15.0\n!pip install tensorflow==2.15.0\n!pip install pandas==2.2.1\n#!pip install nltk\n#!pip install xgboost\n#!pip install gensim\n#!pip install bs4\n#!pip install pyarrow","metadata":{"id":"GUdv1xJzOrea","outputId":"5672bb8e-55c0-4bbd-eef8-a182efc83d36","execution":{"iopub.status.busy":"2024-06-26T14:12:45.890941Z","iopub.execute_input":"2024-06-26T14:12:45.891644Z","iopub.status.idle":"2024-06-26T14:13:27.404471Z","shell.execute_reply.started":"2024-06-26T14:12:45.891612Z","shell.execute_reply":"2024-06-26T14:13:27.403334Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting keras==2.15.0\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\nRequirement already satisfied: tensorflow==2.15.0 in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.59.3)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.15.0) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\nRequirement already satisfied: pandas==2.2.1 in /opt/conda/lib/python3.10/site-packages (2.2.1)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.1) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.1) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.1) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.1) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# @title\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Libraries for text preprocessing\nfrom bs4 import BeautifulSoup\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport string\nimport re\n\nfrom scipy.sparse import hstack\n\n# Download NLTK resources\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\n\n\n# Libraries for vectorization\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Libraries for ML\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight, shuffle\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, accuracy_score,precision_score,recall_score, f1_score,precision_recall_curve\n\nimport random\nimport warnings\nwarnings.simplefilter(action='ignore')","metadata":{"id":"ysxundyZOtj1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1f3f153c-481b-46cc-bb7b-4b2ce3c1d64a","execution":{"iopub.status.busy":"2024-06-26T14:13:27.406493Z","iopub.execute_input":"2024-06-26T14:13:27.406845Z","iopub.status.idle":"2024-06-26T14:13:40.538629Z","shell.execute_reply.started":"2024-06-26T14:13:27.406812Z","shell.execute_reply":"2024-06-26T14:13:40.537652Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-26 14:13:29.356629: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-26 14:13:29.356736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-26 14:13:29.469997: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In order to ensure results reproducibility, we set the random seeds for numpy, tensorflow and the python random package to a constant value of 42. We then made use of the python pandas library to read the data into memory:","metadata":{"id":"KkkVONR3Mvnj"}},{"cell_type":"code","source":"# @title\n# Set random seeds for reproducibility\nrandom.seed(42)\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"id":"Y6dydZa04Q-b","execution":{"iopub.status.busy":"2024-06-26T14:13:40.539676Z","iopub.execute_input":"2024-06-26T14:13:40.540229Z","iopub.status.idle":"2024-06-26T14:13:40.550180Z","shell.execute_reply.started":"2024-06-26T14:13:40.540202Z","shell.execute_reply":"2024-06-26T14:13:40.548975Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# @title\n#Storing the output path of the .csv files to be downloaded\ntraining_df, testing_df= '/kaggle/input/cs985-987-relevance-prediction-2024/relevance_train.parquet', '/kaggle/input/cs985-987-relevance-prediction-2024/relevance_test.parquet'\n\n#Reading the .parquet files into a DataFrame\ntraining_df, testing_df=pd.read_parquet(training_df), pd.read_parquet(testing_df)\n\ntraining_df.head()","metadata":{"id":"pNHGHXdWPdjk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4fb6e44f-0cd2-4666-f61c-75223ab76b21","execution":{"iopub.status.busy":"2024-06-26T14:13:40.553344Z","iopub.execute_input":"2024-06-26T14:13:40.553715Z","iopub.status.idle":"2024-06-26T14:13:42.705513Z","shell.execute_reply.started":"2024-06-26T14:13:40.553670Z","shell.execute_reply":"2024-06-26T14:13:42.704406Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                 doc_id  judgement           author  \\\n0      004c6120d0aa69da29cc045da0562168          0   Terrence McCoy   \n1      005a1f0c2064487a7f15443b2a5f349a          0    Brian McNoldy   \n2  00722094-2935-11e2-b4e0-346287b7e56c          0  Editorial Board   \n3  007d2856-7cc4-11e4-84d4-7c896b90abdc          0   Adam Bernstein   \n4  009aafb6-0283-11e6-8bb1-f124a43f84dc          0             None   \n\n                                                body              byline  \\\n0  <p>More than 60 years ago, a fair-skinned Iris...   By Terrence McCoy   \n1  <p>Hurricane Fred, which formed over the weeke...    By Brian McNoldy   \n2  <p>EIGHT YEARS AGO this month, an inspiring mo...  By Editorial Board   \n3  <p>Mary Burke Washington, an economist who was...   By Adam Bernstein   \n4  <p>When Treasury Secretary Jack Lew <a href=\"h...                None   \n\n                                               title  topic_id  \\\n0  Report on Irish baby homes documents use of in...       321   \n1  Hurricane Fred is a fountain of ‘firsts’ in th...       321   \n2                 Ukraine slides away from democracy       321   \n3  Mary Washington, government official and widow...       321   \n4                  Will women be shortchanged again?       321   \n\n                                         description  \\\n0  Pertinent documents will reflect the fact that...   \n1  Pertinent documents will reflect the fact that...   \n2  Pertinent documents will reflect the fact that...   \n3  Pertinent documents will reflect the fact that...   \n4  Pertinent documents will reflect the fact that...   \n\n                                           narrative           topic_title  \n0  Pertinent documents relating to this issue wil...  Women in Parliaments  \n1  Pertinent documents relating to this issue wil...  Women in Parliaments  \n2  Pertinent documents relating to this issue wil...  Women in Parliaments  \n3  Pertinent documents relating to this issue wil...  Women in Parliaments  \n4  Pertinent documents relating to this issue wil...  Women in Parliaments  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doc_id</th>\n      <th>judgement</th>\n      <th>author</th>\n      <th>body</th>\n      <th>byline</th>\n      <th>title</th>\n      <th>topic_id</th>\n      <th>description</th>\n      <th>narrative</th>\n      <th>topic_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004c6120d0aa69da29cc045da0562168</td>\n      <td>0</td>\n      <td>Terrence McCoy</td>\n      <td>&lt;p&gt;More than 60 years ago, a fair-skinned Iris...</td>\n      <td>By Terrence McCoy</td>\n      <td>Report on Irish baby homes documents use of in...</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005a1f0c2064487a7f15443b2a5f349a</td>\n      <td>0</td>\n      <td>Brian McNoldy</td>\n      <td>&lt;p&gt;Hurricane Fred, which formed over the weeke...</td>\n      <td>By Brian McNoldy</td>\n      <td>Hurricane Fred is a fountain of ‘firsts’ in th...</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00722094-2935-11e2-b4e0-346287b7e56c</td>\n      <td>0</td>\n      <td>Editorial Board</td>\n      <td>&lt;p&gt;EIGHT YEARS AGO this month, an inspiring mo...</td>\n      <td>By Editorial Board</td>\n      <td>Ukraine slides away from democracy</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>007d2856-7cc4-11e4-84d4-7c896b90abdc</td>\n      <td>0</td>\n      <td>Adam Bernstein</td>\n      <td>&lt;p&gt;Mary Burke Washington, an economist who was...</td>\n      <td>By Adam Bernstein</td>\n      <td>Mary Washington, government official and widow...</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>009aafb6-0283-11e6-8bb1-f124a43f84dc</td>\n      <td>0</td>\n      <td>None</td>\n      <td>&lt;p&gt;When Treasury Secretary Jack Lew &lt;a href=\"h...</td>\n      <td>None</td>\n      <td>Will women be shortchanged again?</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2. Exploratory Data Analysis","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"6WNZsRBtpxTH"}},{"cell_type":"markdown","source":"The basic format of the dataset we are working with including 2 main parts, the 'document' that we need to search through, (made up of columns 'title' and 'body'), and the 'topic' that we are interested in retrieving, (made up of columns 'description and 'narrative').   \nWe are working with an imbalance dataset, with only 1/9 documents are relevant to us","metadata":{"id":"pSTuNiyFpxTH"}},{"cell_type":"code","source":"# @title\n# Check target distribution\njudgement_counts = training_df['judgement'].value_counts()\ntotal = judgement_counts.sum()\npercentages = (judgement_counts / total) * 100\nprint(percentages)","metadata":{"id":"VlJUIC8npxTH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"817cd441-77e2-4bd8-abe3-a22889ed0238","execution":{"iopub.status.busy":"2024-06-26T14:13:42.706758Z","iopub.execute_input":"2024-06-26T14:13:42.707138Z","iopub.status.idle":"2024-06-26T14:13:42.718970Z","shell.execute_reply.started":"2024-06-26T14:13:42.707109Z","shell.execute_reply":"2024-06-26T14:13:42.717911Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"judgement\n0    84.284847\n1    15.715153\nName: count, dtype: float64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For relevance judgement, we consider the informative features about the article, and the user's query terms. Specifically we used the body and title features as representations of the article, and the topic_title and description features as representations of the user's query.","metadata":{"id":"_miF-ry6f8N-"}},{"cell_type":"code","source":"# @title\n# visualization of the first 5 records\ntraining_df.head()","metadata":{"id":"HJbrc0Xvg5rS","colab":{"base_uri":"https://localhost:8080/","height":466},"outputId":"121e23e5-730e-454d-f523-5664c61ab485","execution":{"iopub.status.busy":"2024-06-26T14:13:42.720428Z","iopub.execute_input":"2024-06-26T14:13:42.721585Z","iopub.status.idle":"2024-06-26T14:13:42.801168Z","shell.execute_reply.started":"2024-06-26T14:13:42.721538Z","shell.execute_reply":"2024-06-26T14:13:42.800279Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                 doc_id  judgement           author  \\\n0      004c6120d0aa69da29cc045da0562168          0   Terrence McCoy   \n1      005a1f0c2064487a7f15443b2a5f349a          0    Brian McNoldy   \n2  00722094-2935-11e2-b4e0-346287b7e56c          0  Editorial Board   \n3  007d2856-7cc4-11e4-84d4-7c896b90abdc          0   Adam Bernstein   \n4  009aafb6-0283-11e6-8bb1-f124a43f84dc          0             None   \n\n                                                body              byline  \\\n0  <p>More than 60 years ago, a fair-skinned Iris...   By Terrence McCoy   \n1  <p>Hurricane Fred, which formed over the weeke...    By Brian McNoldy   \n2  <p>EIGHT YEARS AGO this month, an inspiring mo...  By Editorial Board   \n3  <p>Mary Burke Washington, an economist who was...   By Adam Bernstein   \n4  <p>When Treasury Secretary Jack Lew <a href=\"h...                None   \n\n                                               title  topic_id  \\\n0  Report on Irish baby homes documents use of in...       321   \n1  Hurricane Fred is a fountain of ‘firsts’ in th...       321   \n2                 Ukraine slides away from democracy       321   \n3  Mary Washington, government official and widow...       321   \n4                  Will women be shortchanged again?       321   \n\n                                         description  \\\n0  Pertinent documents will reflect the fact that...   \n1  Pertinent documents will reflect the fact that...   \n2  Pertinent documents will reflect the fact that...   \n3  Pertinent documents will reflect the fact that...   \n4  Pertinent documents will reflect the fact that...   \n\n                                           narrative           topic_title  \n0  Pertinent documents relating to this issue wil...  Women in Parliaments  \n1  Pertinent documents relating to this issue wil...  Women in Parliaments  \n2  Pertinent documents relating to this issue wil...  Women in Parliaments  \n3  Pertinent documents relating to this issue wil...  Women in Parliaments  \n4  Pertinent documents relating to this issue wil...  Women in Parliaments  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doc_id</th>\n      <th>judgement</th>\n      <th>author</th>\n      <th>body</th>\n      <th>byline</th>\n      <th>title</th>\n      <th>topic_id</th>\n      <th>description</th>\n      <th>narrative</th>\n      <th>topic_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004c6120d0aa69da29cc045da0562168</td>\n      <td>0</td>\n      <td>Terrence McCoy</td>\n      <td>&lt;p&gt;More than 60 years ago, a fair-skinned Iris...</td>\n      <td>By Terrence McCoy</td>\n      <td>Report on Irish baby homes documents use of in...</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005a1f0c2064487a7f15443b2a5f349a</td>\n      <td>0</td>\n      <td>Brian McNoldy</td>\n      <td>&lt;p&gt;Hurricane Fred, which formed over the weeke...</td>\n      <td>By Brian McNoldy</td>\n      <td>Hurricane Fred is a fountain of ‘firsts’ in th...</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00722094-2935-11e2-b4e0-346287b7e56c</td>\n      <td>0</td>\n      <td>Editorial Board</td>\n      <td>&lt;p&gt;EIGHT YEARS AGO this month, an inspiring mo...</td>\n      <td>By Editorial Board</td>\n      <td>Ukraine slides away from democracy</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>007d2856-7cc4-11e4-84d4-7c896b90abdc</td>\n      <td>0</td>\n      <td>Adam Bernstein</td>\n      <td>&lt;p&gt;Mary Burke Washington, an economist who was...</td>\n      <td>By Adam Bernstein</td>\n      <td>Mary Washington, government official and widow...</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>009aafb6-0283-11e6-8bb1-f124a43f84dc</td>\n      <td>0</td>\n      <td>None</td>\n      <td>&lt;p&gt;When Treasury Secretary Jack Lew &lt;a href=\"h...</td>\n      <td>None</td>\n      <td>Will women be shortchanged again?</td>\n      <td>321</td>\n      <td>Pertinent documents will reflect the fact that...</td>\n      <td>Pertinent documents relating to this issue wil...</td>\n      <td>Women in Parliaments</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# @title\n# create a copy of the original dataset\ntraining_df2 = training_df.copy()\n# extract the useful representative features\ntraining_df2 = training_df2.reindex(columns=['judgement','body','description','title','narrative'])","metadata":{"id":"kEi68YSigprK","execution":{"iopub.status.busy":"2024-06-26T14:13:42.802532Z","iopub.execute_input":"2024-06-26T14:13:42.803423Z","iopub.status.idle":"2024-06-26T14:13:42.822311Z","shell.execute_reply.started":"2024-06-26T14:13:42.803394Z","shell.execute_reply":"2024-06-26T14:13:42.819411Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"From the exploratory data analysis we can see that the training dataset has a imbalance dstribution for the two class of 'judgement'. The percentage of the '0' values is approximate 84.28% and the percentage for the '1' is around 15.71%. The 0 reflects the irrelevant pairing and 1 is relevant pairing.\nThe imbalance shows that most articles return are irrelevant to the queries. To consider the relevance judgement, we will use four key features. The 'body' and the 'title' is the actual content and title of the article. The 'description' and 'narative' is the details of the queries. To get the clearer picture we have shown the individual entries for the above important features. Finally we have created a copy of the dataset and reindexed the most important columns for assessing the article relevance.","metadata":{"id":"fFjdXjHm7gEv"}},{"cell_type":"markdown","source":"# 2.Text preprocessing","metadata":{"id":"-pipUaj6pxTI"}},{"cell_type":"code","source":"# @title\n# Check missing values\ntraining_df2.isna().sum()","metadata":{"id":"f5zT4sLSCaAR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"95ec8eb8-ea95-4eae-bf62-077ffd8a6070","execution":{"iopub.status.busy":"2024-06-26T14:13:42.823860Z","iopub.execute_input":"2024-06-26T14:13:42.825528Z","iopub.status.idle":"2024-06-26T14:13:42.844164Z","shell.execute_reply.started":"2024-06-26T14:13:42.825473Z","shell.execute_reply":"2024-06-26T14:13:42.843156Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"judgement       0\nbody           69\ndescription     0\ntitle           0\nnarrative       0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# @title\n# We will drop the articles with null body\ntraining_df2.dropna(inplace=True) # intuitively, without knowing the body, it is almost impossible to find out if it is going to be a match\n# Preprocessing function\ndef preprocess_text(text):\n  #Removing links and tags\n  soup=BeautifulSoup(text, 'html.parser')\n  text=soup.get_text()\n  text=text.lower()\n\n  #Removing unncessary backslash\n  text=re.sub(r'[^\\w\\s()/\\\\]', ' ',text)\n\n  #Removing next line tags\n  text=text.replace('\\\\n', '')\n\n  #Removing unncessary 'xa0' string\n  text=text.replace('\\xa0', ' ')\n\n  #Tokenizing\n  tokens=word_tokenize(text)\n\n  #Removing punctuation\n  tokens=[word for word in tokens if word not in string.punctuation]\n\n  #Removing stop-words\n  stop_words=set(stopwords.words('english'))\n  tokens=[word for word in tokens if word.lower() not in stop_words]\n\n  #Lemantizing\n  lemmatizer=WordNetLemmatizer()\n  tokens=[lemmatizer.lemmatize(word) for word in tokens]\n  sentence=' '.join(tokens)\n\n  return sentence","metadata":{"id":"2raa9peg118c","execution":{"iopub.status.busy":"2024-06-26T14:13:42.845400Z","iopub.execute_input":"2024-06-26T14:13:42.845863Z","iopub.status.idle":"2024-06-26T14:13:42.872374Z","shell.execute_reply.started":"2024-06-26T14:13:42.845838Z","shell.execute_reply":"2024-06-26T14:13:42.871486Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Often the file from nltk does not automatically unzip after being download so we have a code to explicityly perform this base on the default path on kaggle and colab","metadata":{"id":"9Pr6qLxjpxTJ"}},{"cell_type":"code","source":"# @title\nimport os\nimport zipfile\n\n# Define the directories to try\ndirectories_to_try = [\"/root/nltk_data\", \"/usr/share/nltk_data\"]\n\n# Try each directory until successful\nfound = False\nfor directory in directories_to_try:\n    try:\n        # Check if the directory exists\n        if os.path.exists(directory):\n            # Define the path to the WordNet zip file\n            wordnet_zip_path = os.path.join(directory, \"corpora\", \"wordnet.zip\")\n            # Check if the WordNet zip file exists\n            if os.path.exists(wordnet_zip_path):\n                # Unzip WordNet data\n                with zipfile.ZipFile(wordnet_zip_path, 'r') as zip_ref:\n                    zip_ref.extractall(os.path.join(directory, \"corpora\"))\n                found = True\n                break\n    except Exception as e:\n        print(f\"Error: {e}\")\n\nif not found:\n    print(\"WordNet data not found in either directory.\")","metadata":{"id":"uNk4aLGJpxTJ","execution":{"iopub.status.busy":"2024-06-26T14:13:42.876264Z","iopub.execute_input":"2024-06-26T14:13:42.876652Z","iopub.status.idle":"2024-06-26T14:13:43.136264Z","shell.execute_reply.started":"2024-06-26T14:13:42.876619Z","shell.execute_reply":"2024-06-26T14:13:43.135039Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"testing_df.isna().sum()\ntesting_df.fillna('', inplace=True) # to retain the shape of the submission we choose to keep the empty values in the testing","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:23:22.951858Z","iopub.execute_input":"2024-06-26T14:23:22.952740Z","iopub.status.idle":"2024-06-26T14:23:22.969054Z","shell.execute_reply.started":"2024-06-26T14:23:22.952706Z","shell.execute_reply":"2024-06-26T14:23:22.968146Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# @title\n# columns to clean in training\ncolumns_to_clean = [\"title\", \"body\",\"description\",\"narrative\" ]\n\n# applying cleaning function to each column\ntraining_df2 = training_df2[columns_to_clean].map(preprocess_text)\ntesting_df = testing_df[columns_to_clean].map(preprocess_text)\n\n# we re-attached the judgement column back to training_df2\ntraining_df2['judgement'] = training_df['judgement']","metadata":{"id":"txion_lzpxTJ","execution":{"iopub.status.busy":"2024-06-26T14:23:36.415539Z","iopub.execute_input":"2024-06-26T14:23:36.416408Z","iopub.status.idle":"2024-06-26T14:28:24.158207Z","shell.execute_reply.started":"2024-06-26T14:23:36.416375Z","shell.execute_reply":"2024-06-26T14:28:24.157288Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# @title\nprint(training_df2['body'][0])\nprint(training_df2['description'][0])\nprint(training_df2['title'][0])\nprint(training_df2['narrative'][0])","metadata":{"id":"_Qgmed1ADgbF","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"d19510ce-6d45-4ab5-e044-b5de3d87e36f","execution":{"iopub.status.busy":"2024-06-26T14:28:24.159876Z","iopub.execute_input":"2024-06-26T14:28:24.160229Z","iopub.status.idle":"2024-06-26T14:28:24.166979Z","shell.execute_reply.started":"2024-06-26T14:28:24.160204Z","shell.execute_reply":"2024-06-26T14:28:24.165992Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"60 year ago fair skinned irish politician named sally mulready born home unwed mother called st patrick sat road named navan dublin mulready one four sibling born brother john never made st pat like hundred baby born irish home fallen woman john died 1947 two month old inanition death record read according rte news failure thrive rte news said record carried mystery john reason buried 1950 three year death oddity first discarded clerical error john record designation anatomical study infant remains fact given researcher trinity college dublin used medical research though unclear whether mother given consent mulready eventually tracked burial plot explained irish time found marked stick number imagine happening child young baby died well family family influence happen baby beside john according recent irish government report confirming augmenting earlier report rte investigation called anatomy scandal report preliminary review designed set framework full formal investigation ordered irish parliament wake another story one historian claim hundred baby may buried beside home unwed mother tuam government said parliament established inquiry belief latest shameful episode ireland painful social history must fully accurately documented order comprehensive account institution available record show report said year 1940 1965 474 unclaimed infant remains transferred anatomy department ireland cited old record anatomical committee irish medical school purpose study anatomy study structure human body baby undetermined number came home mother baby home amongst institution remains transferred report said confirming earlier irish news account medical research others may come hospital practice took place mid 1960 issue broader home appears part wider practice time regarding use anatomical remains report said report prepared irish department child youth affair found baby body studied university college dublin trinity college dublin royal college surgeon dublin national university ireland galway act enabled unusual law called anatomy act 1832 act designed regulate school anatomy provide legal supply cadaver medical research education reaction public fear illegal trade corp report said investigation also discovered least 123 child home unwed mother used testing vaccine manufactured company called wellcome laboratory merging glaxo became glaxo wellcome test provided fodder two published article peer reviewed journal report said unclear often researcher obtained consent fresh finding rekindled scandal absorbed international news day last month touched one darker chapter ireland history unwed pregnant woman filtered score similar home subject stigmatization society still governed strict catholic dogma ten thousand baby born home many later adopted others however died home shocking level infant mortality year ireland general infant mortality rate general population 6 percent called illegitimate birth rate much higher according 1939 annual inspector report highlighted government investigation 47 percent baby one home cork died another 23 percent home tuam center recent news report infant mortality rate lower others 15 percent chance survival illegitimate infant born slum placed foster mother slum day birth greater infant born one special home unmarried mother 1939 report unearthed authority said many child experienced fate tuam detailed irish government report nearly one fourth died something called debility birth another 120 baby expired respiratory disease congenital syphilis claimed 12 seven killed ear infection remains unclear exactly nearly 800 baby body buried interview washington post last month historian catherine corless affirmed belief baby unmarked mass grave near tuam home government report lent support assertion said police inquiry confirm report skeletal remains discovered underground structure near site mid 1970s adding police continuing investigation\npertinent document reflect fact woman continue poorly represented parliament across world gap political power sex wide particularly third world\nreport irish baby home document use infant med school cadaver vaccine testing\npertinent document relating issue discus lack representation woman country mandate inclusion certain percentage woman legislature decrease female representation legislature country representation woman\n","output_type":"stream"}]},{"cell_type":"code","source":"# @title\ndef grouping_col(data):\n  data['document'] = data['title'] + ' ' + data['body']\n  data['topic'] = data['description'] + ' ' + data['narrative']\n  data['concatenated_text'] = data['document'] + '[SEP]' + data['topic'] # [SEP] are default denominator for splitting text, will be relevant when apply on BERT\n  return data\n\ntraining_df2 = grouping_col(training_df2)\ntesting_df = grouping_col(testing_df)\ndf_combine = training_df2.copy()","metadata":{"id":"gtTrGfO0pxTK","execution":{"iopub.status.busy":"2024-06-26T14:28:24.168221Z","iopub.execute_input":"2024-06-26T14:28:24.168558Z","iopub.status.idle":"2024-06-26T14:28:24.403852Z","shell.execute_reply.started":"2024-06-26T14:28:24.168531Z","shell.execute_reply":"2024-06-26T14:28:24.402881Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"training_df2.to_csv('cleaned_training_df2.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:33:36.162953Z","iopub.execute_input":"2024-06-26T14:33:36.163608Z","iopub.status.idle":"2024-06-26T14:33:45.936059Z","shell.execute_reply.started":"2024-06-26T14:33:36.163577Z","shell.execute_reply":"2024-06-26T14:33:45.935273Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"training_df2.to_parquet('cleaned_training_df2.parquet.gzip',\n              compression='gzip')  \ntraining_df2 = pd.read_parquet('/kaggle/working/cleaned_training_df2.parquet.gzip')  ","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:36:07.890647Z","iopub.execute_input":"2024-06-26T14:36:07.891469Z","iopub.status.idle":"2024-06-26T14:36:26.400408Z","shell.execute_reply.started":"2024-06-26T14:36:07.891434Z","shell.execute_reply":"2024-06-26T14:36:26.399439Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                                   title  \\\n0      report irish baby home document use infant med...   \n1           hurricane fred fountain first atlantic ocean   \n2                           ukraine slide away democracy   \n3      mary washington government official widow form...   \n4                                     woman shortchanged   \n...                                                  ...   \n26227  daily 202 liberal hypocrisy abounds electoral ...   \n26228  transportation dept get strict rule train carr...   \n26229  joni ernst iowa campaign make quick work war w...   \n26230          real reason american love bacon breakfast   \n26231                    ear favorite corn recipe summer   \n\n                                                    body  \\\n0      60 year ago fair skinned irish politician name...   \n1      hurricane fred formed weekend far eastern atla...   \n2      eight year ago month inspiring movement took h...   \n3      mary burke washington economist ranking offici...   \n4      treasury secretary jack lew announced last jun...   \n...                                                  ...   \n26227  breanne deppischthe big idea ti season hypocri...   \n26228  almost two year runaway tank car train erupted...   \n26229  urbandale iowathe machine shed restaurant wait...   \n26230  secret history bacon almost nobody know tell n...   \n26231  may noticed focusing corn week roberto ferdman...   \n\n                                             description  \\\n0      pertinent document reflect fact woman continue...   \n1      pertinent document reflect fact woman continue...   \n2      pertinent document reflect fact woman continue...   \n3      pertinent document reflect fact woman continue...   \n4      pertinent document reflect fact woman continue...   \n...                                                  ...   \n26227  diversion u corn crop ethanol fuel increase fo...   \n26228  diversion u corn crop ethanol fuel increase fo...   \n26229  diversion u corn crop ethanol fuel increase fo...   \n26230  diversion u corn crop ethanol fuel increase fo...   \n26231  diversion u corn crop ethanol fuel increase fo...   \n\n                                               narrative  judgement  \\\n0      pertinent document relating issue discus lack ...          0   \n1      pertinent document relating issue discus lack ...          0   \n2      pertinent document relating issue discus lack ...          0   \n3      pertinent document relating issue discus lack ...          0   \n4      pertinent document relating issue discus lack ...          0   \n...                                                  ...        ...   \n26227  identify document discus impact growing corn i...          0   \n26228  identify document discus impact growing corn i...          0   \n26229  identify document discus impact growing corn i...          0   \n26230  identify document discus impact growing corn i...          0   \n26231  identify document discus impact growing corn i...          0   \n\n                                                document  \\\n0      report irish baby home document use infant med...   \n1      hurricane fred fountain first atlantic ocean h...   \n2      ukraine slide away democracy eight year ago mo...   \n3      mary washington government official widow form...   \n4      woman shortchanged treasury secretary jack lew...   \n...                                                  ...   \n26227  daily 202 liberal hypocrisy abounds electoral ...   \n26228  transportation dept get strict rule train carr...   \n26229  joni ernst iowa campaign make quick work war w...   \n26230  real reason american love bacon breakfast secr...   \n26231  ear favorite corn recipe summer may noticed fo...   \n\n                                                   topic  \\\n0      pertinent document reflect fact woman continue...   \n1      pertinent document reflect fact woman continue...   \n2      pertinent document reflect fact woman continue...   \n3      pertinent document reflect fact woman continue...   \n4      pertinent document reflect fact woman continue...   \n...                                                  ...   \n26227  diversion u corn crop ethanol fuel increase fo...   \n26228  diversion u corn crop ethanol fuel increase fo...   \n26229  diversion u corn crop ethanol fuel increase fo...   \n26230  diversion u corn crop ethanol fuel increase fo...   \n26231  diversion u corn crop ethanol fuel increase fo...   \n\n                                       concatenated_text  \n0      report irish baby home document use infant med...  \n1      hurricane fred fountain first atlantic ocean h...  \n2      ukraine slide away democracy eight year ago mo...  \n3      mary washington government official widow form...  \n4      woman shortchanged treasury secretary jack lew...  \n...                                                  ...  \n26227  daily 202 liberal hypocrisy abounds electoral ...  \n26228  transportation dept get strict rule train carr...  \n26229  joni ernst iowa campaign make quick work war w...  \n26230  real reason american love bacon breakfast secr...  \n26231  ear favorite corn recipe summer may noticed fo...  \n\n[19689 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>body</th>\n      <th>description</th>\n      <th>narrative</th>\n      <th>judgement</th>\n      <th>document</th>\n      <th>topic</th>\n      <th>concatenated_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>report irish baby home document use infant med...</td>\n      <td>60 year ago fair skinned irish politician name...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>pertinent document relating issue discus lack ...</td>\n      <td>0</td>\n      <td>report irish baby home document use infant med...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>report irish baby home document use infant med...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hurricane fred fountain first atlantic ocean</td>\n      <td>hurricane fred formed weekend far eastern atla...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>pertinent document relating issue discus lack ...</td>\n      <td>0</td>\n      <td>hurricane fred fountain first atlantic ocean h...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>hurricane fred fountain first atlantic ocean h...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ukraine slide away democracy</td>\n      <td>eight year ago month inspiring movement took h...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>pertinent document relating issue discus lack ...</td>\n      <td>0</td>\n      <td>ukraine slide away democracy eight year ago mo...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>ukraine slide away democracy eight year ago mo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mary washington government official widow form...</td>\n      <td>mary burke washington economist ranking offici...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>pertinent document relating issue discus lack ...</td>\n      <td>0</td>\n      <td>mary washington government official widow form...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>mary washington government official widow form...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>woman shortchanged</td>\n      <td>treasury secretary jack lew announced last jun...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>pertinent document relating issue discus lack ...</td>\n      <td>0</td>\n      <td>woman shortchanged treasury secretary jack lew...</td>\n      <td>pertinent document reflect fact woman continue...</td>\n      <td>woman shortchanged treasury secretary jack lew...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26227</th>\n      <td>daily 202 liberal hypocrisy abounds electoral ...</td>\n      <td>breanne deppischthe big idea ti season hypocri...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>identify document discus impact growing corn i...</td>\n      <td>0</td>\n      <td>daily 202 liberal hypocrisy abounds electoral ...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>daily 202 liberal hypocrisy abounds electoral ...</td>\n    </tr>\n    <tr>\n      <th>26228</th>\n      <td>transportation dept get strict rule train carr...</td>\n      <td>almost two year runaway tank car train erupted...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>identify document discus impact growing corn i...</td>\n      <td>0</td>\n      <td>transportation dept get strict rule train carr...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>transportation dept get strict rule train carr...</td>\n    </tr>\n    <tr>\n      <th>26229</th>\n      <td>joni ernst iowa campaign make quick work war w...</td>\n      <td>urbandale iowathe machine shed restaurant wait...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>identify document discus impact growing corn i...</td>\n      <td>0</td>\n      <td>joni ernst iowa campaign make quick work war w...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>joni ernst iowa campaign make quick work war w...</td>\n    </tr>\n    <tr>\n      <th>26230</th>\n      <td>real reason american love bacon breakfast</td>\n      <td>secret history bacon almost nobody know tell n...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>identify document discus impact growing corn i...</td>\n      <td>0</td>\n      <td>real reason american love bacon breakfast secr...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>real reason american love bacon breakfast secr...</td>\n    </tr>\n    <tr>\n      <th>26231</th>\n      <td>ear favorite corn recipe summer</td>\n      <td>may noticed focusing corn week roberto ferdman...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>identify document discus impact growing corn i...</td>\n      <td>0</td>\n      <td>ear favorite corn recipe summer may noticed fo...</td>\n      <td>diversion u corn crop ethanol fuel increase fo...</td>\n      <td>ear favorite corn recipe summer may noticed fo...</td>\n    </tr>\n  </tbody>\n</table>\n<p>19689 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3.Neural Network with GloVe embedding","metadata":{"id":"qReENfjYBGDW"}},{"cell_type":"markdown","source":"In general, the problem of matching a whole document with a provided topics can be attritube to the broader topics of textual similarity, or sentence similarity, so below we will explore severall approach that incorporated ideas within representation models, interaction models and pre-trained models.","metadata":{"id":"hThMLrVaV54L"}},{"cell_type":"markdown","source":"## 3.1. Importing libraries","metadata":{"id":"OQ9B7LJcFQgW"}},{"cell_type":"code","source":"# @title\nimport pickle\nfrom sklearn.metrics import roc_auc_score\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom tensorflow.keras.layers import GlobalMaxPool2D, GlobalAvgPool2D, Multiply, Subtract, Add, Activation, MaxPool2D, Concatenate,Reshape, Conv2D, MaxPooling2D, Dropout, Input, Embedding, Bidirectional, LSTM, Dense, Lambda, GlobalAveragePooling1D, Reshape, GRU, Flatten, Dropout, Embedding\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras.activations import gelu\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nimport zipfile\nimport os\n# Checking for GPU\nlen(tf.config.list_physical_devices('GPU'))\n\n# Setting epoch_count = 1 just to let the file run as demo, we have saved the trained models in a separated folder and will be using this to review\nbatch_size=256\nepoch_count=15\nactivation_func=gelu","metadata":{"id":"lgKIUnDJGVgd","outputId":"33a8e1e0-abaa-4a9a-8946-bfda9339c44a","execution":{"iopub.status.busy":"2024-06-26T14:55:21.747222Z","iopub.execute_input":"2024-06-26T14:55:21.747903Z","iopub.status.idle":"2024-06-26T14:55:21.926296Z","shell.execute_reply.started":"2024-06-26T14:55:21.747874Z","shell.execute_reply":"2024-06-26T14:55:21.925305Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"In this part, along with the typical singple input model, we will also be consider a **Siamese** model architecture, with 2 separate inputs, each for 'topic' and 'document' that will be later merge into 1 binary output layer downstream. With these approach so we will have in total 3 different set of features, one each for 'document' and 'topic', and one for 'concatenatex_text', which is the combination of the first 2.","metadata":{"id":"Iu8NAP1d3UzY"}},{"cell_type":"code","source":"# @title\nX,y = training_df2[['document','topic','concatenated_text']],training_df2['judgement']\n# We are using a train/validate/test ratio of 0.85/0.1/0.05\n# Split data into train and tempt (combined of validate and test)\nX_train,X_temp,y_train,y_temp = train_test_split(X, y, test_size=0.15, random_state=42)\n\n# Split tempt to validate and test\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)\n\nX_train_doc,X_train_topic = X_train['document'].values, X_train['topic'].values\nX_val_doc,X_val_topic = X_val['document'].values, X_val['topic'].values\nX_test_doc,X_test_topic = X_test['document'].values, X_test['topic'].values\n\nX_train_concat = X_train['concatenated_text'].values\nX_val_concat = X_val['concatenated_text'].values\nX_test_concat = X_test['concatenated_text'].values","metadata":{"id":"kydExlPsBJQt","execution":{"iopub.status.busy":"2024-06-26T14:55:24.740910Z","iopub.execute_input":"2024-06-26T14:55:24.741593Z","iopub.status.idle":"2024-06-26T14:55:24.764035Z","shell.execute_reply.started":"2024-06-26T14:55:24.741560Z","shell.execute_reply":"2024-06-26T14:55:24.763134Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"As stated above, since we are looking to find the matching document with the provided topic, se while the 'judgement' are binary, we are mostly interest in the minority class, or y = 1, indicating that the document is relevant to the provided topics. Because of the imbalancy, so accuracy can be a misleading metrics, while taking into account multiple metrics like accuracy, precision, recall at once can make poor comparison, so we will mainly base our calculation on F1-Score. Due to tensorflow does not include f1 score as metrics, so we have to defined our own incorporating into tensorflow backend","metadata":{"id":"LKB2mfUF3UzY"}},{"cell_type":"markdown","source":"## 3.2. Generating word Embedding using GloVe\nThere are different option for pre-trained dataset but we choose GloVe 6B, with the 300 dimension variant, as it was based on Wikipedia 2014 anđ Gigaword5, which are intuitively related to the vocabulary of the text we are processing, also because it's relatively light weight to incorporate into our models. We hope that using GloVe will provide our model with global semantic representation and generalization, based on the dataset it was trained on.","metadata":{"id":"IpzggKo-BMrC"}},{"cell_type":"code","source":"# @title\n# Load GloVe embeddings\ndef load_glove_embeddings(embedding_path):\n    embedding_index = {}\n    with open(embedding_path, encoding=\"utf8\") as f:\n        for line in f:\n            values = line.split()\n            word = values[0]\n            coefs = np.asarray(values[1:], dtype='float32')\n            embedding_index[word] = coefs\n    return embedding_index\n\nembedding_dim = 300\n\n# Load GloVe embeddings\nglove_path = '/kaggle/input/glove-6b/glove.6B.'+ str(embedding_dim) +'d.txt'\nglove_embeddings_index = load_glove_embeddings(glove_path)\n\n# Custom function to map words to GloVe embeddings\ndef map_word_to_glove(word):\n    return glove_embeddings_index.get(word, np.zeros(embedding_dim)) # 300 is the dimensionality of GloVe embeddings\n\n# Define a function to convert text to embeddings using the vectorizer and custom mapping\ndef text_to_embedding(text):\n    words = tf.strings.split(text)\n    embeddings = tf.map_fn(lambda word: tf.py_function(map_word_to_glove, [word], Tout=tf.float32), words)\n    return embeddings","metadata":{"id":"U6S-9QUxBJLe","execution":{"iopub.status.busy":"2024-06-26T14:55:27.200706Z","iopub.execute_input":"2024-06-26T14:55:27.201370Z","iopub.status.idle":"2024-06-26T14:56:00.680219Z","shell.execute_reply.started":"2024-06-26T14:55:27.201335Z","shell.execute_reply":"2024-06-26T14:56:00.679371Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# @title\ndoc_max_sequence_length = 500\ndoc_max_tokens = 5000\n\ntopic_max_sequence_length = 500\ntopic_max_tokens = 500\n\nconcat_max_sequence_length = 1000\nconcat_max_tokens = \n\n# Create a TextVectorization layer with custom standardization and mapping function\ntopic_vectorizer = tf.keras.layers.TextVectorization(\n    max_tokens=topic_max_tokens,\n    output_mode='int',\n    output_sequence_length=topic_max_sequence_length,\n    standardize=None,  # Disable standardization\n\n)\ntopic_vectorizer.adapt(X_train['topic'])\n\n# Create a TextVectorization layer with custom standardization and mapping function\ndoc_vectorizer = tf.keras.layers.TextVectorization(\n    max_tokens=doc_max_tokens,\n    output_mode='int',\n    output_sequence_length=doc_max_sequence_length,\n    standardize=None,  # Disable standardization\n)\ndoc_vectorizer.adapt(X_train['document'])\n\n# Create a TextVectorization layer with custom standardization and mapping function\nconcat_vectorizer = tf.keras.layers.TextVectorization(\n    max_tokens=concat_max_tokens,\n    output_mode='int',\n    output_sequence_length=concat_max_sequence_length,\n    standardize=None,  # Disable standardization\n\n)\nconcat_vectorizer.adapt(X_train['concatenated_text'])","metadata":{"id":"TFnoaWM0BJJG","execution":{"iopub.status.busy":"2024-06-26T14:56:00.681956Z","iopub.execute_input":"2024-06-26T14:56:00.682277Z","iopub.status.idle":"2024-06-26T14:56:08.489773Z","shell.execute_reply.started":"2024-06-26T14:56:00.682247Z","shell.execute_reply":"2024-06-26T14:56:08.488933Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# @title\n# Get the vocabulary from the topic_vectorizer\ntopic_vocab = topic_vectorizer.get_vocabulary()\ndoc_vocab = doc_vectorizer.get_vocabulary()\nconcat_vocab = concat_vectorizer.get_vocabulary()\n\n# Initialize an empty list to store the embeddings\ntopic_embedding = []\ndoc_embedding = []\nconcat_embedding = []\n# Iterate through the vocabulary and map each word to its GloVe embedding\nfor word in topic_vocab:\n    topic_embedding.append(map_word_to_glove(word))\n\nfor word in doc_vocab:\n    doc_embedding.append(map_word_to_glove(word))\n\nfor word in concat_vocab:\n    concat_embedding.append(map_word_to_glove(word))\n\n\n# Convert the list of embedding vectors to a numpy array\ntopic_embedding = np.array(topic_embedding)\ndoc_embedding = np.array(doc_embedding)\nconcat_embedding = np.array(concat_embedding)\n\n# Check the shape of the embedding matrix\nprint(\"Shape of topic embedding:\", topic_embedding.shape)\nprint(\"Shape of document embedding:\", doc_embedding.shape)\nprint(\"Shape of concatened text embedding:\", concat_embedding.shape)","metadata":{"id":"FzBUM3WIBJGO","outputId":"9d088b5b-c40a-4794-8f47-484e4b76651f","execution":{"iopub.status.busy":"2024-06-26T14:56:08.490967Z","iopub.execute_input":"2024-06-26T14:56:08.491409Z","iopub.status.idle":"2024-06-26T14:56:08.591422Z","shell.execute_reply.started":"2024-06-26T14:56:08.491380Z","shell.execute_reply":"2024-06-26T14:56:08.590479Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Shape of topic embedding: (500, 300)\nShape of document embedding: (5000, 300)\nShape of concatened text embedding: (10000, 300)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3.3.Deep NN with GloVe Embedding","metadata":{"id":"RUCy-PGzBRrU"}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.utils import class_weight\nimport os\nimport zipfile\n\nclass ModelTraining:\n    def __init__(self, y_train):\n        # Prepare a dictionary to record result\n        self.dl_results={}\n        # Rebalanced classes weights\n        self.class_weights = self.compute_class_weights(y_train)\n        # Define metrics\n        self.metrics = self.define_metrics()\n        self._optimizer='adam'\n        self._loss_func='binary_crossentropy'\n        self._monitor='val_loss'\n        self.histories={}\n        # callback functions\n        self.callbacks = self.setup_callbacks()\n\n\n    # Setting up f1_score function for use during training process\n    def f1_score_metrics(self, y_true, y_pred):\n        true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n        possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n        predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n        recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n        f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n        return f1\n\n    def define_metrics(self):\n        return [\n            tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n#            tf.keras.metrics.Precision(name='precision'),\n#            tf.keras.metrics.Recall(name='recall'),\n#            tf.keras.metrics.AUC(name='auc'),\n            self.f1_score_metrics,\n        ]\n    #Calculate class weights\n    def compute_class_weights(self, y_train):\n        class_weights = class_weight.compute_class_weight(class_weight='balanced',\n                                                          classes=np.unique(y_train),\n                                                          y=y_train)\n        # Convert class weights to a dictionary\n        return dict(enumerate(class_weights))\n\n    def setup_callbacks(self):\n        lrd = ReduceLROnPlateau(monitor=self._monitor,\n                                patience=5,  # reduce lr every 5 epochs with no improvement\n                                verbose=1,\n                                factor=0.7,  # reduction factor\n                                min_lr=1e-4)  # minimum lr\n        mcp = ModelCheckpoint('model.h5.keras',\n                              monitor=self._monitor,\n                              verbose=1,\n                              save_best_only=True,  # Save 1 optimal model\n                              mode='min')  # Since we are looking to minimize loss\n        es = EarlyStopping(monitor=self._monitor, verbose=1,\n                           patience=15,  # early stop after 15 consecutive epochs with no improvement\n                           mode='min',  # Since we are looking to minimize loss\n                           restore_best_weights=True)  # Revert back to version with best loss\n        return [lrd, mcp, es]\n\n    # Setting up function to measure the models performance\n    def dl_metrics(self, test_pred, test_label, model_name, threshold=0.5):\n        binary_test_pred = (test_pred > threshold).astype(int)\n        report = classification_report(test_label, binary_test_pred)\n        print(report)\n        accuracy = accuracy_score(test_label, binary_test_pred)\n        precision = precision_score(test_label, binary_test_pred)\n        recall = recall_score(test_label, binary_test_pred)\n        f1 = f1_score(test_label, binary_test_pred)\n        pred_count = sum(binary_test_pred)\n        print('Total predictions: ', pred_count)\n        self.dl_results[model_name] = [accuracy, precision, recall, f1, pred_count]\n\n    # Code to zip\n    def zip_folder(self, folder_path, zip_path):\n        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            # Walk through all the files in the folder\n            for root, dirs, files in os.walk(folder_path):\n                for file in files:\n                    # Add each file to the zip file\n                    file_path = os.path.join(root, file)\n                    zipf.write(file_path, os.path.relpath(file_path, folder_path))\n    def compile_model(self,model, model_name):\n        model.compile(optimizer=self._optimizer,\n                      loss=self._loss_func,\n                      metrics=self.metrics)\n        model.summary()\n        model_plot = model_name +'.png'\n        plot_model(model,show_shapes=True,to_file = model_plot)\n    # Code to train model\n    def train_model(self, model,model_name,\n                    x_train, y_train,\n                    x_val, y_val,\n                    x_test, y_test,\n                    epochs=epoch_count, batch_size=batch_size):\n\n        history = model.fit(x_train, y_train,\n                            epochs=epochs,\n                            batch_size=batch_size,\n                            validation_data=(x_val, y_val),\n                            class_weight=self.class_weights,\n                            #callbacks=self.callbacks\n                            )\n        self.histories[model_name] = history\n\n        # make a prediction and save result\n        test_pred = model.predict(x_test)\n\n        self.dl_metrics(test_pred.flatten(),y_test, model_name)\n        # Saving the trained model\n        model.save(model_name)\n\n        # Specify the folder to be zipped and the path to save the zip file\n        zip_file_path = model_name + '.zip'\n\n        # Call the function to zip the folder\n        self.zip_folder(model_name, zip_file_path)","metadata":{"id":"_uWVyq8KJNYJ","execution":{"iopub.status.busy":"2024-06-26T15:36:04.629441Z","iopub.execute_input":"2024-06-26T15:36:04.629807Z","iopub.status.idle":"2024-06-26T15:36:04.654210Z","shell.execute_reply.started":"2024-06-26T15:36:04.629776Z","shell.execute_reply":"2024-06-26T15:36:04.653210Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"### 3.3.1. Dense NN with just embedding layer","metadata":{"id":"Ftiq2aR0BUTZ"}},{"cell_type":"code","source":"neural='dense'\nembedding=''\narchitecture=''\nmodel_name=neural+'_'+embedding+'_'+architecture\nprint(model_name)","metadata":{"id":"KQ9QYRYkoiwh","execution":{"iopub.status.busy":"2024-06-26T15:36:10.149333Z","iopub.execute_input":"2024-06-26T15:36:10.149694Z","iopub.status.idle":"2024-06-26T15:36:10.155453Z","shell.execute_reply.started":"2024-06-26T15:36:10.149664Z","shell.execute_reply":"2024-06-26T15:36:10.154468Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"dense__\n","output_type":"stream"}]},{"cell_type":"code","source":"# @title\n# Define input layers for 'document' and 'topic'\nconcat_input = tf.keras.layers.Input(shape=(1,),\n                                       dtype=tf.string, name='concat_input')\n\n# Use the tokenizer for each types\nconcat_tokens = concat_vectorizer(concat_input)\n\n# Embedding layer for 'document'\nconcat_embedding_layer = tf.keras.layers.Embedding(input_dim=len(concat_vocab),\n                                                    output_dim=embedding_dim,\n                                                    #input_length=concat_max_sequence_length,\n                                                   mask_zero=True)(concat_tokens)\n\n# Flatten the input if needed\nflattened_input = tf.keras.layers.Flatten()(concat_embedding_layer)\n\n# Define dense layers with L2 regularization\ndense1 = Dense(50, activation=activation_func, kernel_regularizer=regularizers.l2(0.01))(flattened_input)\ndropout1 = Dropout(0.5)(dense1)  # Add dropout\ndense2 = Dense(50, activation=activation_func, kernel_regularizer=regularizers.l2(0.01))(dropout1)\ndropout2 = Dropout(0.5)(dense2)  # Add dropout\ndense3 = Dense(50, activation=activation_func, kernel_regularizer=regularizers.l2(0.01))(dropout2)\n\n\n# Output layer for binary classification (assuming binary classification)\noutput_layer = Dense(1, activation='sigmoid')(dense3)\n\n# Define the model\nmodel = tf.keras.Model(inputs=concat_input, outputs=output_layer)","metadata":{"id":"sGmzrt00BJBI","outputId":"ec0dc41c-e918-40e7-b7e4-8f5f7f42a4cf","execution":{"iopub.status.busy":"2024-06-26T15:36:12.162528Z","iopub.execute_input":"2024-06-26T15:36:12.163213Z","iopub.status.idle":"2024-06-26T15:36:12.272471Z","shell.execute_reply.started":"2024-06-26T15:36:12.163180Z","shell.execute_reply":"2024-06-26T15:36:12.271695Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"model_training = ModelTraining(y_train)\nmodel_training.compile_model(model, model_name)","metadata":{"id":"LTgpbv7LBI-l","outputId":"e2038aac-6c36-49a8-9a53-7729033c57fd","execution":{"iopub.status.busy":"2024-06-26T15:36:14.842822Z","iopub.execute_input":"2024-06-26T15:36:14.843232Z","iopub.status.idle":"2024-06-26T15:36:14.988285Z","shell.execute_reply.started":"2024-06-26T15:36:14.843185Z","shell.execute_reply":"2024-06-26T15:36:14.987285Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"Model: \"model_9\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n concat_input (InputLayer)   [(None, 1)]               0         \n                                                                 \n text_vectorization_1 (Text  (None, 500)               0         \n Vectorization)                                                  \n                                                                 \n embedding_13 (Embedding)    (None, 500, 300)          3000000   \n                                                                 \n flatten_7 (Flatten)         (None, 150000)            0         \n                                                                 \n dense_24 (Dense)            (None, 50)                7500050   \n                                                                 \n dropout_15 (Dropout)        (None, 50)                0         \n                                                                 \n dense_25 (Dense)            (None, 50)                2550      \n                                                                 \n dropout_16 (Dropout)        (None, 50)                0         \n                                                                 \n dense_26 (Dense)            (None, 50)                2550      \n                                                                 \n dense_27 (Dense)            (None, 1)                 51        \n                                                                 \n=================================================================\nTotal params: 10505201 (40.07 MB)\nTrainable params: 10505201 (40.07 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_training.train_model(model, model_name,\n                           X_train_concat, y_train,\n                           X_val_concat, y_val,\n                           X_test_concat, y_test,\n                           )","metadata":{"id":"IHIM6e1x1tL-","execution":{"iopub.status.busy":"2024-06-26T15:36:17.729589Z","iopub.execute_input":"2024-06-26T15:36:17.729955Z","iopub.status.idle":"2024-06-26T15:37:08.236793Z","shell.execute_reply.started":"2024-06-26T15:36:17.729923Z","shell.execute_reply":"2024-06-26T15:37:08.235590Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"Epoch 1/15\n66/66 [==============================] - 8s 95ms/step - loss: 1.5029 - accuracy: 0.4274 - f1_score_metrics: 0.2741 - val_loss: 1.1799 - val_accuracy: 0.3643 - val_f1_score_metrics: 0.2674\nEpoch 2/15\n66/66 [==============================] - 3s 52ms/step - loss: 1.0752 - accuracy: 0.6501 - f1_score_metrics: 0.4124 - val_loss: 1.1001 - val_accuracy: 0.7155 - val_f1_score_metrics: 0.4550\nEpoch 3/15\n66/66 [==============================] - 3s 43ms/step - loss: 1.0530 - accuracy: 0.8223 - f1_score_metrics: 0.5763 - val_loss: 0.9604 - val_accuracy: 0.8423 - val_f1_score_metrics: 0.5132\nEpoch 4/15\n66/66 [==============================] - 2s 36ms/step - loss: 0.9474 - accuracy: 0.8847 - f1_score_metrics: 0.6990 - val_loss: 1.1556 - val_accuracy: 0.8252 - val_f1_score_metrics: 0.5139\nEpoch 5/15\n66/66 [==============================] - 3s 38ms/step - loss: 0.9226 - accuracy: 0.9331 - f1_score_metrics: 0.8151 - val_loss: 1.1516 - val_accuracy: 0.8196 - val_f1_score_metrics: 0.5378\nEpoch 6/15\n66/66 [==============================] - 3s 39ms/step - loss: 0.7745 - accuracy: 0.9614 - f1_score_metrics: 0.8862 - val_loss: 1.0106 - val_accuracy: 0.8626 - val_f1_score_metrics: 0.5403\nEpoch 7/15\n66/66 [==============================] - 2s 36ms/step - loss: 0.6782 - accuracy: 0.9756 - f1_score_metrics: 0.9269 - val_loss: 0.9901 - val_accuracy: 0.8626 - val_f1_score_metrics: 0.5496\nEpoch 8/15\n66/66 [==============================] - 2s 36ms/step - loss: 0.6030 - accuracy: 0.9805 - f1_score_metrics: 0.9414 - val_loss: 0.8081 - val_accuracy: 0.8691 - val_f1_score_metrics: 0.5377\nEpoch 9/15\n66/66 [==============================] - 2s 34ms/step - loss: 0.5880 - accuracy: 0.9827 - f1_score_metrics: 0.9456 - val_loss: 0.8834 - val_accuracy: 0.8631 - val_f1_score_metrics: 0.5442\nEpoch 10/15\n66/66 [==============================] - 2s 33ms/step - loss: 0.5541 - accuracy: 0.9843 - f1_score_metrics: 0.9521 - val_loss: 0.9354 - val_accuracy: 0.8651 - val_f1_score_metrics: 0.5275\nEpoch 11/15\n66/66 [==============================] - 2s 34ms/step - loss: 0.5447 - accuracy: 0.9865 - f1_score_metrics: 0.9576 - val_loss: 0.8999 - val_accuracy: 0.8631 - val_f1_score_metrics: 0.5210\nEpoch 12/15\n66/66 [==============================] - 2s 35ms/step - loss: 0.5410 - accuracy: 0.9875 - f1_score_metrics: 0.9611 - val_loss: 0.8444 - val_accuracy: 0.8701 - val_f1_score_metrics: 0.5415\nEpoch 13/15\n66/66 [==============================] - 2s 35ms/step - loss: 0.4834 - accuracy: 0.9898 - f1_score_metrics: 0.9684 - val_loss: 0.7665 - val_accuracy: 0.8641 - val_f1_score_metrics: 0.5631\nEpoch 14/15\n66/66 [==============================] - 2s 37ms/step - loss: 0.4483 - accuracy: 0.9898 - f1_score_metrics: 0.9675 - val_loss: 0.7165 - val_accuracy: 0.8772 - val_f1_score_metrics: 0.5332\nEpoch 15/15\n66/66 [==============================] - 2s 33ms/step - loss: 0.4891 - accuracy: 0.9906 - f1_score_metrics: 0.9698 - val_loss: 0.8089 - val_accuracy: 0.8706 - val_f1_score_metrics: 0.5357\n31/31 [==============================] - 0s 4ms/step\n              precision    recall  f1-score   support\n\n           0       0.90      0.93      0.92       821\n           1       0.55      0.47      0.51       154\n\n    accuracy                           0.86       975\n   macro avg       0.73      0.70      0.71       975\nweighted avg       0.85      0.86      0.85       975\n\nTotal predictions:  130\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 3.3.2. Dense NN with GloVe\nThe main goal of this experimentation is to see if the Embedding will improve the training result - The results during the process indicate a slight imporvement interm of F1-score but only by around 2%","metadata":{"id":"mrVxJmNXBbva"}},{"cell_type":"code","source":"neural='dense'\nembedding='GloVe'\narchitecture=''\nmodel_name=neural+'_'+embedding+'_'+architecture\nprint(model_name)","metadata":{"id":"Dqik-9R_ol9R","execution":{"iopub.status.busy":"2024-06-26T15:37:08.238969Z","iopub.execute_input":"2024-06-26T15:37:08.239396Z","iopub.status.idle":"2024-06-26T15:37:08.247009Z","shell.execute_reply.started":"2024-06-26T15:37:08.239358Z","shell.execute_reply":"2024-06-26T15:37:08.245787Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"dense_GloVe_\n","output_type":"stream"}]},{"cell_type":"code","source":"# @title\n# Define input layers for 'document' and 'topic'\nconcat_input = tf.keras.layers.Input(shape=(1,),\n                                       dtype=tf.string, name='concat_input')\n\n# Use the tokenizer for each types\nconcat_tokens = concat_vectorizer(concat_input)\n\n# Embedding layer for 'document'\nconcat_embedding_layer = tf.keras.layers.Embedding(input_dim=len(concat_vocab),\n                                                      output_dim=embedding_dim,\n                                                     weights=[concat_embedding],\n                                                      #input_length=concat_max_sequence_length,\n                                                      trainable=True, mask_zero=True)(concat_tokens)\n\n# Flatten the input if needed\nflattened_input = tf.keras.layers.Flatten()(concat_embedding_layer)\n\n# Define dense layers with L2 regularization\ndense1 = Dense(50, activation=activation_func, kernel_regularizer=regularizers.l2(0.01))(flattened_input)\ndropout1 = Dropout(0.5)(dense1)  # Add dropout\ndense2 = Dense(50, activation=activation_func, kernel_regularizer=regularizers.l2(0.01))(dropout1)\ndropout2 = Dropout(0.5)(dense2)  # Add dropout\ndense3 = Dense(50, activation=activation_func, kernel_regularizer=regularizers.l2(0.01))(dropout2)\n\n# Output layer for binary classification (assuming binary classification)\noutput_layer = Dense(1, activation='sigmoid')(dense3)\n\n# Define the model\nmodel = tf.keras.Model(inputs=concat_input, outputs=output_layer)","metadata":{"id":"SkRhzhLMBI2z","outputId":"c794dc2c-9f63-4732-8167-815aba22d5c6","execution":{"iopub.status.busy":"2024-06-26T15:37:13.832294Z","iopub.execute_input":"2024-06-26T15:37:13.832674Z","iopub.status.idle":"2024-06-26T15:37:13.953527Z","shell.execute_reply.started":"2024-06-26T15:37:13.832642Z","shell.execute_reply":"2024-06-26T15:37:13.952594Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"model_training.compile_model(model, model_name)","metadata":{"id":"TLstvemrzN9-","execution":{"iopub.status.busy":"2024-06-26T15:37:13.955445Z","iopub.execute_input":"2024-06-26T15:37:13.955807Z","iopub.status.idle":"2024-06-26T15:37:14.079723Z","shell.execute_reply.started":"2024-06-26T15:37:13.955772Z","shell.execute_reply":"2024-06-26T15:37:14.078948Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Model: \"model_11\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n concat_input (InputLayer)   [(None, 1)]               0         \n                                                                 \n text_vectorization_1 (Text  (None, 500)               0         \n Vectorization)                                                  \n                                                                 \n embedding_15 (Embedding)    (None, 500, 300)          3000000   \n                                                                 \n flatten_9 (Flatten)         (None, 150000)            0         \n                                                                 \n dense_32 (Dense)            (None, 50)                7500050   \n                                                                 \n dropout_19 (Dropout)        (None, 50)                0         \n                                                                 \n dense_33 (Dense)            (None, 50)                2550      \n                                                                 \n dropout_20 (Dropout)        (None, 50)                0         \n                                                                 \n dense_34 (Dense)            (None, 50)                2550      \n                                                                 \n dense_35 (Dense)            (None, 1)                 51        \n                                                                 \n=================================================================\nTotal params: 10505201 (40.07 MB)\nTrainable params: 10505201 (40.07 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_training.train_model(model, model_name,\n                           X_train_concat, y_train,\n                           X_val_concat, y_val,\n                           X_test_concat, y_test,\n                           )","metadata":{"id":"sXCYOcTm1wFw","execution":{"iopub.status.busy":"2024-06-26T15:37:14.080776Z","iopub.execute_input":"2024-06-26T15:37:14.081050Z","iopub.status.idle":"2024-06-26T15:38:45.262742Z","shell.execute_reply.started":"2024-06-26T15:37:14.081025Z","shell.execute_reply":"2024-06-26T15:38:45.261533Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"Epoch 1/15\n66/66 [==============================] - 8s 94ms/step - loss: 2.0604 - accuracy: 0.7456 - f1_score_metrics: 0.1312 - val_loss: 1.3774 - val_accuracy: 0.8519 - val_f1_score_metrics: 0.0862\nEpoch 2/15\n66/66 [==============================] - 3s 53ms/step - loss: 1.2304 - accuracy: 0.7328 - f1_score_metrics: 0.1823 - val_loss: 1.1461 - val_accuracy: 0.5119 - val_f1_score_metrics: 0.2489\nEpoch 3/15\n66/66 [==============================] - 3s 42ms/step - loss: 1.0781 - accuracy: 0.6771 - f1_score_metrics: 0.2369 - val_loss: 0.9928 - val_accuracy: 0.8570 - val_f1_score_metrics: 0.1753\nEpoch 4/15\n66/66 [==============================] - 2s 36ms/step - loss: 0.9886 - accuracy: 0.7167 - f1_score_metrics: 0.2797 - val_loss: 0.8938 - val_accuracy: 0.8545 - val_f1_score_metrics: 0.1418\nEpoch 5/15\n66/66 [==============================] - 3s 38ms/step - loss: 0.9373 - accuracy: 0.7365 - f1_score_metrics: 0.3246 - val_loss: 0.8659 - val_accuracy: 0.8444 - val_f1_score_metrics: 0.3370\nEpoch 6/15\n66/66 [==============================] - 3s 38ms/step - loss: 0.9161 - accuracy: 0.7893 - f1_score_metrics: 0.3982 - val_loss: 0.8412 - val_accuracy: 0.8489 - val_f1_score_metrics: 0.3965\nEpoch 7/15\n66/66 [==============================] - 2s 35ms/step - loss: 1.0129 - accuracy: 0.8274 - f1_score_metrics: 0.4874 - val_loss: 1.1303 - val_accuracy: 0.8090 - val_f1_score_metrics: 0.4299\nEpoch 8/15\n66/66 [==============================] - 2s 36ms/step - loss: 1.3355 - accuracy: 0.8412 - f1_score_metrics: 0.5667 - val_loss: 1.2956 - val_accuracy: 0.8626 - val_f1_score_metrics: 0.4033\nEpoch 9/15\n66/66 [==============================] - 2s 34ms/step - loss: 1.4159 - accuracy: 0.8627 - f1_score_metrics: 0.6198 - val_loss: 1.6349 - val_accuracy: 0.8312 - val_f1_score_metrics: 0.4778\nEpoch 10/15\n66/66 [==============================] - 2s 33ms/step - loss: 1.5339 - accuracy: 0.8785 - f1_score_metrics: 0.6707 - val_loss: 1.4793 - val_accuracy: 0.8317 - val_f1_score_metrics: 0.4795\nEpoch 11/15\n66/66 [==============================] - 2s 32ms/step - loss: 1.2923 - accuracy: 0.8986 - f1_score_metrics: 0.7106 - val_loss: 1.5778 - val_accuracy: 0.8580 - val_f1_score_metrics: 0.4945\nEpoch 12/15\n66/66 [==============================] - 2s 34ms/step - loss: 1.3453 - accuracy: 0.9239 - f1_score_metrics: 0.7758 - val_loss: 1.6154 - val_accuracy: 0.7595 - val_f1_score_metrics: 0.4363\nEpoch 13/15\n66/66 [==============================] - 2s 35ms/step - loss: 1.3038 - accuracy: 0.9203 - f1_score_metrics: 0.7692 - val_loss: 1.5001 - val_accuracy: 0.8464 - val_f1_score_metrics: 0.4902\nEpoch 14/15\n66/66 [==============================] - 2s 38ms/step - loss: 1.3009 - accuracy: 0.9352 - f1_score_metrics: 0.8119 - val_loss: 1.3687 - val_accuracy: 0.8519 - val_f1_score_metrics: 0.4865\nEpoch 15/15\n66/66 [==============================] - 2s 34ms/step - loss: 1.2231 - accuracy: 0.9411 - f1_score_metrics: 0.8251 - val_loss: 1.4713 - val_accuracy: 0.8368 - val_f1_score_metrics: 0.5059\n31/31 [==============================] - 0s 4ms/step\n              precision    recall  f1-score   support\n\n           0       0.90      0.89      0.89       821\n           1       0.45      0.49      0.47       154\n\n    accuracy                           0.82       975\n   macro avg       0.67      0.69      0.68       975\nweighted avg       0.83      0.82      0.83       975\n\nTotal predictions:  168\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3.4. RNN with GLoVe","metadata":{"id":"SRC4mP9JoARc"}},{"cell_type":"code","source":"neural='rnn'\nembedding='glove'\narchitecture=''\nmodel_name=neural+'_'+embedding+'_'+architecture\nprint(model_name)","metadata":{"id":"r64MQ6A5otMG","execution":{"iopub.status.busy":"2024-06-26T15:38:45.265535Z","iopub.execute_input":"2024-06-26T15:38:45.266326Z","iopub.status.idle":"2024-06-26T15:38:45.271372Z","shell.execute_reply.started":"2024-06-26T15:38:45.266275Z","shell.execute_reply":"2024-06-26T15:38:45.270395Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"rnn_glove_\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3.5. GRU and BiGRU with GLoVe","metadata":{"id":"M7Hndtu6oA_6"}},{"cell_type":"markdown","source":"### 3.5.1. GRU with GloVe","metadata":{"id":"dvrOK4Mao5M6"}},{"cell_type":"code","source":"neural='gru'\nembedding='glove'\narchitecture=''\nmodel_name=neural+'_'+embedding+'_'+architecture\nprint(model_name)","metadata":{"id":"ZqV2tZ4kotpg","outputId":"6cd7d3d0-e8f7-4024-d62e-d2be2b3c826b","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-26T15:38:45.272633Z","iopub.execute_input":"2024-06-26T15:38:45.272966Z","iopub.status.idle":"2024-06-26T15:38:45.281805Z","shell.execute_reply.started":"2024-06-26T15:38:45.272931Z","shell.execute_reply":"2024-06-26T15:38:45.280885Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"gru_glove_\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 3.5.2. BiGRU with GloVe","metadata":{"id":"_i8yaufXo8cJ"}},{"cell_type":"code","source":"neural='bigru'\nembedding='glove'\narchitecture=''\nmodel_name=neural+'_'+embedding+'_'+architecture\nprint(model_name)","metadata":{"id":"zNMsVwtPpcvI","execution":{"iopub.status.busy":"2024-06-26T15:38:45.282969Z","iopub.execute_input":"2024-06-26T15:38:45.283243Z","iopub.status.idle":"2024-06-26T15:38:45.291420Z","shell.execute_reply.started":"2024-06-26T15:38:45.283221Z","shell.execute_reply":"2024-06-26T15:38:45.290544Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"bigru_glove_\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3.6. LSTM and BiLSTM with GLoVe\nAs LSTM are mainly for sequential data such as text so we are experimenting to see if there is a clear improvement with just LSTM - though since we are looking for textual similarity, which might be outside of sequential pattern.","metadata":{"id":"uH_bh1OhBhnd"}},{"cell_type":"markdown","source":"### 3.6.1. LSTM","metadata":{"id":"r6qknpL-Bhkl"}},{"cell_type":"code","source":"neural='LSTM'\nembedding='GloVe'\narchitecture=''\nmodel_name=neural+'_'+embedding+'_'+architecture\nprint(model_name)","metadata":{"id":"AnrSTWecoz5-","execution":{"iopub.status.busy":"2024-06-26T15:38:45.292483Z","iopub.execute_input":"2024-06-26T15:38:45.292810Z","iopub.status.idle":"2024-06-26T15:38:45.302828Z","shell.execute_reply.started":"2024-06-26T15:38:45.292780Z","shell.execute_reply":"2024-06-26T15:38:45.301926Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"LSTM_GloVe_\n","output_type":"stream"}]},{"cell_type":"code","source":"# @title\n# Define input layers for 'document' and 'topic'\nconcat_input = tf.keras.layers.Input(shape=(1,),\n                                      dtype=tf.string, name='concat_input')\n\n# Use the tokenizer for each type\nconcat_tokens = concat_vectorizer(concat_input)\n\n# Embedding layer for 'document'\nconcat_embedding_layer = tf.keras.layers.Embedding(input_dim=len(concat_vocab),\n                                                   output_dim=embedding_dim,\n                                                   weights=[concat_embedding],\n                                                   #input_length=concat_max_sequence_length,\n                                                   trainable=True, mask_zero=True)(concat_tokens)\n\n# LSTM layers with dropout and regularizers\nlstm1 = LSTM(50, return_sequences=True, kernel_regularizer=regularizers.l2(0.01), recurrent_regularizer=regularizers.l2(0.01))(concat_embedding_layer)\ndropout1 = Dropout(0.5)(lstm1)  # Add dropout\nlstm2 = LSTM(50, kernel_regularizer=regularizers.l2(0.01), recurrent_regularizer=regularizers.l2(0.01))(dropout1)\ndropout2 = Dropout(0.5)(lstm2)  # Add dropout\n\n# Output layer for binary classification (assuming binary classification)\noutput_layer = Dense(1, activation='sigmoid')(dropout2)\n\n# Define the model\nmodel = tf.keras.Model(inputs=concat_input, outputs=output_layer)","metadata":{"id":"0A2XrbBVBmGu","outputId":"9fb3429a-e4e5-493d-fa91-bb78882950ca","execution":{"iopub.status.busy":"2024-06-26T15:38:45.304185Z","iopub.execute_input":"2024-06-26T15:38:45.304446Z","iopub.status.idle":"2024-06-26T15:38:46.942764Z","shell.execute_reply.started":"2024-06-26T15:38:45.304424Z","shell.execute_reply":"2024-06-26T15:38:46.941995Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"model_training.compile_model(model, model_name)","metadata":{"id":"FUlM9wtvzdNO","execution":{"iopub.status.busy":"2024-06-26T15:38:46.943767Z","iopub.execute_input":"2024-06-26T15:38:46.944344Z","iopub.status.idle":"2024-06-26T15:38:47.052683Z","shell.execute_reply.started":"2024-06-26T15:38:46.944317Z","shell.execute_reply":"2024-06-26T15:38:47.051814Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"Model: \"model_12\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n concat_input (InputLayer)   [(None, 1)]               0         \n                                                                 \n text_vectorization_1 (Text  (None, 500)               0         \n Vectorization)                                                  \n                                                                 \n embedding_16 (Embedding)    (None, 500, 300)          3000000   \n                                                                 \n lstm_7 (LSTM)               (None, 500, 50)           70200     \n                                                                 \n dropout_21 (Dropout)        (None, 500, 50)           0         \n                                                                 \n lstm_8 (LSTM)               (None, 50)                20200     \n                                                                 \n dropout_22 (Dropout)        (None, 50)                0         \n                                                                 \n dense_36 (Dense)            (None, 1)                 51        \n                                                                 \n=================================================================\nTotal params: 3090451 (11.79 MB)\nTrainable params: 3090451 (11.79 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_training.train_model(model, model_name,\n                           X_train_concat, y_train,\n                           X_val_concat, y_val,\n                           X_test_concat, y_test,\n                           )","metadata":{"id":"iOc1OnSE1zSH","execution":{"iopub.status.busy":"2024-06-26T15:38:47.055772Z","iopub.execute_input":"2024-06-26T15:38:47.056052Z","iopub.status.idle":"2024-06-26T15:40:56.331276Z","shell.execute_reply.started":"2024-06-26T15:38:47.056027Z","shell.execute_reply":"2024-06-26T15:40:56.330228Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"Epoch 1/15\n66/66 [==============================] - 20s 187ms/step - loss: 2.7437 - accuracy: 0.5842 - f1_score_metrics: 0.2928 - val_loss: 1.4017 - val_accuracy: 0.6023 - val_f1_score_metrics: 0.3246\nEpoch 2/15\n66/66 [==============================] - 7s 111ms/step - loss: 1.0038 - accuracy: 0.6497 - f1_score_metrics: 0.3630 - val_loss: 0.8284 - val_accuracy: 0.5766 - val_f1_score_metrics: 0.3377\nEpoch 3/15\n66/66 [==============================] - 7s 102ms/step - loss: 0.6891 - accuracy: 0.6824 - f1_score_metrics: 0.4151 - val_loss: 0.5617 - val_accuracy: 0.7650 - val_f1_score_metrics: 0.3975\nEpoch 4/15\n66/66 [==============================] - 6s 97ms/step - loss: 0.5929 - accuracy: 0.7142 - f1_score_metrics: 0.4556 - val_loss: 0.6473 - val_accuracy: 0.6680 - val_f1_score_metrics: 0.3724\nEpoch 5/15\n66/66 [==============================] - 7s 101ms/step - loss: 0.5414 - accuracy: 0.7505 - f1_score_metrics: 0.5003 - val_loss: 0.7229 - val_accuracy: 0.5851 - val_f1_score_metrics: 0.3553\nEpoch 6/15\n66/66 [==============================] - 7s 99ms/step - loss: 0.5106 - accuracy: 0.7646 - f1_score_metrics: 0.5241 - val_loss: 0.4802 - val_accuracy: 0.7938 - val_f1_score_metrics: 0.4138\nEpoch 7/15\n66/66 [==============================] - 6s 97ms/step - loss: 0.4751 - accuracy: 0.7888 - f1_score_metrics: 0.5554 - val_loss: 0.5796 - val_accuracy: 0.7418 - val_f1_score_metrics: 0.4303\nEpoch 8/15\n66/66 [==============================] - 6s 97ms/step - loss: 0.4433 - accuracy: 0.8174 - f1_score_metrics: 0.5912 - val_loss: 0.5586 - val_accuracy: 0.7479 - val_f1_score_metrics: 0.4098\nEpoch 9/15\n66/66 [==============================] - 6s 95ms/step - loss: 0.4245 - accuracy: 0.8304 - f1_score_metrics: 0.6139 - val_loss: 0.5672 - val_accuracy: 0.7479 - val_f1_score_metrics: 0.4104\nEpoch 10/15\n66/66 [==============================] - 6s 95ms/step - loss: 0.4096 - accuracy: 0.8357 - f1_score_metrics: 0.6298 - val_loss: 0.5710 - val_accuracy: 0.7676 - val_f1_score_metrics: 0.4199\nEpoch 11/15\n66/66 [==============================] - 6s 94ms/step - loss: 0.3756 - accuracy: 0.8577 - f1_score_metrics: 0.6612 - val_loss: 0.4997 - val_accuracy: 0.8080 - val_f1_score_metrics: 0.4224\nEpoch 12/15\n66/66 [==============================] - 6s 95ms/step - loss: 0.3594 - accuracy: 0.8647 - f1_score_metrics: 0.6762 - val_loss: 0.5285 - val_accuracy: 0.7908 - val_f1_score_metrics: 0.4120\nEpoch 13/15\n66/66 [==============================] - 6s 97ms/step - loss: 0.3601 - accuracy: 0.8660 - f1_score_metrics: 0.6798 - val_loss: 0.6611 - val_accuracy: 0.7352 - val_f1_score_metrics: 0.4285\nEpoch 14/15\n66/66 [==============================] - 6s 98ms/step - loss: 0.3449 - accuracy: 0.8731 - f1_score_metrics: 0.6888 - val_loss: 0.6307 - val_accuracy: 0.7741 - val_f1_score_metrics: 0.4168\nEpoch 15/15\n66/66 [==============================] - 6s 95ms/step - loss: 0.3224 - accuracy: 0.8856 - f1_score_metrics: 0.7129 - val_loss: 0.6502 - val_accuracy: 0.7479 - val_f1_score_metrics: 0.4180\n31/31 [==============================] - 3s 23ms/step\n              precision    recall  f1-score   support\n\n           0       0.90      0.76      0.82       821\n           1       0.30      0.56      0.39       154\n\n    accuracy                           0.73       975\n   macro avg       0.60      0.66      0.61       975\nweighted avg       0.81      0.73      0.76       975\n\nTotal predictions:  283\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 3.6.2. Bidirectional LSTM","metadata":{"id":"hRdAKYgeBhh-"}},{"cell_type":"code","source":"# @title\n# Define input layers for 'document' and 'topic'\nconcat_input = tf.keras.layers.Input(shape=(1,),\n                                      dtype=tf.string, name='concat_input')\n\n# Use the tokenizer for each type\nconcat_tokens = concat_vectorizer(concat_input)\n\n# Embedding layer for 'document'\nconcat_embedding_layer = tf.keras.layers.Embedding(input_dim=len(concat_vocab),\n                                                   output_dim=embedding_dim,\n                                                   weights=[concat_embedding],\n                                                   trainable=True,\n                                                   mask_zero=True)(concat_tokens)\n\n# LSTM layers with dropout and regularizers\nlstm1 =  Bidirectional(LSTM(50, return_sequences=True,\n                            kernel_regularizer=regularizers.l2(0.01),\n                            recurrent_regularizer=regularizers.l2(0.01)))(concat_embedding_layer)\ndropout1 = Dropout(0.5)(lstm1)  # Add dropout\nlstm2 =  Bidirectional(LSTM(50, kernel_regularizer=regularizers.l2(0.01),\n                            recurrent_regularizer=regularizers.l2(0.01)))(dropout1)\ndropout2 = Dropout(0.5)(lstm2)  # Add dropout\n\n# Output layer for binary classification (assuming binary classification)\noutput_layer = Dense(1, activation='sigmoid')(dropout2)\n\n# Define the model\nmodel = tf.keras.Model(inputs=concat_input, outputs=output_layer)","metadata":{"id":"DsxdH3vnCV1x","outputId":"753b3b32-98f4-4bf9-a4b5-0c4f77197616","execution":{"iopub.status.busy":"2024-06-26T15:40:56.332655Z","iopub.execute_input":"2024-06-26T15:40:56.332956Z","iopub.status.idle":"2024-06-26T15:40:59.835493Z","shell.execute_reply.started":"2024-06-26T15:40:56.332933Z","shell.execute_reply":"2024-06-26T15:40:59.834472Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"model_training.compile_model(model, model_name)","metadata":{"id":"h6xqYs_WCXTN","outputId":"1d3092a5-7ae8-482f-d98f-f07afe607104","execution":{"iopub.status.busy":"2024-06-26T15:40:59.836590Z","iopub.execute_input":"2024-06-26T15:40:59.836875Z","iopub.status.idle":"2024-06-26T15:40:59.955425Z","shell.execute_reply.started":"2024-06-26T15:40:59.836850Z","shell.execute_reply":"2024-06-26T15:40:59.954478Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"Model: \"model_13\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n concat_input (InputLayer)   [(None, 1)]               0         \n                                                                 \n text_vectorization_1 (Text  (None, 500)               0         \n Vectorization)                                                  \n                                                                 \n embedding_17 (Embedding)    (None, 500, 300)          3000000   \n                                                                 \n bidirectional_4 (Bidirecti  (None, 500, 100)          140400    \n onal)                                                           \n                                                                 \n dropout_23 (Dropout)        (None, 500, 100)          0         \n                                                                 \n bidirectional_5 (Bidirecti  (None, 100)               60400     \n onal)                                                           \n                                                                 \n dropout_24 (Dropout)        (None, 100)               0         \n                                                                 \n dense_37 (Dense)            (None, 1)                 101       \n                                                                 \n=================================================================\nTotal params: 3200901 (12.21 MB)\nTrainable params: 3200901 (12.21 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_training.train_model(model, model_name,\n                           X_train_concat, y_train,\n                           X_val_concat, y_val,\n                           X_test_concat, y_test\n                           )","metadata":{"id":"Ch1-X6ZT13m5","execution":{"iopub.status.busy":"2024-06-26T15:40:59.956640Z","iopub.execute_input":"2024-06-26T15:40:59.956942Z","iopub.status.idle":"2024-06-26T15:45:19.777856Z","shell.execute_reply.started":"2024-06-26T15:40:59.956916Z","shell.execute_reply":"2024-06-26T15:45:19.776759Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"Epoch 1/15\n66/66 [==============================] - 37s 311ms/step - loss: 5.3025 - accuracy: 0.5780 - f1_score_metrics: 0.2829 - val_loss: 2.2625 - val_accuracy: 0.6392 - val_f1_score_metrics: 0.3420\nEpoch 2/15\n66/66 [==============================] - 14s 207ms/step - loss: 1.3562 - accuracy: 0.6919 - f1_score_metrics: 0.4022 - val_loss: 0.9071 - val_accuracy: 0.6685 - val_f1_score_metrics: 0.4130\nEpoch 3/15\n66/66 [==============================] - 13s 199ms/step - loss: 0.6559 - accuracy: 0.7716 - f1_score_metrics: 0.5133 - val_loss: 0.5467 - val_accuracy: 0.8024 - val_f1_score_metrics: 0.4954\nEpoch 4/15\n66/66 [==============================] - 13s 195ms/step - loss: 0.4877 - accuracy: 0.8195 - f1_score_metrics: 0.5922 - val_loss: 0.5514 - val_accuracy: 0.7802 - val_f1_score_metrics: 0.4919\nEpoch 5/15\n66/66 [==============================] - 13s 197ms/step - loss: 0.4352 - accuracy: 0.8358 - f1_score_metrics: 0.6265 - val_loss: 0.6916 - val_accuracy: 0.6776 - val_f1_score_metrics: 0.4197\nEpoch 6/15\n66/66 [==============================] - 13s 197ms/step - loss: 0.3892 - accuracy: 0.8540 - f1_score_metrics: 0.6574 - val_loss: 0.4714 - val_accuracy: 0.8151 - val_f1_score_metrics: 0.5063\nEpoch 7/15\n66/66 [==============================] - 13s 195ms/step - loss: 0.3571 - accuracy: 0.8682 - f1_score_metrics: 0.6858 - val_loss: 0.5163 - val_accuracy: 0.7852 - val_f1_score_metrics: 0.4825\nEpoch 8/15\n66/66 [==============================] - 13s 195ms/step - loss: 0.3242 - accuracy: 0.8797 - f1_score_metrics: 0.7080 - val_loss: 0.5408 - val_accuracy: 0.7797 - val_f1_score_metrics: 0.4735\nEpoch 9/15\n66/66 [==============================] - 13s 193ms/step - loss: 0.3101 - accuracy: 0.8840 - f1_score_metrics: 0.7163 - val_loss: 0.6438 - val_accuracy: 0.7676 - val_f1_score_metrics: 0.4752\nEpoch 10/15\n66/66 [==============================] - 13s 193ms/step - loss: 0.2773 - accuracy: 0.9021 - f1_score_metrics: 0.7529 - val_loss: 0.6101 - val_accuracy: 0.7736 - val_f1_score_metrics: 0.4733\nEpoch 11/15\n66/66 [==============================] - 13s 193ms/step - loss: 0.2665 - accuracy: 0.9043 - f1_score_metrics: 0.7561 - val_loss: 0.6241 - val_accuracy: 0.7837 - val_f1_score_metrics: 0.4832\nEpoch 12/15\n66/66 [==============================] - 13s 193ms/step - loss: 0.2508 - accuracy: 0.9141 - f1_score_metrics: 0.7795 - val_loss: 0.5357 - val_accuracy: 0.8343 - val_f1_score_metrics: 0.4968\nEpoch 13/15\n66/66 [==============================] - 13s 195ms/step - loss: 0.2300 - accuracy: 0.9261 - f1_score_metrics: 0.8031 - val_loss: 0.6548 - val_accuracy: 0.7959 - val_f1_score_metrics: 0.4882\nEpoch 14/15\n66/66 [==============================] - 13s 196ms/step - loss: 0.2157 - accuracy: 0.9324 - f1_score_metrics: 0.8152 - val_loss: 0.6542 - val_accuracy: 0.8105 - val_f1_score_metrics: 0.4978\nEpoch 15/15\n66/66 [==============================] - 13s 192ms/step - loss: 0.2014 - accuracy: 0.9361 - f1_score_metrics: 0.8242 - val_loss: 0.5778 - val_accuracy: 0.8191 - val_f1_score_metrics: 0.4901\n31/31 [==============================] - 6s 40ms/step\n              precision    recall  f1-score   support\n\n           0       0.91      0.86      0.88       821\n           1       0.41      0.54      0.47       154\n\n    accuracy                           0.81       975\n   macro avg       0.66      0.70      0.68       975\nweighted avg       0.83      0.81      0.82       975\n\nTotal predictions:  200\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3.7. Siamese Neural Network with GloVe embedding\nThis is just a separate test to see if the Siamese architecture by itself help imporve performance\n","metadata":{"id":"leo3VDU0BhfO"}},{"cell_type":"markdown","source":"### 3.7.1. Siamese LSTM with cosine distance","metadata":{"id":"jGZ3pi-bugMh"}},{"cell_type":"code","source":"neural='lstm'\nembedding='glove'\narchitecture='siamese'\ndistance='cosine'\nmodel_name=neural+'_'+embedding+'_'+architecture+'_'+distance\nprint(model_name)","metadata":{"id":"1KlbSg0Wq91q","outputId":"0ac9600c-dc2b-461b-b823-39c20266627f","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-26T15:45:19.779195Z","iopub.execute_input":"2024-06-26T15:45:19.779502Z","iopub.status.idle":"2024-06-26T15:45:19.784998Z","shell.execute_reply.started":"2024-06-26T15:45:19.779477Z","shell.execute_reply":"2024-06-26T15:45:19.784137Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"lstm_glove_siamese_cosine\n","output_type":"stream"}]},{"cell_type":"code","source":"# @title\ndef auroc(y_true, y_pred):\n    auc = tf.numpy_function(roc_auc_score, (y_true, y_pred), tf.double)\n    return auc\ndef cosine_distance(vests):\n    x, y = vests\n    x = K.l2_normalize(x, axis=-1)\n    y = K.l2_normalize(y, axis=-1)\n    return -K.mean(x * y, axis=-1, keepdims=True)\n\ndef cos_dist_output_shape(shapes):\n    shape1, shape2 = shapes\n    return (shape1[0],1)\n# Define input layers for 'document' and 'topic'\ndocument_input = tf.keras.layers.Input(shape=(1,),\n                                       dtype=tf.string, name='document_input')\ntopic_input = tf.keras.layers.Input(shape=(1,),\n                                    dtype=tf.string, name='topic_input')\n\n# Use the tokenizer for each types\ndocument_tokens = doc_vectorizer(document_input)\n\ntopic_tokens = topic_vectorizer(topic_input)\n\n# Embedding layer for 'document'\ndocument_embedding_layer = tf.keras.layers.Embedding(input_dim=len(doc_vocab),\n                                                      output_dim=embedding_dim,\n                                                     weights=[doc_embedding],\n                                                      #input_length=doc_max_sequence_length,\n                                                      trainable=True, mask_zero=True)(document_tokens)\n\n# Embedding layer for 'topic'\ntopic_embedding_layer = tf.keras.layers.Embedding(input_dim=len(topic_vocab),\n                                                  output_dim=embedding_dim,\n                                                  weights=[topic_embedding],\n                                                  #input_length=topic_max_sequence_length,\n                                                  trainable=True, mask_zero=True)(topic_tokens)\nlstm_1 = document_embedding_layer\nlstm_2 = topic_embedding_layer\n\n\ncommon_lstm = LSTM(64,return_sequences=True, activation=\"relu\")\nvector_1 = common_lstm(lstm_1)\nvector_1 = Flatten()(vector_1)\n\nvector_2 = common_lstm(lstm_2)\nvector_2 = Flatten()(vector_2)\n\nx3 = Subtract()([vector_1, vector_2])\nx3 = Multiply()([x3, x3])\n\nx1_ = Multiply()([vector_1, vector_1])\nx2_ = Multiply()([vector_2, vector_2])\nx4 = Subtract()([x1_, x2_])\n\n    #https://stackoverflow.com/a/51003359/10650182\nx5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([vector_1, vector_2])\n\nconc = Concatenate(axis=-1)([x5,x4, x3])\n\nx = Dense(100, activation=\"relu\", name='conc_layer')(conc)\nx = Dropout(0.5)(x)\nout = Dense(1, activation=\"sigmoid\", name = 'out')(x)\n\nmodel = Model([document_input, topic_input], out)","metadata":{"id":"SzTOY-X-C_We","outputId":"0d95ba5b-fb32-4906-8502-efd372439f16","execution":{"iopub.status.busy":"2024-06-26T15:45:19.786894Z","iopub.execute_input":"2024-06-26T15:45:19.787277Z","iopub.status.idle":"2024-06-26T15:45:20.117395Z","shell.execute_reply.started":"2024-06-26T15:45:19.787232Z","shell.execute_reply":"2024-06-26T15:45:20.116513Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"model_training.compile_model(model, model_name)","metadata":{"id":"tikR2b1Tzz9K","execution":{"iopub.status.busy":"2024-06-26T15:45:20.118589Z","iopub.execute_input":"2024-06-26T15:45:20.118934Z","iopub.status.idle":"2024-06-26T15:45:20.384777Z","shell.execute_reply.started":"2024-06-26T15:45:20.118900Z","shell.execute_reply":"2024-06-26T15:45:20.383723Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Model: \"model_14\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n document_input (InputLayer  [(None, 1)]                  0         []                            \n )                                                                                                \n                                                                                                  \n topic_input (InputLayer)    [(None, 1)]                  0         []                            \n                                                                                                  \n text_vectorization_1 (Text  (None, 500)                  0         ['document_input[0][0]']      \n Vectorization)                                                                                   \n                                                                                                  \n text_vectorization (TextVe  (None, 500)                  0         ['topic_input[0][0]']         \n ctorization)                                                                                     \n                                                                                                  \n embedding_18 (Embedding)    (None, 500, 300)             1500000   ['text_vectorization_1[16][0]'\n                                                                    ]                             \n                                                                                                  \n embedding_19 (Embedding)    (None, 500, 300)             150000    ['text_vectorization[2][0]']  \n                                                                                                  \n lstm_11 (LSTM)              (None, 500, 64)              93440     ['embedding_18[0][0]',        \n                                                                     'embedding_19[0][0]']        \n                                                                                                  \n flatten_10 (Flatten)        (None, 32000)                0         ['lstm_11[0][0]']             \n                                                                                                  \n flatten_11 (Flatten)        (None, 32000)                0         ['lstm_11[1][0]']             \n                                                                                                  \n multiply_4 (Multiply)       (None, 32000)                0         ['flatten_10[0][0]',          \n                                                                     'flatten_10[0][0]']          \n                                                                                                  \n multiply_5 (Multiply)       (None, 32000)                0         ['flatten_11[0][0]',          \n                                                                     'flatten_11[0][0]']          \n                                                                                                  \n subtract_2 (Subtract)       (None, 32000)                0         ['flatten_10[0][0]',          \n                                                                     'flatten_11[0][0]']          \n                                                                                                  \n lambda_2 (Lambda)           (None, 1)                    0         ['flatten_10[0][0]',          \n                                                                     'flatten_11[0][0]']          \n                                                                                                  \n subtract_3 (Subtract)       (None, 32000)                0         ['multiply_4[0][0]',          \n                                                                     'multiply_5[0][0]']          \n                                                                                                  \n multiply_3 (Multiply)       (None, 32000)                0         ['subtract_2[0][0]',          \n                                                                     'subtract_2[0][0]']          \n                                                                                                  \n concatenate_1 (Concatenate  (None, 64001)                0         ['lambda_2[0][0]',            \n )                                                                   'subtract_3[0][0]',          \n                                                                     'multiply_3[0][0]']          \n                                                                                                  \n conc_layer (Dense)          (None, 100)                  6400200   ['concatenate_1[0][0]']       \n                                                                                                  \n dropout_25 (Dropout)        (None, 100)                  0         ['conc_layer[0][0]']          \n                                                                                                  \n out (Dense)                 (None, 1)                    101       ['dropout_25[0][0]']          \n                                                                                                  \n==================================================================================================\nTotal params: 8143741 (31.07 MB)\nTrainable params: 8143741 (31.07 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_training.train_model(model, model_name,\n                           [X_train_doc,X_train_topic], y_train,\n                           [X_val_doc, X_val_topic], y_val,\n                           [X_test_doc, X_test_topic], y_test\n                           )","metadata":{"id":"vGdpgN132Gw3","execution":{"iopub.status.busy":"2024-06-26T15:45:20.385938Z","iopub.execute_input":"2024-06-26T15:45:20.386264Z","iopub.status.idle":"2024-06-26T15:48:29.554580Z","shell.execute_reply.started":"2024-06-26T15:45:20.386226Z","shell.execute_reply":"2024-06-26T15:48:29.552986Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Epoch 1/15\n66/66 [==============================] - 106s 2s/step - loss: 0.6455 - accuracy: 0.6445 - f1_score_metrics: 0.3656 - val_loss: 0.5847 - val_accuracy: 0.6796 - val_f1_score_metrics: 0.4064\nEpoch 2/15\n55/66 [========================>.....] - ETA: 16s - loss: 0.5190 - accuracy: 0.7465 - f1_score_metrics: 0.4809","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train_topic\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_topic\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_topic\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[91], line 104\u001b[0m, in \u001b[0;36mModelTraining.train_model\u001b[0;34m(self, model, model_name, x_train, y_train, x_val, y_val, x_test, y_test, epochs, batch_size)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model,model_name,\n\u001b[1;32m     99\u001b[0m                 x_train, y_train,\n\u001b[1;32m    100\u001b[0m                 x_val, y_val,\n\u001b[1;32m    101\u001b[0m                 x_test, y_test,\n\u001b[1;32m    102\u001b[0m                 epochs\u001b[38;5;241m=\u001b[39mepoch_count, batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[0;32m--> 104\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m#callbacks=self.callbacks\u001b[39;49;00m\n\u001b[1;32m    110\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistories[model_name] \u001b[38;5;241m=\u001b[39m history\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# make a prediction and save result\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"### 3.7.2 Siamese Bidirectional LSTM with euclidean distance","metadata":{"id":"eMZpbF7AD7fc"}},{"cell_type":"code","source":"neural='bilstm'\nembedding='glove'\narchitecture='siamese'\ndistance='euclidean'\nmodel_name=neural+'_'+embedding+'_'+architecture+'_'+distance\nprint(model_name)","metadata":{"id":"ZiZvkRqPr567","outputId":"5a2dd95f-186f-4f25-bf25-a9c4c549eb25","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-26T15:48:35.191155Z","iopub.execute_input":"2024-06-26T15:48:35.191801Z","iopub.status.idle":"2024-06-26T15:48:35.197300Z","shell.execute_reply.started":"2024-06-26T15:48:35.191769Z","shell.execute_reply":"2024-06-26T15:48:35.196361Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"bilstm_glove_siamese_euclidean\n","output_type":"stream"}]},{"cell_type":"code","source":"# @title\ndef euclidean_distance(vects):\n    x, y = vects\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n\n\n# Define input layers for 'document' and 'topic'\ndocument_input = Input(shape=(1,), dtype=tf.string, name='document_input')\ntopic_input = Input(shape=(1,), dtype=tf.string, name='topic_input')\n\n# Use the tokenizer for each type\ndocument_tokens = doc_vectorizer(document_input)\ntopic_tokens = topic_vectorizer(topic_input)\n\n# Embedding layer for 'document'\ndocument_embedding_layer = tf.keras.layers.Embedding(input_dim=len(doc_vocab),\n                                                      output_dim=embedding_dim,\n                                                     weights=[doc_embedding],\n                                                      #input_length=doc_max_sequence_length,\n                                                      trainable=True, mask_zero=True)(document_tokens)\n\n# Embedding layer for 'topic'\ntopic_embedding_layer = tf.keras.layers.Embedding(input_dim=len(topic_vocab),\n                                                  output_dim=embedding_dim,\n                                                  weights=[topic_embedding],\n                                                  #input_length=topic_max_sequence_length,\n                                                  trainable=True, mask_zero=True)(topic_tokens)\n\ndistance = Lambda(euclidean_distance)([document_embedding_layer, topic_embedding_layer])\n\n# Bidirectional LSTM layers for 'document' and 'topic'\nbidirectional_lstm_document = Bidirectional(LSTM(units=64, activation=activation_func, return_sequences=True, dropout=0.5))(distance)\nbidirectional_lstm_topic = Bidirectional(LSTM(units=64, activation=activation_func, return_sequences=True, dropout=0.5))(distance)\n\n# Dense layer\ndense_combined = Dense(units=32, activation=activation_func)(bidirectional_lstm_document)\n\n\n# Dense layer\noutput = Dense(units=1, activation='sigmoid')(dense_combined)\n\n# Define the model\nmodel = Model(inputs=[document_input, topic_input], outputs=output)","metadata":{"id":"MKBP9RrOD-WV","outputId":"31a0a24a-b795-43ad-9ff8-4613ac11ecfe","execution":{"iopub.status.busy":"2024-06-26T15:48:37.459863Z","iopub.execute_input":"2024-06-26T15:48:37.460237Z","iopub.status.idle":"2024-06-26T15:48:37.971239Z","shell.execute_reply.started":"2024-06-26T15:48:37.460206Z","shell.execute_reply":"2024-06-26T15:48:37.970225Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"model_training.compile_model(model, model_name)","metadata":{"id":"PTQs_F1UEBTr","outputId":"e9f66fc7-4edc-47ce-aace-18bef36e7cb2","execution":{"iopub.status.busy":"2024-06-26T15:48:41.735500Z","iopub.execute_input":"2024-06-26T15:48:41.735869Z","iopub.status.idle":"2024-06-26T15:48:41.869212Z","shell.execute_reply.started":"2024-06-26T15:48:41.735839Z","shell.execute_reply":"2024-06-26T15:48:41.868284Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"Model: \"model_15\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n document_input (InputLayer  [(None, 1)]                  0         []                            \n )                                                                                                \n                                                                                                  \n topic_input (InputLayer)    [(None, 1)]                  0         []                            \n                                                                                                  \n text_vectorization_1 (Text  (None, 500)                  0         ['document_input[0][0]']      \n Vectorization)                                                                                   \n                                                                                                  \n text_vectorization (TextVe  (None, 500)                  0         ['topic_input[0][0]']         \n ctorization)                                                                                     \n                                                                                                  \n embedding_20 (Embedding)    (None, 500, 300)             1500000   ['text_vectorization_1[17][0]'\n                                                                    ]                             \n                                                                                                  \n embedding_21 (Embedding)    (None, 500, 300)             150000    ['text_vectorization[3][0]']  \n                                                                                                  \n lambda_3 (Lambda)           (None, 1, 300)               0         ['embedding_20[0][0]',        \n                                                                     'embedding_21[0][0]']        \n                                                                                                  \n bidirectional_6 (Bidirecti  (None, 1, 128)               186880    ['lambda_3[0][0]']            \n onal)                                                                                            \n                                                                                                  \n dense_38 (Dense)            (None, 1, 32)                4128      ['bidirectional_6[0][0]']     \n                                                                                                  \n dense_39 (Dense)            (None, 1, 1)                 33        ['dense_38[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 1841041 (7.02 MB)\nTrainable params: 1841041 (7.02 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_training.train_model(model, model_name,\n                           [X_train_doc,X_train_topic], y_train,\n                           [X_val_doc, X_val_topic], y_val,\n                           [X_test_doc, X_test_topic], y_test,\n                           )","metadata":{"id":"VQ-EWEPa2M-g","execution":{"iopub.status.busy":"2024-06-26T15:48:45.040916Z","iopub.execute_input":"2024-06-26T15:48:45.041785Z","iopub.status.idle":"2024-06-26T15:49:56.343470Z","shell.execute_reply.started":"2024-06-26T15:48:45.041752Z","shell.execute_reply":"2024-06-26T15:49:56.342444Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"Epoch 1/15\n66/66 [==============================] - 13s 124ms/step - loss: 0.7577 - accuracy: 0.6137 - f1_score_metrics: 0.2475 - val_loss: 0.7575 - val_accuracy: 0.1622 - val_f1_score_metrics: 0.2664\nEpoch 2/15\n66/66 [==============================] - 5s 77ms/step - loss: 0.6994 - accuracy: 0.4611 - f1_score_metrics: 0.2398 - val_loss: 0.6805 - val_accuracy: 0.8277 - val_f1_score_metrics: 0.0108\nEpoch 3/15\n66/66 [==============================] - 4s 58ms/step - loss: 0.6955 - accuracy: 0.4923 - f1_score_metrics: 0.2400 - val_loss: 0.6487 - val_accuracy: 0.8454 - val_f1_score_metrics: 0.0000e+00\nEpoch 4/15\n66/66 [==============================] - 4s 53ms/step - loss: 0.6956 - accuracy: 0.5583 - f1_score_metrics: 0.2273 - val_loss: 0.7097 - val_accuracy: 0.2956 - val_f1_score_metrics: 0.2528\nEpoch 5/15\n66/66 [==============================] - 4s 58ms/step - loss: 0.6921 - accuracy: 0.4954 - f1_score_metrics: 0.2598 - val_loss: 0.6978 - val_accuracy: 0.3825 - val_f1_score_metrics: 0.2547\nEpoch 6/15\n66/66 [==============================] - 3s 51ms/step - loss: 0.6917 - accuracy: 0.5072 - f1_score_metrics: 0.2602 - val_loss: 0.6570 - val_accuracy: 0.8454 - val_f1_score_metrics: 0.0000e+00\nEpoch 7/15\n66/66 [==============================] - 3s 49ms/step - loss: 0.6902 - accuracy: 0.5364 - f1_score_metrics: 0.2643 - val_loss: 0.6623 - val_accuracy: 0.8125 - val_f1_score_metrics: 0.3125\nEpoch 8/15\n66/66 [==============================] - 3s 51ms/step - loss: 0.6866 - accuracy: 0.5117 - f1_score_metrics: 0.2732 - val_loss: 0.6267 - val_accuracy: 0.8489 - val_f1_score_metrics: 0.0970\nEpoch 9/15\n66/66 [==============================] - 3s 53ms/step - loss: 0.6853 - accuracy: 0.5694 - f1_score_metrics: 0.2628 - val_loss: 0.6908 - val_accuracy: 0.4558 - val_f1_score_metrics: 0.2925\nEpoch 10/15\n66/66 [==============================] - 3s 51ms/step - loss: 0.6739 - accuracy: 0.5933 - f1_score_metrics: 0.3008 - val_loss: 0.6256 - val_accuracy: 0.8125 - val_f1_score_metrics: 0.3891\nEpoch 11/15\n66/66 [==============================] - 3s 53ms/step - loss: 0.6666 - accuracy: 0.6213 - f1_score_metrics: 0.3139 - val_loss: 0.6863 - val_accuracy: 0.5447 - val_f1_score_metrics: 0.3497\nEpoch 12/15\n66/66 [==============================] - 3s 52ms/step - loss: 0.6469 - accuracy: 0.6412 - f1_score_metrics: 0.3401 - val_loss: 0.6361 - val_accuracy: 0.6837 - val_f1_score_metrics: 0.4030\nEpoch 13/15\n66/66 [==============================] - 3s 52ms/step - loss: 0.6398 - accuracy: 0.6457 - f1_score_metrics: 0.3507 - val_loss: 0.6011 - val_accuracy: 0.7312 - val_f1_score_metrics: 0.4140\nEpoch 14/15\n66/66 [==============================] - 3s 52ms/step - loss: 0.6220 - accuracy: 0.6586 - f1_score_metrics: 0.3717 - val_loss: 0.5229 - val_accuracy: 0.8135 - val_f1_score_metrics: 0.4384\nEpoch 15/15\n66/66 [==============================] - 3s 49ms/step - loss: 0.6031 - accuracy: 0.6854 - f1_score_metrics: 0.3931 - val_loss: 0.5721 - val_accuracy: 0.7357 - val_f1_score_metrics: 0.4556\n31/31 [==============================] - 1s 5ms/step\n              precision    recall  f1-score   support\n\n           0       0.93      0.75      0.83       821\n           1       0.35      0.72      0.47       154\n\n    accuracy                           0.74       975\n   macro avg       0.64      0.73      0.65       975\nweighted avg       0.84      0.74      0.77       975\n\nTotal predictions:  319\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4.Blaise's model","metadata":{}},{"cell_type":"code","source":"prefix='blaise'\nneural='bilstm'\nembedding='glove'\narchitecture='siamese'\ndistance='euclidean'\nmodel_name=prefix+'_'+neural+'_'+embedding+'_'+architecture+'_'+distance\nprint(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:50:53.052629Z","iopub.execute_input":"2024-06-26T15:50:53.053421Z","iopub.status.idle":"2024-06-26T15:50:53.059173Z","shell.execute_reply.started":"2024-06-26T15:50:53.053385Z","shell.execute_reply":"2024-06-26T15:50:53.058158Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"blaise_bilstm_glove_siamese_euclidean\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define input layers for 'document' and 'topic'\ndocument_input = Input(shape=(1,), dtype=tf.string, name='document_input')\ntopic_input = Input(shape=(1,), dtype=tf.string, name='topic_input')\n\n# Use the tokenizer for each type\ndocument_tokens = doc_vectorizer(document_input)\ntopic_tokens = topic_vectorizer(topic_input)\n\narticles_embedded = tf.keras.layers.Embedding(input_dim=len(doc_vocab),output_dim=300,\n                             weights=[doc_embedding],trainable=True,mask_zero=True)(document_tokens)\nqueries_embedded = tf.keras.layers.Embedding(input_dim=len(topic_vocab),output_dim=300,\n                                       weights=[topic_embedding],trainable=True,mask_zero=True)(topic_tokens)\n\n# concatenate the embeddings and remove the extra dimensions\ndistance=Lambda(euclidean_distance)([articles_embedded,queries_embedded])\n\n# add an LSTM layer\nlstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,return_sequences=True,dropout=0.6))(distance)\nlstm2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,dropout=0.4))(lstm1)\n\n# add a single output layer\nout = tf.keras.layers.Dense(1,activation=\"sigmoid\")(lstm2)\n\nmodel_bidirectional = tf.keras.Model(inputs=[document_input,topic_input],outputs=[out])","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:01:03.525863Z","iopub.execute_input":"2024-06-26T16:01:03.526784Z","iopub.status.idle":"2024-06-26T16:01:04.653423Z","shell.execute_reply.started":"2024-06-26T16:01:03.526750Z","shell.execute_reply":"2024-06-26T16:01:04.652615Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"model_training.compile_model(model, model_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:01:08.954758Z","iopub.execute_input":"2024-06-26T16:01:08.955649Z","iopub.status.idle":"2024-06-26T16:01:09.102234Z","shell.execute_reply.started":"2024-06-26T16:01:08.955617Z","shell.execute_reply":"2024-06-26T16:01:09.101112Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stdout","text":"Model: \"model_15\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n document_input (InputLayer  [(None, 1)]                  0         []                            \n )                                                                                                \n                                                                                                  \n topic_input (InputLayer)    [(None, 1)]                  0         []                            \n                                                                                                  \n text_vectorization_1 (Text  (None, 500)                  0         ['document_input[0][0]']      \n Vectorization)                                                                                   \n                                                                                                  \n text_vectorization (TextVe  (None, 500)                  0         ['topic_input[0][0]']         \n ctorization)                                                                                     \n                                                                                                  \n embedding_20 (Embedding)    (None, 500, 300)             1500000   ['text_vectorization_1[17][0]'\n                                                                    ]                             \n                                                                                                  \n embedding_21 (Embedding)    (None, 500, 300)             150000    ['text_vectorization[3][0]']  \n                                                                                                  \n lambda_3 (Lambda)           (None, 1, 300)               0         ['embedding_20[0][0]',        \n                                                                     'embedding_21[0][0]']        \n                                                                                                  \n bidirectional_6 (Bidirecti  (None, 1, 128)               186880    ['lambda_3[0][0]']            \n onal)                                                                                            \n                                                                                                  \n dense_38 (Dense)            (None, 1, 32)                4128      ['bidirectional_6[0][0]']     \n                                                                                                  \n dense_39 (Dense)            (None, 1, 1)                 33        ['dense_38[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 1841041 (7.02 MB)\nTrainable params: 1841041 (7.02 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_training.train_model(model, model_name,\n                           [X_train_doc,X_train_topic], y_train,\n                           [X_val_doc, X_val_topic], y_val,\n                           [X_test_doc, X_test_topic], y_test,\n                           epochs=60\n                           )","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:03:07.430549Z","iopub.execute_input":"2024-06-26T16:03:07.431468Z","iopub.status.idle":"2024-06-26T16:06:31.810422Z","shell.execute_reply.started":"2024-06-26T16:03:07.431435Z","shell.execute_reply":"2024-06-26T16:06:31.809512Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"Epoch 1/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.4174 - accuracy: 0.7898 - f1_score_metrics: 0.5564 - val_loss: 0.4055 - val_accuracy: 0.8014 - val_f1_score_metrics: 0.5305\nEpoch 2/60\n66/66 [==============================] - 3s 48ms/step - loss: 0.4099 - accuracy: 0.7992 - f1_score_metrics: 0.5639 - val_loss: 0.3821 - val_accuracy: 0.8221 - val_f1_score_metrics: 0.5506\nEpoch 3/60\n66/66 [==============================] - 3s 46ms/step - loss: 0.4081 - accuracy: 0.7987 - f1_score_metrics: 0.5633 - val_loss: 0.3921 - val_accuracy: 0.8181 - val_f1_score_metrics: 0.5490\nEpoch 4/60\n66/66 [==============================] - 3s 47ms/step - loss: 0.3988 - accuracy: 0.8078 - f1_score_metrics: 0.5778 - val_loss: 0.4436 - val_accuracy: 0.7782 - val_f1_score_metrics: 0.5234\nEpoch 5/60\n66/66 [==============================] - 3s 46ms/step - loss: 0.3979 - accuracy: 0.8051 - f1_score_metrics: 0.5764 - val_loss: 0.3638 - val_accuracy: 0.8378 - val_f1_score_metrics: 0.5710\nEpoch 6/60\n66/66 [==============================] - 3s 46ms/step - loss: 0.3957 - accuracy: 0.8106 - f1_score_metrics: 0.5801 - val_loss: 0.4311 - val_accuracy: 0.7883 - val_f1_score_metrics: 0.5257\nEpoch 7/60\n66/66 [==============================] - 3s 47ms/step - loss: 0.3990 - accuracy: 0.8061 - f1_score_metrics: 0.5735 - val_loss: 0.4122 - val_accuracy: 0.8065 - val_f1_score_metrics: 0.5389\nEpoch 8/60\n66/66 [==============================] - 3s 47ms/step - loss: 0.3830 - accuracy: 0.8119 - f1_score_metrics: 0.5867 - val_loss: 0.3483 - val_accuracy: 0.8489 - val_f1_score_metrics: 0.5732\nEpoch 9/60\n66/66 [==============================] - 3s 47ms/step - loss: 0.3869 - accuracy: 0.8167 - f1_score_metrics: 0.5916 - val_loss: 0.3848 - val_accuracy: 0.8226 - val_f1_score_metrics: 0.5550\nEpoch 10/60\n66/66 [==============================] - 3s 48ms/step - loss: 0.3908 - accuracy: 0.8095 - f1_score_metrics: 0.5823 - val_loss: 0.4006 - val_accuracy: 0.8095 - val_f1_score_metrics: 0.5378\nEpoch 11/60\n66/66 [==============================] - 3s 47ms/step - loss: 0.3844 - accuracy: 0.8120 - f1_score_metrics: 0.5817 - val_loss: 0.4487 - val_accuracy: 0.7797 - val_f1_score_metrics: 0.5255\nEpoch 12/60\n66/66 [==============================] - 3s 48ms/step - loss: 0.3793 - accuracy: 0.8161 - f1_score_metrics: 0.5942 - val_loss: 0.4056 - val_accuracy: 0.8085 - val_f1_score_metrics: 0.5423\nEpoch 13/60\n66/66 [==============================] - 3s 46ms/step - loss: 0.3806 - accuracy: 0.8162 - f1_score_metrics: 0.5896 - val_loss: 0.4169 - val_accuracy: 0.7989 - val_f1_score_metrics: 0.5325\nEpoch 14/60\n66/66 [==============================] - 3s 47ms/step - loss: 0.3734 - accuracy: 0.8237 - f1_score_metrics: 0.6010 - val_loss: 0.3885 - val_accuracy: 0.8231 - val_f1_score_metrics: 0.5582\nEpoch 15/60\n66/66 [==============================] - 3s 47ms/step - loss: 0.3707 - accuracy: 0.8234 - f1_score_metrics: 0.6006 - val_loss: 0.3579 - val_accuracy: 0.8378 - val_f1_score_metrics: 0.5727\nEpoch 16/60\n66/66 [==============================] - 3s 52ms/step - loss: 0.3622 - accuracy: 0.8173 - f1_score_metrics: 0.5982 - val_loss: 0.3610 - val_accuracy: 0.8388 - val_f1_score_metrics: 0.5705\nEpoch 17/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3593 - accuracy: 0.8269 - f1_score_metrics: 0.6083 - val_loss: 0.3922 - val_accuracy: 0.8186 - val_f1_score_metrics: 0.5571\nEpoch 18/60\n66/66 [==============================] - 3s 52ms/step - loss: 0.3635 - accuracy: 0.8189 - f1_score_metrics: 0.6021 - val_loss: 0.4046 - val_accuracy: 0.8065 - val_f1_score_metrics: 0.5435\nEpoch 19/60\n66/66 [==============================] - 3s 51ms/step - loss: 0.3557 - accuracy: 0.8246 - f1_score_metrics: 0.6121 - val_loss: 0.4017 - val_accuracy: 0.8100 - val_f1_score_metrics: 0.5505\nEpoch 20/60\n66/66 [==============================] - 3s 47ms/step - loss: 0.3568 - accuracy: 0.8232 - f1_score_metrics: 0.6089 - val_loss: 0.3873 - val_accuracy: 0.8231 - val_f1_score_metrics: 0.5593\nEpoch 21/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3645 - accuracy: 0.8252 - f1_score_metrics: 0.6066 - val_loss: 0.3760 - val_accuracy: 0.8287 - val_f1_score_metrics: 0.5653\nEpoch 22/60\n66/66 [==============================] - 3s 53ms/step - loss: 0.3532 - accuracy: 0.8314 - f1_score_metrics: 0.6155 - val_loss: 0.4055 - val_accuracy: 0.8125 - val_f1_score_metrics: 0.5546\nEpoch 23/60\n66/66 [==============================] - 3s 52ms/step - loss: 0.3545 - accuracy: 0.8278 - f1_score_metrics: 0.6136 - val_loss: 0.3876 - val_accuracy: 0.8247 - val_f1_score_metrics: 0.5647\nEpoch 24/60\n66/66 [==============================] - 3s 51ms/step - loss: 0.3537 - accuracy: 0.8222 - f1_score_metrics: 0.6046 - val_loss: 0.3887 - val_accuracy: 0.8226 - val_f1_score_metrics: 0.5641\nEpoch 25/60\n66/66 [==============================] - 4s 54ms/step - loss: 0.3499 - accuracy: 0.8303 - f1_score_metrics: 0.6179 - val_loss: 0.4348 - val_accuracy: 0.7959 - val_f1_score_metrics: 0.5391\nEpoch 26/60\n66/66 [==============================] - 3s 52ms/step - loss: 0.3537 - accuracy: 0.8250 - f1_score_metrics: 0.6096 - val_loss: 0.3984 - val_accuracy: 0.8130 - val_f1_score_metrics: 0.5554\nEpoch 27/60\n66/66 [==============================] - 3s 52ms/step - loss: 0.3455 - accuracy: 0.8307 - f1_score_metrics: 0.6173 - val_loss: 0.3512 - val_accuracy: 0.8479 - val_f1_score_metrics: 0.5850\nEpoch 28/60\n66/66 [==============================] - 3s 50ms/step - loss: 0.3493 - accuracy: 0.8292 - f1_score_metrics: 0.6126 - val_loss: 0.3948 - val_accuracy: 0.8176 - val_f1_score_metrics: 0.5563\nEpoch 29/60\n66/66 [==============================] - 3s 52ms/step - loss: 0.3491 - accuracy: 0.8301 - f1_score_metrics: 0.6183 - val_loss: 0.4241 - val_accuracy: 0.7964 - val_f1_score_metrics: 0.5386\nEpoch 30/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3430 - accuracy: 0.8291 - f1_score_metrics: 0.6173 - val_loss: 0.3829 - val_accuracy: 0.8277 - val_f1_score_metrics: 0.5691\nEpoch 31/60\n66/66 [==============================] - 3s 53ms/step - loss: 0.3416 - accuracy: 0.8325 - f1_score_metrics: 0.6208 - val_loss: 0.4062 - val_accuracy: 0.8151 - val_f1_score_metrics: 0.5578\nEpoch 32/60\n66/66 [==============================] - 3s 50ms/step - loss: 0.3395 - accuracy: 0.8328 - f1_score_metrics: 0.6231 - val_loss: 0.3756 - val_accuracy: 0.8368 - val_f1_score_metrics: 0.5813\nEpoch 33/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3305 - accuracy: 0.8368 - f1_score_metrics: 0.6274 - val_loss: 0.4074 - val_accuracy: 0.8201 - val_f1_score_metrics: 0.5628\nEpoch 34/60\n66/66 [==============================] - 3s 51ms/step - loss: 0.3321 - accuracy: 0.8394 - f1_score_metrics: 0.6327 - val_loss: 0.4108 - val_accuracy: 0.8065 - val_f1_score_metrics: 0.5464\nEpoch 35/60\n66/66 [==============================] - 3s 52ms/step - loss: 0.3299 - accuracy: 0.8340 - f1_score_metrics: 0.6268 - val_loss: 0.3774 - val_accuracy: 0.8307 - val_f1_score_metrics: 0.5719\nEpoch 36/60\n66/66 [==============================] - 3s 50ms/step - loss: 0.3409 - accuracy: 0.8373 - f1_score_metrics: 0.6293 - val_loss: 0.3983 - val_accuracy: 0.8236 - val_f1_score_metrics: 0.5637\nEpoch 37/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3276 - accuracy: 0.8378 - f1_score_metrics: 0.6302 - val_loss: 0.3947 - val_accuracy: 0.8252 - val_f1_score_metrics: 0.5653\nEpoch 38/60\n66/66 [==============================] - 3s 51ms/step - loss: 0.3286 - accuracy: 0.8362 - f1_score_metrics: 0.6299 - val_loss: 0.3794 - val_accuracy: 0.8338 - val_f1_score_metrics: 0.5753\nEpoch 39/60\n66/66 [==============================] - 3s 50ms/step - loss: 0.3254 - accuracy: 0.8387 - f1_score_metrics: 0.6339 - val_loss: 0.3967 - val_accuracy: 0.8206 - val_f1_score_metrics: 0.5636\nEpoch 40/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3259 - accuracy: 0.8383 - f1_score_metrics: 0.6327 - val_loss: 0.4159 - val_accuracy: 0.8080 - val_f1_score_metrics: 0.5501\nEpoch 41/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3282 - accuracy: 0.8357 - f1_score_metrics: 0.6304 - val_loss: 0.4063 - val_accuracy: 0.8075 - val_f1_score_metrics: 0.5479\nEpoch 42/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3263 - accuracy: 0.8377 - f1_score_metrics: 0.6318 - val_loss: 0.4068 - val_accuracy: 0.8125 - val_f1_score_metrics: 0.5541\nEpoch 43/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3248 - accuracy: 0.8376 - f1_score_metrics: 0.6326 - val_loss: 0.3977 - val_accuracy: 0.8171 - val_f1_score_metrics: 0.5583\nEpoch 44/60\n66/66 [==============================] - 3s 51ms/step - loss: 0.3281 - accuracy: 0.8373 - f1_score_metrics: 0.6315 - val_loss: 0.4572 - val_accuracy: 0.7787 - val_f1_score_metrics: 0.5230\nEpoch 45/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3189 - accuracy: 0.8380 - f1_score_metrics: 0.6338 - val_loss: 0.3714 - val_accuracy: 0.8327 - val_f1_score_metrics: 0.5748\nEpoch 46/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3224 - accuracy: 0.8430 - f1_score_metrics: 0.6411 - val_loss: 0.4235 - val_accuracy: 0.8039 - val_f1_score_metrics: 0.5451\nEpoch 47/60\n66/66 [==============================] - 3s 50ms/step - loss: 0.3192 - accuracy: 0.8424 - f1_score_metrics: 0.6403 - val_loss: 0.4289 - val_accuracy: 0.7994 - val_f1_score_metrics: 0.5396\nEpoch 48/60\n66/66 [==============================] - 3s 51ms/step - loss: 0.3123 - accuracy: 0.8486 - f1_score_metrics: 0.6508 - val_loss: 0.3909 - val_accuracy: 0.8257 - val_f1_score_metrics: 0.5694\nEpoch 49/60\n66/66 [==============================] - 3s 51ms/step - loss: 0.3165 - accuracy: 0.8425 - f1_score_metrics: 0.6385 - val_loss: 0.3957 - val_accuracy: 0.8231 - val_f1_score_metrics: 0.5659\nEpoch 50/60\n66/66 [==============================] - 3s 53ms/step - loss: 0.3169 - accuracy: 0.8431 - f1_score_metrics: 0.6430 - val_loss: 0.3806 - val_accuracy: 0.8262 - val_f1_score_metrics: 0.5672\nEpoch 51/60\n66/66 [==============================] - 3s 51ms/step - loss: 0.3064 - accuracy: 0.8494 - f1_score_metrics: 0.6515 - val_loss: 0.3909 - val_accuracy: 0.8257 - val_f1_score_metrics: 0.5676\nEpoch 52/60\n66/66 [==============================] - 4s 56ms/step - loss: 0.3076 - accuracy: 0.8491 - f1_score_metrics: 0.6504 - val_loss: 0.3665 - val_accuracy: 0.8413 - val_f1_score_metrics: 0.5795\nEpoch 53/60\n66/66 [==============================] - 4s 54ms/step - loss: 0.3143 - accuracy: 0.8441 - f1_score_metrics: 0.6432 - val_loss: 0.4187 - val_accuracy: 0.8044 - val_f1_score_metrics: 0.5453\nEpoch 54/60\n66/66 [==============================] - 3s 52ms/step - loss: 0.3084 - accuracy: 0.8451 - f1_score_metrics: 0.6463 - val_loss: 0.3861 - val_accuracy: 0.8267 - val_f1_score_metrics: 0.5686\nEpoch 55/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3094 - accuracy: 0.8474 - f1_score_metrics: 0.6460 - val_loss: 0.4092 - val_accuracy: 0.8176 - val_f1_score_metrics: 0.5589\nEpoch 56/60\n66/66 [==============================] - 3s 47ms/step - loss: 0.3042 - accuracy: 0.8443 - f1_score_metrics: 0.6460 - val_loss: 0.3631 - val_accuracy: 0.8444 - val_f1_score_metrics: 0.5865\nEpoch 57/60\n66/66 [==============================] - 3s 46ms/step - loss: 0.3092 - accuracy: 0.8494 - f1_score_metrics: 0.6526 - val_loss: 0.4047 - val_accuracy: 0.8146 - val_f1_score_metrics: 0.5562\nEpoch 58/60\n66/66 [==============================] - 3s 52ms/step - loss: 0.3068 - accuracy: 0.8434 - f1_score_metrics: 0.6414 - val_loss: 0.4033 - val_accuracy: 0.8171 - val_f1_score_metrics: 0.5590\nEpoch 59/60\n66/66 [==============================] - 3s 49ms/step - loss: 0.3071 - accuracy: 0.8454 - f1_score_metrics: 0.6450 - val_loss: 0.3902 - val_accuracy: 0.8262 - val_f1_score_metrics: 0.5695\nEpoch 60/60\n66/66 [==============================] - 3s 51ms/step - loss: 0.3072 - accuracy: 0.8472 - f1_score_metrics: 0.6484 - val_loss: 0.3828 - val_accuracy: 0.8332 - val_f1_score_metrics: 0.5734\n31/31 [==============================] - 0s 5ms/step\n              precision    recall  f1-score   support\n\n           0       0.93      0.84      0.88       821\n           1       0.44      0.69      0.54       154\n\n    accuracy                           0.81       975\n   macro avg       0.69      0.76      0.71       975\nweighted avg       0.86      0.81      0.83       975\n\nTotal predictions:  240\n","output_type":"stream"}]},{"cell_type":"code","source":"results_dict= model_training.dl_results\n# Convert the dictionary to a pandas DataFrame\ndf_results = pd.DataFrame.from_dict(results_dict, orient='index', columns=['accuracy', 'precision', 'recall', 'f1', 'pred_count'])\n\n# Reset the index to move model names into a column\ndf_results.reset_index(inplace=True)\ndf_results.rename(columns={'index': 'model_name'}, inplace=True)\n\n# Display the DataFrame\nprint(df_results)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:09:27.215030Z","iopub.execute_input":"2024-06-26T16:09:27.215831Z","iopub.status.idle":"2024-06-26T16:09:27.227277Z","shell.execute_reply.started":"2024-06-26T16:09:27.215795Z","shell.execute_reply":"2024-06-26T16:09:27.226266Z"},"trusted":true},"execution_count":132,"outputs":[{"name":"stdout","text":"                              model_name  accuracy  precision    recall  \\\n0                                dense__  0.856410   0.553846  0.467532   \n1                           dense_GloVe_  0.823590   0.446429  0.487013   \n2                            LSTM_GloVe_  0.807179   0.415000  0.538961   \n3         bilstm_glove_siamese_euclidean  0.742564   0.347962  0.720779   \n4  blaise_bilstm_glove_siamese_euclidean  0.813333   0.441667  0.688312   \n\n         f1  pred_count  \n0  0.507042         130  \n1  0.465839         168  \n2  0.468927         200  \n3  0.469345         319  \n4  0.538071         240  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5.Loading pretrained models for reusability","metadata":{"id":"pJg8rvxz0SUw"}},{"cell_type":"code","source":"# @title\nfrom tensorflow.keras.models import load_model\n\n# Function to load and make predictions for a single model\nCNN_glove_model = load_model('/kaggle/input/trained-model/CNN_glove',\n                       custom_objects={'f1_score_metrics': f1_score_metrics})\nDense_glove_model = load_model('/kaggle/input/trained-model/Dense_GloVe',\n                       custom_objects={'f1_score_metrics': f1_score_metrics})\nDense_NN_model = load_model('/kaggle/input/trained-model/Dense_NN',\n                       custom_objects={'f1_score_metrics': f1_score_metrics})\nbilstm_glove_model = load_model('/kaggle/input/trained-model/bilstm_GloVe',\n                       custom_objects={'f1_score_metrics': f1_score_metrics})\nbilstm_euclid_glove_model = load_model('/kaggle/input/trained-model/bilstm_euclid_glove',\n                       custom_objects={'f1_score_metrics': f1_score_metrics})\nlstm_glove_model = load_model('/kaggle/input/trained-model/lstm_GloVe',\n                       custom_objects={'f1_score_metrics': f1_score_metrics})\nsiamese_glove_cosine_model = load_model('/kaggle/input/trained-model/siamese_glove_cosine',\n                       custom_objects={'auroc': auroc})\ntest_pred = CNN_glove_model.predict([X_test_doc, X_test_topic]).flatten()\ndl_metrics(test_pred,y_test, 'CNN_glove')\ntest_pred = Dense_glove_model.predict(X_test_concat).flatten()\ndl_metrics(test_pred,y_test, 'Dense_glove')\ntest_pred = Dense_NN_model.predict(X_test_concat).flatten()\ndl_metrics(test_pred,y_test, 'Dense_NN')\ntest_pred = bilstm_glove_model.predict(X_test_concat).flatten()\ndl_metrics(test_pred,y_test, 'bilstm_glove')\ntest_pred = lstm_glove_model.predict(X_test_concat).flatten()\ndl_metrics(test_pred,y_test, 'lstm_glove')\ntest_pred = siamese_glove_cosine_model.predict([X_test_doc, X_test_topic]).flatten()\ndl_metrics(test_pred,y_test, 'siamese_glove_cosine')\ntest_pred = bilstm_euclid_glove_model.predict([X_test_doc, X_test_topic]).flatten()\ndl_metrics(test_pred,y_test, 'bilstm_euclid_glove')\n\n# Convert the dictionary into a pandas DataFrame\ndl_results_df = pd.DataFrame.from_dict(dl_results,\n                                    orient='index',\n                                    columns=['accuracy','precision','recall','f1_core','count_predictions'])\n# Display the results as a table\nprint(\"Model Performance Comparison:\")\ndl_results_df","metadata":{"id":"LgSS0jnc5OmL","outputId":"77179754-25bf-42f4-fb34-02803d1d77f5","execution":{"iopub.status.busy":"2024-06-26T15:48:29.563416Z","iopub.status.idle":"2024-06-26T15:48:29.563747Z","shell.execute_reply.started":"2024-06-26T15:48:29.563585Z","shell.execute_reply":"2024-06-26T15:48:29.563600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title\nimport os\nimport pickle\nimport matplotlib.pyplot as plt\n\n# Directory containing pickle files\ndirectory = '/kaggle/input/trained-model'\n\n# List of pickle files\npickle_files = [\n    \"cnn_history.pkl\",\n    \"glove_bilstm_euclid_history.pkl\",\n    \"simese_glove_cosine_history.pkl\"\n]\n\n# Plot validation loss\nplt.figure(figsize=(10, 5))  # Adjust figure size if needed\nfor file in pickle_files:\n    filepath = os.path.join(directory, file)\n    with open(filepath, 'rb') as f:\n        history = pickle.load(f)\n\n    # Extract validation loss values\n    val_loss = history['val_loss']\n\n    # Plot validation loss\n    plt.plot(val_loss, label=file)\n\n# Set labels and legend\nplt.title('Validation Loss Value Over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Validation Loss')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n# Plot training loss\nplt.figure(figsize=(10, 5))  # Adjust figure size if needed\nfor file in pickle_files:\n    filepath = os.path.join(directory, file)\n    with open(filepath, 'rb') as f:\n        history = pickle.load(f)\n\n    # Extract training loss values\n    loss = history['loss']\n\n    # Plot training loss\n    plt.plot(loss, label=file)\n\n# Set labels and legend\nplt.title('Training Loss Value Over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Training Loss')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"id":"c6kwvgw45OmM","outputId":"80cd9715-f5eb-445a-fc0a-ed9de5794dc0","execution":{"iopub.status.busy":"2024-06-26T15:48:29.564922Z","iopub.status.idle":"2024-06-26T15:48:29.565285Z","shell.execute_reply.started":"2024-06-26T15:48:29.565103Z","shell.execute_reply":"2024-06-26T15:48:29.565123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title\n# Compute precision and recall for different thresholds\nprecision, recall, thresholds = precision_recall_curve(y_test, test_pred)\n\n# Initialize lists to store F1 scores\nf1_scores = []\n\n# Compute F1 scores for each threshold\nfor i in range(len(thresholds)):\n    # Compute F1 score\n    f1 = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i] + 1e-5)  # Adding a small value to avoid division by zero\n    f1_scores.append(f1)\n\n# Plot F1 scores\nplt.plot(thresholds, f1_scores, marker='.')\nplt.xlabel('Threshold')\nplt.ylabel('F1 Score')\nplt.title('F1 Score vs. Threshold')\nplt.grid(True)\nplt.show()\n# Initialize variables to store optimal values\noptimal_threshold = None\noptimal_f1_score = -1\n\n# Iterate over each threshold and calculate F1 score\nfor i in range(len(thresholds)):\n    threshold = thresholds[i]\n    y_pred = (test_pred >= threshold).astype(int)\n    f1 = f1_score(y_test, y_pred)\n    if f1 > optimal_f1_score:\n        optimal_f1_score = f1\n        optimal_threshold = threshold\n\nprint(\"Optimal Threshold:\", optimal_threshold)\nprint(\"Optimal F1 Score:\", optimal_f1_score)","metadata":{"id":"Me8gTO5TEJLf","outputId":"b8241ad1-4fae-4207-ec24-27ebbae9c83f","execution":{"iopub.status.busy":"2024-06-26T15:48:29.566934Z","iopub.status.idle":"2024-06-26T15:48:29.567276Z","shell.execute_reply.started":"2024-06-26T15:48:29.567086Z","shell.execute_reply":"2024-06-26T15:48:29.567118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#References\n\n\"Developing and Evaluating Siamese Neural Networks: A Comprehensive Guide to Architecture\" by Dr. Isaac Faber. Available at: Medium\n\nGloVe: Global Vectors for Word Representation by Jeffrey Pennington, Richard Socher, and Christopher D. Manning. Available at: Stanford NLP\n\n\"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\" by Nils Reimers and Iryna Gurevych. Available at: arXiv\n\n\"Siamese Neural Networks for One-shot Image Recognition\" by Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov. Available at: SpringerLink\n\n\"Bert-based Siamese Network for Semantic Similarity\" by Z Yan, H Wu, X Li, and Z Jiao. Available at: IOPscience\n\nGitHub repository by Rafal Jan Wojcik comparing SentenceBERT vs. Siamese LSTM. Available at: GitHub\n\nGitHub repository for the Sentence Transformers library by UKPLab. Available at: GitHub","metadata":{"id":"ZAQIUKP6yzhF"}}]}