{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9012001,"sourceType":"datasetVersion","datasetId":5429851},{"sourceId":9062110,"sourceType":"datasetVersion","datasetId":5465014}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shutil\nimport os\n\n# Remove the directory if already exist \ndir_name = 'neural_medical_qa'\nif os.path.exists(dir_name):\n    shutil.rmtree(dir_name)\n\n#clone the repo from github\n!git clone https://github.com/trduc97/neural_medical_qa.git\n%cd neural_medical_qa\n# install the requirement\n!pip install -r requirements.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T03:27:41.047289Z","iopub.execute_input":"2024-08-05T03:27:41.047626Z","iopub.status.idle":"2024-08-05T03:27:57.715662Z","shell.execute_reply.started":"2024-08-05T03:27:41.047600Z","shell.execute_reply":"2024-08-05T03:27:57.714626Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'neural_medical_qa'...\nremote: Enumerating objects: 126, done.\u001b[K\nremote: Counting objects: 100% (126/126), done.\u001b[K\nremote: Compressing objects: 100% (119/119), done.\u001b[K\nremote: Total 126 (delta 58), reused 0 (delta 0), pack-reused 0\u001b[K\nReceiving objects: 100% (126/126), 1.79 MiB | 9.90 MiB/s, done.\nResolving deltas: 100% (58/58), done.\n/kaggle/working/neural_medical_qa\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.20.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->-r requirements.txt (line 1)) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.19.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets->-r requirements.txt (line 1)) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets->-r requirements.txt (line 1)) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 1)) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nfrom datasets import Dataset, DatasetDict, load_dataset\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\ndef load_bioasq_pubmedqa(bioasq_kaggle_path = '/kaggle/input/bioasq-training-12b/training12b_new.json', \n                         pubmed_kaggle_path='/kaggle/input/pubmed-qa/pubmed_qa_pga_labeled.parquet'):\n    # Load the JSON file\n    with open(bioasq_kaggle_path,'r') as f:\n        bioasq_data=json.load(f)\n    # Extract yes/no questions directly\n    bioasq_yesno = [{\n            'id':question['id'],\n            'question':question['body'],\n            'final_decision':question['exact_answer'],\n            'long_answer':question['ideal_answer'], \n            'documents':question['documents']\n        }\n        for question in bioasq_data['questions'] if question['type'] == 'yesno']\n    # Convert the list of yes/no questions to a Pandas DataFrame\n    bioasq_df = pd.DataFrame(bioasq_yesno)\n\n    # Convert the DataFrame to a Hugging Face Dataset\n    bioasq_dataset = Dataset.from_pandas(bioasq_df)\n    # Create a DatasetDict with the 'train' split\n    bioasq_data=DatasetDict({'train': bioasq_dataset})\n\n    # Read from parquet and translate to a dataset object\n    pubmed_df=pd.read_parquet(pubmed_kaggle_path)\n    dataset=Dataset.from_pandas(pubmed_df,preserve_index=False)\n    #Setting into similar format as from huggingface\n    pubmedqa_data = DatasetDict({'train': dataset})\n    \n    # Load the pubmedqa dataset\n    #pubmedqa_data=load_dataset(\"pubmed_qa\",\"pqa_labeled\") # unstable connection\n\n    #Encoding decisions \n    def decision_encode(question):\n        labels_map = {'no': 0, 'maybe': 1, 'yes': 2}\n        question['decision_encoded'] = labels_map[question['final_decision']]\n        return question\n\n    pubmedqa_data=pubmedqa_data.map(decision_encode)\n    bioasq_data=pubmedqa_data.map(decision_encode)\n\n    return bioasq_data, pubmedqa_data\n\n\ndef pubmed_train_test_split(datasetdict,train_size=0.75, \n                         strat_col='decision_encoded'):\n    #Convert dataset to pandas DataFrame\n    df = pd.DataFrame(datasetdict['train'])\n    test_size=(1-train_size)\n    # Define the stratification column\n    stratify_col=strat_col\n\n    #Split like normal\n    train_df, test_df = train_test_split(\n        df,\n        test_size=test_size,\n        stratify=df[stratify_col],\n        random_state=42)\n    # Convert DataFrames back to Dataset\n    train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n    test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n\n    return train_dataset, test_dataset\n\n\ndef train_val_test_split(datasetdict,train_size=0.75, \n                         val_test_ratio=0.6,\n                         strat_col='decision_encoded'):\n    #Convert dataset to pandas DataFrame\n    df = pd.DataFrame(datasetdict['train'])\n    test_size=(1-train_size)\n    # Define the stratification column\n    stratify_col=strat_col\n\n    #First, split for the train set\n    train_df, val_test_df = train_test_split(\n        df,\n        test_size=test_size,\n        stratify=df[stratify_col],\n        random_state=42)\n    #Then, split the remaining into validation and test\n    val_df, test_df = train_test_split(\n        val_test_df,\n        test_size=val_test_ratio,\n        stratify=val_test_df[stratify_col],\n        random_state=42)\n    # Convert DataFrames back to Dataset\n    train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n    val_dataset = Dataset.from_pandas(val_df, preserve_index=False)\n    test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n\n    return train_dataset, val_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:28:49.757650Z","iopub.execute_input":"2024-08-05T03:28:49.758530Z","iopub.status.idle":"2024-08-05T03:28:49.778661Z","shell.execute_reply.started":"2024-08-05T03:28:49.758496Z","shell.execute_reply":"2024-08-05T03:28:49.777409Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from import_datasets import load_bioasq_pubmedqa, train_test_split\n\nbioasq, pubmedqa = load_bioasq_pubmedqa()\n\n# Display the first few samples of the PubMedQA dataset\nprint(pubmedqa['train'].to_pandas().head())\n\nresponses = pubmedqa['train']['final_decision']\n# Counting the occurrences of each value\nyes_count = responses.count('yes')\nno_count = responses.count('no')\nmaybe_count = responses.count('maybe')\n\n# Display the counts\nprint(f\"Yes: {yes_count}\")\nprint(f\"No: {no_count}\")\nprint(f\"Maybe: {maybe_count}\")\n\npubmedqa_train, pubmedqa_test = pubmed_train_test_split(pubmedqa)\nprint(f\"Train size: {len(pubmedqa_train)}\")\nprint(f\"Test size: {len(pubmedqa_test)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:28:54.570277Z","iopub.execute_input":"2024-08-05T03:28:54.570635Z","iopub.status.idle":"2024-08-05T03:28:56.140176Z","shell.execute_reply.started":"2024-08-05T03:28:54.570607Z","shell.execute_reply":"2024-08-05T03:28:56.139183Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44463614789541a7bfc23d3f5cc7ee12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8c3098c42ea4e08b9e4dfdbb93f8bc0"}},"metadata":{}},{"name":"stdout","text":"      pubid                                           question  \\\n0  21645374  Do mitochondria play a role in remodelling lac...   \n1  16418930  Landolt C and snellen e acuity: differences in...   \n2   9488747  Syncope during bathing in infants, a pediatric...   \n3  17208539  Are the long-term results of the transanal pul...   \n4  10808977  Can tailored interventions increase mammograph...   \n\n                                             context  \\\n0  {'contexts': ['Programmed cell death (PCD) is ...   \n1  {'contexts': ['Assessment of visual acuity dep...   \n2  {'contexts': ['Apparent life-threatening event...   \n3  {'contexts': ['The transanal endorectal pull-t...   \n4  {'contexts': ['Telephone counseling and tailor...   \n\n                                         long_answer final_decision  \\\n0  Results depicted mitochondrial dynamics in viv...            yes   \n1  Using the charts described, there was only a s...             no   \n2  \"Aquagenic maladies\" could be a pediatric form...            yes   \n3  Our long-term study showed significantly bette...             no   \n4  The effects of the intervention were most pron...            yes   \n\n   decision_encoded  \n0                 2  \n1                 0  \n2                 2  \n3                 0  \n4                 2  \nYes: 552\nNo: 338\nMaybe: 110\nTrain size: 750\nTest size: 250\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import defaultdict\n# Initialize a defaultdict to hold the bucket counts\nlength_buckets = defaultdict(int)\n\n# Define the bucket size\nbucket_size = 128\n\n# Loop through each string in the list\nfor s in pubmedqa_train['long_answer']:\n    # Determine the bucket for the current string length\n    bucket = (len(s) // bucket_size) * bucket_size\n    # Increment the count for the appropriate bucket\n    length_buckets[bucket] += 1\n\n# Display the counts for each bucket\nfor bucket, count in sorted(length_buckets.items()):\n    print(f\"Length {bucket} - {bucket + bucket_size - 1}: {count} strings\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:28:59.651695Z","iopub.execute_input":"2024-08-05T03:28:59.652860Z","iopub.status.idle":"2024-08-05T03:28:59.662586Z","shell.execute_reply.started":"2024-08-05T03:28:59.652816Z","shell.execute_reply":"2024-08-05T03:28:59.661493Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Length 0 - 127: 66 strings\nLength 128 - 255: 326 strings\nLength 256 - 383: 244 strings\nLength 384 - 511: 82 strings\nLength 512 - 639: 25 strings\nLength 640 - 767: 4 strings\nLength 768 - 895: 3 strings\n","output_type":"stream"}]},{"cell_type":"code","source":"bioasq, pubmedqa_artificial = load_bioasq_pubmedqa(pubmed_kaggle_path='/kaggle/input/pubmed-qa/pubmed_qa_pga_artificial.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:29:05.505777Z","iopub.execute_input":"2024-08-05T03:29:05.506372Z","iopub.status.idle":"2024-08-05T03:30:01.508481Z","shell.execute_reply.started":"2024-08-05T03:29:05.506340Z","shell.execute_reply":"2024-08-05T03:30:01.507466Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/211269 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4430c67774834cabb7145a0c06e375da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/211269 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0c345f0c8104145abadfdaceeb56ecf"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, concatenate_datasets, DatasetDict\n\n# Convert to pandas DataFrame to handle schema mismatch\npubmedqa_df = pubmedqa['train'].to_pandas()\npubmedqa_artificial_df = pubmedqa_artificial['train'].to_pandas()\n# Ensure both DataFrames have the same columns\ncommon_columns = list(set(pubmedqa_df.columns).intersection(set(pubmedqa_artificial_df.columns)))\n\npubmedqa_df = pubmedqa_df[common_columns]\npubmedqa_artificial_df = pubmedqa_artificial_df[common_columns]\n\n# Take 1000 rows from each\npubmedqa_sample = pubmedqa_df.sample(n=1000, random_state=42)\npubmedqa_artificial_sample = pubmedqa_artificial_df.sample(n=1000, random_state=42)\n\n# Step 3: Combine the samples to create pubmed_mix\ncombined_df = pd.concat([pubmedqa_sample, pubmedqa_artificial_sample], ignore_index=True)\n\n# Step 4: Shuffle the combined DataFrame to mix the rows\npubmed_mix_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Step 5: Convert back to DatasetDict format\npubmed_mix = Dataset.from_pandas(pubmed_mix_df)\n\n# Create DatasetDict\npubmed_mix_dataset = DatasetDict({\n    'train': pubmed_mix\n})\n\n# Verify the structure\nprint(pubmed_mix_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:30:01.510759Z","iopub.execute_input":"2024-08-05T03:30:01.511136Z","iopub.status.idle":"2024-08-05T03:30:03.270318Z","shell.execute_reply.started":"2024-08-05T03:30:01.511087Z","shell.execute_reply":"2024-08-05T03:30:03.269401Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['final_decision', 'decision_encoded', 'question', 'context', 'pubid', 'long_answer'],\n        num_rows: 2000\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"pubmedqa_mix_train, pubmedqa_mix_test = pubmed_train_test_split(pubmed_mix_dataset)\nprint(f\"Train size: {len(pubmedqa_mix_train)}\")\nprint(f\"Test size: {len(pubmedqa_mix_test)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:30:03.271489Z","iopub.execute_input":"2024-08-05T03:30:03.271809Z","iopub.status.idle":"2024-08-05T03:30:03.683378Z","shell.execute_reply.started":"2024-08-05T03:30:03.271776Z","shell.execute_reply":"2024-08-05T03:30:03.682285Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Train size: 1500\nTest size: 500\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel, GPT2Tokenizer, GPT2Model\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n\nclass QAModel(nn.Module):\n    def __init__(self, model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # number of classes may vary between BioASQ (2 classes) and PubMedQA (3 classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nclass Trainandtest:\n\n    def __init__(self, df_train, df_test, stratify_col='decision_encoded'):\n        self.train_data = df_train\n        self.test_data = df_test\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.stratify_col = stratify_col\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.results={}\n\n    def initialize_tokenizer(self, model_name, source):\n        if isinstance(source, tuple):\n                source = source[0]\n        if 'GPT' in model_name:\n            tokenizer = GPT2Tokenizer.from_pretrained(source)\n            if tokenizer.pad_token is None:\n                tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n            return tokenizer\n        elif 'BioLinkBERT' in model_name or 'LinkBERT' in model_name:\n            return AutoTokenizer.from_pretrained(source)\n        else:\n            return BertTokenizer.from_pretrained(source)\n\n    def encode_data(self, df, tokenizer):\n        inputs = tokenizer(\n            text=df['question'], \n            text_pair=df['long_answer'], \n            padding=True, \n            truncation=True, \n            return_tensors='pt', \n            max_length=128*4\n        )\n        labels = torch.tensor(df[self.stratify_col])\n        return inputs, labels\n\n    def create_dataloader(self, inputs, labels, batch_size):\n        dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    def import_model(self, model_name, source, tokenizer):\n        if isinstance(source, tuple):\n            source = source[0]\n        if 'GPT' in model_name:\n            model = GPT2Model.from_pretrained(source)\n            model.resize_token_embeddings(len(tokenizer))\n            model = QAModel(model)\n        elif 'BioLinkBERT' in model_name or 'LinkBERT' in model_name:\n            model = AutoModel.from_pretrained(source)\n            model = QAModel(model)\n        else:\n            model = BertModel.from_pretrained(source)\n            model = QAModel(model)\n        return model\n    def model_compile(self, model_name, source, batch_size=64, adamw=True):\n        batch_size = 16 if 'GPT' in model_name else batch_size\n        tokenizer = self.initialize_tokenizer(model_name, source)\n        train_inputs, train_labels = self.encode_data(self.train_data, tokenizer)\n        test_inputs, test_labels = self.encode_data(self.test_data, tokenizer)\n        self.train_loader = self.create_dataloader(train_inputs, train_labels, batch_size)\n        self.test_loader = self.create_dataloader(test_inputs, test_labels, batch_size)\n        \n        self.model = self.import_model(model_name, source, tokenizer).to(self.device) \n        if adamw:\n            self.optimizer = optim.AdamW(self.model.parameters(), lr=2e-5)\n        else: \n            self.optimizer = optim.Adam(self.model.parameters(), lr=2e-5)\n    \n    def training(self, model_name, epochs=10):\n        if isinstance(model_name, tuple):\n            model_name = model_name[0]        \n        self.model.train()\n        for epoch in range(epochs):\n            total_loss = 0\n            all_preds = []\n            all_labels = []\n        \n            for batch in self.train_loader:\n                b_input_ids, b_attention_mask, b_labels = [t.to(self.device) for t in batch]\n                self.optimizer.zero_grad()\n            \n                outputs = self.model(b_input_ids, b_attention_mask)\n                loss = self.loss_fn(outputs, b_labels)\n                loss.backward()\n                self.optimizer.step()\n                \n                total_loss += loss.item()\n            \n                preds = outputs.detach().cpu().numpy()\n                label_ids = b_labels.to('cpu').numpy()\n                del b_input_ids \n                del b_attention_mask \n                del b_labels\n                gc.collect()\n                torch.cuda.empty_cache()\n                all_preds.append(preds)\n                all_labels.append(label_ids)\n        \n            avg_loss = total_loss / len(self.train_loader)\n            all_preds = np.concatenate(all_preds, axis=0)\n            all_labels = np.concatenate(all_labels, axis=0)\n            avg_f1_score = self.calculate_f1_score(all_preds, all_labels)\n        \n            print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n        \n        self.save_model(model_name)\n\n    def save_model(self, model_name):\n        os.makedirs('/kaggle/working/models', exist_ok=True)\n        model_path = f'/kaggle/working/models/{model_name}_model.pth'\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n        }, model_path)\n        print(f\"Model saved to {model_path}\")\n\n    def load_model(self, model_path):\n        checkpoint = torch.load(model_path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        print(f\"Model loaded from {model_path}\")\n\n    def calculate_f1_score(self, preds, labels):\n        preds_flat = np.argmax(preds, axis=1).flatten()\n        labels_flat = labels.flatten()\n        return f1_score(labels_flat, preds_flat, average='weighted')\n\n    def evaluate(self, dataloader):\n        self.model.eval()\n        total_loss = 0\n        predictions, true_labels = [], []\n    \n        with torch.no_grad():\n            for batch in dataloader:\n                b_input_ids, b_attention_mask, b_labels = [t.to(self.device) for t in batch]\n                outputs = self.model(b_input_ids, b_attention_mask)\n                logits = outputs.detach().cpu().numpy()\n                label_ids = b_labels.cpu().numpy()\n                predictions.extend(np.argmax(logits, axis=1))\n                true_labels.extend(label_ids)\n                del b_input_ids \n                del b_attention_mask \n                del b_labels\n                gc.collect()\n                torch.cuda.empty_cache()\n    \n        accuracy = accuracy_score(true_labels, predictions)\n        precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n        return accuracy, precision, recall, f1\n        \n\n    def val(self, load_model_path=None):\n        if load_model_path:\n            self.load_model(load_model_path)\n                \n        test_accuracy, test_precision, test_recall, test_f1 = self.evaluate(self.test_loader)\n        print(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")\n    \n        return {\n            'test': {\n                'accuracy': test_accuracy,\n                'precision': test_precision,\n                'recall': test_recall,\n                'f1': test_f1\n            }\n        }","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:30:03.685910Z","iopub.execute_input":"2024-08-05T03:30:03.686315Z","iopub.status.idle":"2024-08-05T03:30:08.323697Z","shell.execute_reply.started":"2024-08-05T03:30:03.686281Z","shell.execute_reply":"2024-08-05T03:30:08.322621Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"models = [\n    \n    {\n        'model_name': 'BERT',\n        'source': 'bert-base-uncased',\n    },\n    {\n        'model_name': 'GPT',\n        'source': 'gpt2',\n    },\n    {\n        'model_name': 'ColBERT',\n        'source': 'colbert-ir/colbertv2.0',\n    },\n\n    {\n        'model_name': 'LinkBERT',\n        'source': 'michiyasunaga/LinkBERT-base',\n    },\n    {\n        'model_name': 'BiomedNLP',\n        'source': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract',\n    },\n    {\n        'model_name': 'BioLinkBERT',\n        'source': 'michiyasunaga/BioLinkBERT-base',\n    },\n\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:30:42.751614Z","iopub.execute_input":"2024-08-05T03:30:42.752545Z","iopub.status.idle":"2024-08-05T03:30:42.758467Z","shell.execute_reply.started":"2024-08-05T03:30:42.752513Z","shell.execute_reply":"2024-08-05T03:30:42.757209Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"trainer = Trainandtest(pubmedqa_train, pubmedqa_test)\n\nfor model in models:\n    model_name=model['model_name'],\n    source=model['source'],\n    trainer.model_compile(model_name,source)\n    # Train the model\n    trainer.training(model_name, epochs=10)\n    \n    # test the model\n    test_result = trainer.val()\n    trainer.results[model['model_name']] = test_result","metadata":{"execution":{"iopub.status.busy":"2024-08-05T02:08:28.879499Z","iopub.execute_input":"2024-08-05T02:08:28.879897Z","iopub.status.idle":"2024-08-05T02:21:19.047031Z","shell.execute_reply.started":"2024-08-05T02:08:28.879859Z","shell.execute_reply":"2024-08-05T02:21:19.045609Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.9844380617141724, F1 Score: 0.451102100456621\nEpoch 2, Loss: 0.9382130602995554, F1 Score: 0.48689957230021924\nEpoch 3, Loss: 0.8745568990707397, F1 Score: 0.4878706680244128\nEpoch 4, Loss: 0.7442253679037094, F1 Score: 0.6828985274431058\nEpoch 5, Loss: 0.6305228173732758, F1 Score: 0.7394395187833391\nEpoch 6, Loss: 0.5366672997673353, F1 Score: 0.7673279708789403\nEpoch 7, Loss: 0.4447324052453041, F1 Score: 0.8041047471620227\nEpoch 8, Loss: 0.3756386563181877, F1 Score: 0.8379031285741234\nEpoch 9, Loss: 0.3128013958533605, F1 Score: 0.869524328521953\nEpoch 10, Loss: 0.24801820889115334, F1 Score: 0.8876733767126234\nModel saved to /kaggle/working/models/BERT_model.pth\nTest - Accuracy: 0.756, Precision: 0.7322769583103609, Recall: 0.756, F1-Score: 0.7432146154023473\nEpoch 1, Loss: 1.4042836820825617, F1 Score: 0.42090071953689334\nEpoch 2, Loss: 1.0755147274504318, F1 Score: 0.4217221361893262\nEpoch 3, Loss: 1.0375938935482756, F1 Score: 0.42722761789827207\nEpoch 4, Loss: 1.0293863643991186, F1 Score: 0.44418364418938305\nEpoch 5, Loss: 0.9916858305322364, F1 Score: 0.46666726587271873\nEpoch 6, Loss: 0.9940506346682285, F1 Score: 0.42483174603174606\nEpoch 7, Loss: 0.9867699957908468, F1 Score: 0.4390815792467857\nEpoch 8, Loss: 0.9789338644514692, F1 Score: 0.43131977896551127\nEpoch 9, Loss: 0.9836685657501221, F1 Score: 0.42790311921605145\nEpoch 10, Loss: 0.9636167376599414, F1 Score: 0.42711073137388933\nModel saved to /kaggle/working/models/GPT_model.pth\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Test - Accuracy: 0.552, Precision: 0.30470400000000003, Recall: 0.552, F1-Score: 0.392659793814433\nEpoch 1, Loss: 0.9800732036431631, F1 Score: 0.4655292470457658\nEpoch 2, Loss: 0.9360240449508032, F1 Score: 0.45662408362561036\nEpoch 3, Loss: 0.9092981467644373, F1 Score: 0.5078878350984526\nEpoch 4, Loss: 0.7796382904052734, F1 Score: 0.655855977887538\nEpoch 5, Loss: 0.6443670441706976, F1 Score: 0.7173714285714284\nEpoch 6, Loss: 0.5754364828268687, F1 Score: 0.754838728628801\nEpoch 7, Loss: 0.4827369898557663, F1 Score: 0.7842122728871859\nEpoch 8, Loss: 0.38864947110414505, F1 Score: 0.8298314503416319\nEpoch 9, Loss: 0.32261645793914795, F1 Score: 0.8445088593548139\nEpoch 10, Loss: 0.2478681622693936, F1 Score: 0.9132765272716787\nModel saved to /kaggle/working/models/ColBERT_model.pth\nTest - Accuracy: 0.708, Precision: 0.677927786499215, Recall: 0.708, F1-Score: 0.6897143818334734\nEpoch 1, Loss: 1.0035943885644276, F1 Score: 0.4399729669645635\nEpoch 2, Loss: 0.9621362288792928, F1 Score: 0.4477717129966209\nEpoch 3, Loss: 0.951024999221166, F1 Score: 0.46352569960097956\nEpoch 4, Loss: 0.8771678556998571, F1 Score: 0.5395122102921996\nEpoch 5, Loss: 0.7137137949466705, F1 Score: 0.7055847687635661\nEpoch 6, Loss: 0.6213962584733963, F1 Score: 0.7489293723605651\nEpoch 7, Loss: 0.5273722410202026, F1 Score: 0.7850967053268145\nEpoch 8, Loss: 0.4448552330334981, F1 Score: 0.8040044770662842\nEpoch 9, Loss: 0.39419201264778775, F1 Score: 0.8164999175425561\nEpoch 10, Loss: 0.34246236582597095, F1 Score: 0.8567011838364255\nModel saved to /kaggle/working/models/LinkBERT_model.pth\nTest - Accuracy: 0.748, Precision: 0.696185806451613, Recall: 0.748, F1-Score: 0.7170497175141244\nEpoch 1, Loss: 1.0730944524208705, F1 Score: 0.4489664644226961\nEpoch 2, Loss: 0.9716770748297373, F1 Score: 0.48945476326608406\nEpoch 3, Loss: 0.9194800506035486, F1 Score: 0.511676026571405\nEpoch 4, Loss: 0.8297430028518041, F1 Score: 0.60013052965621\nEpoch 5, Loss: 0.6653930296500524, F1 Score: 0.7274670711010003\nEpoch 6, Loss: 0.5817162866393725, F1 Score: 0.7561646135693059\nEpoch 7, Loss: 0.48999059448639554, F1 Score: 0.7987693534013712\nEpoch 8, Loss: 0.39317015434304875, F1 Score: 0.8409246739216909\nEpoch 9, Loss: 0.3142683667441209, F1 Score: 0.8909003713218044\nEpoch 10, Loss: 0.24202758197983107, F1 Score: 0.9163539456539356\nModel saved to /kaggle/working/models/BiomedNLP_model.pth\nTest - Accuracy: 0.8, Precision: 0.7543820682628629, Recall: 0.8, F1-Score: 0.7702133025759322\nEpoch 1, Loss: 1.000192567706108, F1 Score: 0.45253403743916065\nEpoch 2, Loss: 0.9468157192071279, F1 Score: 0.4204976958525346\nEpoch 3, Loss: 0.9285100400447845, F1 Score: 0.4916694685180008\nEpoch 4, Loss: 0.8928653399149576, F1 Score: 0.5027167421356218\nEpoch 5, Loss: 0.770828569928805, F1 Score: 0.6550645143018974\nEpoch 6, Loss: 0.6361225719253222, F1 Score: 0.7386934840687309\nEpoch 7, Loss: 0.5400010024507841, F1 Score: 0.7762587064676618\nEpoch 8, Loss: 0.46647798518339795, F1 Score: 0.7977013852391718\nEpoch 9, Loss: 0.4076753929257393, F1 Score: 0.8297855899066335\nEpoch 10, Loss: 0.3541063244144122, F1 Score: 0.8560462516360046\nModel saved to /kaggle/working/models/BioLinkBERT_model.pth\nTest - Accuracy: 0.804, Precision: 0.768, Recall: 0.804, F1-Score: 0.7667862460120525\n","output_type":"stream"}]},{"cell_type":"code","source":"def result_convert(result_dict):\n    df = pd.DataFrame({\n        'Model': result_dict.keys(),\n        'Accuracy': [result_dict[model]['test']['accuracy'] for model in result_dict],\n        'Precision': [result_dict[model]['test']['precision'] for model in result_dict],\n        'Recall': [result_dict[model]['test']['recall'] for model in result_dict],\n        'F1 Score': [result_dict[model]['test']['f1'] for model in result_dict]})\n    return df\n\nresult_adamw= result_convert(trainer.results)\nresult_adamw","metadata":{"execution":{"iopub.status.busy":"2024-08-05T02:50:02.635006Z","iopub.execute_input":"2024-08-05T02:50:02.635413Z","iopub.status.idle":"2024-08-05T02:50:02.652861Z","shell.execute_reply.started":"2024-08-05T02:50:02.635375Z","shell.execute_reply":"2024-08-05T02:50:02.651740Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"         Model  Accuracy  Precision  Recall  F1 Score\n0         BERT     0.756   0.732277   0.756  0.743215\n1          GPT     0.552   0.304704   0.552  0.392660\n2      ColBERT     0.708   0.677928   0.708  0.689714\n3     LinkBERT     0.748   0.696186   0.748  0.717050\n4    BiomedNLP     0.800   0.754382   0.800  0.770213\n5  BioLinkBERT     0.804   0.768000   0.804  0.766786","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BERT</td>\n      <td>0.756</td>\n      <td>0.732277</td>\n      <td>0.756</td>\n      <td>0.743215</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GPT</td>\n      <td>0.552</td>\n      <td>0.304704</td>\n      <td>0.552</td>\n      <td>0.392660</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ColBERT</td>\n      <td>0.708</td>\n      <td>0.677928</td>\n      <td>0.708</td>\n      <td>0.689714</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LinkBERT</td>\n      <td>0.748</td>\n      <td>0.696186</td>\n      <td>0.748</td>\n      <td>0.717050</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BiomedNLP</td>\n      <td>0.800</td>\n      <td>0.754382</td>\n      <td>0.800</td>\n      <td>0.770213</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>BioLinkBERT</td>\n      <td>0.804</td>\n      <td>0.768000</td>\n      <td>0.804</td>\n      <td>0.766786</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Testing with adam instead of AdamW ","metadata":{}},{"cell_type":"code","source":"trainer_adam = Trainandtest(pubmedqa_train, pubmedqa_test)\n\nfor model in models:\n    model_name=model['model_name'],\n    source=model['source'],\n    trainer_adam.model_compile(model_name,source, adamw=False)\n    # Train the model\n    trainer_adam.training(model_name, epochs=10)\n    \n    # test the model\n    test_result = trainer_adam.val()\n    trainer_adam.results[model['model_name']] = test_result","metadata":{"execution":{"iopub.status.busy":"2024-08-05T02:39:00.062055Z","iopub.execute_input":"2024-08-05T02:39:00.062461Z","iopub.status.idle":"2024-08-05T02:45:48.395460Z","shell.execute_reply.started":"2024-08-05T02:39:00.062426Z","shell.execute_reply":"2024-08-05T02:45:48.393869Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.0309644838174183, F1 Score: 0.40058593679164584\nEpoch 2, Loss: 0.9316036502520243, F1 Score: 0.4747573362442472\nEpoch 3, Loss: 0.8613795091708502, F1 Score: 0.5061758701612865\nEpoch 4, Loss: 0.7254956861337026, F1 Score: 0.700234471420467\nEpoch 5, Loss: 0.6264600505431493, F1 Score: 0.7411422535411772\nEpoch 6, Loss: 0.5110151842236519, F1 Score: 0.7740106259041619\nEpoch 7, Loss: 0.41622703646620113, F1 Score: 0.8145444292878178\nEpoch 8, Loss: 0.37562190741300583, F1 Score: 0.8349004296838056\nEpoch 9, Loss: 0.3377520367503166, F1 Score: 0.8515858841168065\nEpoch 10, Loss: 0.2603805400431156, F1 Score: 0.9020769182956309\nModel saved to /kaggle/working/models/BERT_model.pth\nTest - Accuracy: 0.74, Precision: 0.7112554872695347, Recall: 0.74, F1-Score: 0.7217710309930425\nEpoch 1, Loss: 1.3248475029113445, F1 Score: 0.43854165753924795\nEpoch 2, Loss: 1.0566828149430296, F1 Score: 0.4334618520959984\nEpoch 3, Loss: 1.0054618094829804, F1 Score: 0.43878453721072985\nEpoch 4, Loss: 0.9941811663039187, F1 Score: 0.4541596424010217\nEpoch 5, Loss: 0.9638968870994893, F1 Score: 0.4420788699415145\nEpoch 6, Loss: 0.9701903690683081, F1 Score: 0.45263748981076357\nEpoch 7, Loss: 1.0076325345546642, F1 Score: 0.4197311669979546\nEpoch 8, Loss: 0.9711890829370377, F1 Score: 0.4485556057353665\nEpoch 9, Loss: 0.9597450456720718, F1 Score: 0.4281303822937626\nEpoch 10, Loss: 0.9345145301615938, F1 Score: 0.4658525195712137\nModel saved to /kaggle/working/models/GPT_model.pth\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Test - Accuracy: 0.552, Precision: 0.30470400000000003, Recall: 0.552, F1-Score: 0.392659793814433\nEpoch 1, Loss: 1.0021938135226567, F1 Score: 0.4206173589885405\nEpoch 2, Loss: 0.9467902034521103, F1 Score: 0.4320542353976594\nEpoch 3, Loss: 0.8945818791786829, F1 Score: 0.5402030197444831\nEpoch 4, Loss: 0.8381931483745575, F1 Score: 0.5987180784833515\nEpoch 5, Loss: 0.6877349317073822, F1 Score: 0.7134915750915752\nEpoch 6, Loss: 0.5719812711079916, F1 Score: 0.7570669644356144\nEpoch 7, Loss: 0.4945155245562394, F1 Score: 0.7798998244312088\nEpoch 8, Loss: 0.4173024247090022, F1 Score: 0.8108981463255851\nEpoch 9, Loss: 0.33342715601126355, F1 Score: 0.8606649627091386\nEpoch 10, Loss: 0.261577049891154, F1 Score: 0.8855086290510183\nModel saved to /kaggle/working/models/ColBERT_model.pth\nTest - Accuracy: 0.72, Precision: 0.6557874636778745, Recall: 0.72, F1-Score: 0.6859459709074117\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m trainer_adam\u001b[38;5;241m.\u001b[39mmodel_compile(model_name,source, adamw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrainer_adam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# test the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m test_result \u001b[38;5;241m=\u001b[39m trainer_adam\u001b[38;5;241m.\u001b[39mval()\n","Cell \u001b[0;32mIn[34], line 110\u001b[0m, in \u001b[0;36mTrainandtest.training\u001b[0;34m(self, model_name, epochs)\u001b[0m\n\u001b[1;32m    108\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(b_input_ids, b_attention_mask)\n\u001b[1;32m    109\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(outputs, b_labels)\n\u001b[0;32m--> 110\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    113\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 13.12 MiB is free. Process 2197 has 15.87 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 13.12 MiB is free. Process 2197 has 15.87 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"result_adam= result_convert(trainer_adam.results)\nresult_adam","metadata":{"execution":{"iopub.status.busy":"2024-08-05T02:48:59.639743Z","iopub.execute_input":"2024-08-05T02:48:59.640075Z","iopub.status.idle":"2024-08-05T02:48:59.652508Z","shell.execute_reply.started":"2024-08-05T02:48:59.640051Z","shell.execute_reply":"2024-08-05T02:48:59.651494Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"     Model  Accuracy  Precision  Recall  F1 Score\n0     BERT     0.740   0.711255   0.740  0.721771\n1      GPT     0.552   0.304704   0.552  0.392660\n2  ColBERT     0.720   0.655787   0.720  0.685946","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BERT</td>\n      <td>0.740</td>\n      <td>0.711255</td>\n      <td>0.740</td>\n      <td>0.721771</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GPT</td>\n      <td>0.552</td>\n      <td>0.304704</td>\n      <td>0.552</td>\n      <td>0.392660</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ColBERT</td>\n      <td>0.720</td>\n      <td>0.655787</td>\n      <td>0.720</td>\n      <td>0.685946</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# mixing artificial data ","metadata":{}},{"cell_type":"code","source":"trainer_mix = Trainandtest(pubmedqa_mix_train, pubmedqa_mix_test)\n\nimport torch\nimport gc\n# Function to free up memory\ndef free_memory():\n    gc.collect()\n    torch.cuda.empty_cache()\n\nfor model in models:\n    model_name=model['model_name'],\n    source=model['source'],\n    trainer_mix.model_compile(model_name,source,batch_size=8)\n    free_memory()\n    # Train the model\n    trainer_mix.training(model_name, epochs=3)\n    \n    # test the model\n    test_result = trainer_mix.val()\n    trainer_mix.results[model['model_name']] = test_result","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:34:30.331677Z","iopub.execute_input":"2024-08-05T03:34:30.332402Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.6263292911759717, F1 Score: 0.7266546606955939\nEpoch 2, Loss: 0.42936402545409635, F1 Score: 0.8301333277319162\nEpoch 3, Loss: 0.2957336701541901, F1 Score: 0.8827430232347814\nModel saved to /kaggle/working/models/BERT_model.pth\nTest - Accuracy: 0.842, Precision: 0.8159382698298586, Recall: 0.842, F1-Score: 0.8216820920080387\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0da8783f6ba4d3c906c8778e067f840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7e1b7c8750841588d1e59492c224cb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a581fd26ed6416289c3e6a725979505"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60440e63aa7a47c68cdc303e8a224355"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bbcfb75cd2f403d8e582c587c9e5199"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45f37a77d3c34e5d92a14fd74fe6f7e8"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, Loss: 0.9151097472677839, F1 Score: 0.6166968136848008\nEpoch 2, Loss: 0.7974374842770556, F1 Score: 0.6303224806048497\nEpoch 3, Loss: 0.7702962867123015, F1 Score: 0.638075781614834\nModel saved to /kaggle/working/models/GPT_model.pth\nTest - Accuracy: 0.738, Precision: 0.544644, Recall: 0.738, F1-Score: 0.6267479861910242\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f17c33519cc341d084a234db29fb7cef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8604f7fdcfbb49b3a45f31efbf72351c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b8f631c4604bc2b5ec89f4f243ca2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a49b6feefa1243d297ed9eabb2fa5323"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b784403227674ca9955e14dcd74e9dba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17b1253946e74dc383feb70e4f8f3039"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, Loss: 0.639295128273203, F1 Score: 0.7154349656129164\nEpoch 2, Loss: 0.44220527273384813, F1 Score: 0.8249534732287269\nEpoch 3, Loss: 0.2967134022272806, F1 Score: 0.8797971386603824\nModel saved to /kaggle/working/models/ColBERT_model.pth\nTest - Accuracy: 0.836, Precision: 0.7857278932018402, Recall: 0.836, F1-Score: 0.8054858255668382\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39ef05ae71a84c489dcfc10dc39936ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc420f2f83ad4f1c87c5eb61c9c917f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f7689f5698c403893c92df74c8c6225"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6110ac7b5247eaa6a45edb716f06b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/559 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"457fca54f0e741f99eb3f5ee006b1873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57e3b37a869b45d58a72622e84d07881"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.6404168241201563, F1 Score: 0.7252281312845033\nEpoch 2, Loss: 0.44086362566164833, F1 Score: 0.8322019258281858\n","output_type":"stream"}]}]}