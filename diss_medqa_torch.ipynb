{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9012001,"sourceType":"datasetVersion","datasetId":5429851},{"sourceId":9062110,"sourceType":"datasetVersion","datasetId":5465014}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shutil\nimport os\n\n# Remove the directory if already exist \ndir_name = 'neural_medical_qa'\nif os.path.exists(dir_name):\n    shutil.rmtree(dir_name)\n\n#clone the repo from github\n!git clone https://github.com/trduc97/neural_medical_qa.git\n%cd neural_medical_qa\n# install the requirement\n!pip install -r requirements.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T23:58:20.659097Z","iopub.execute_input":"2024-08-04T23:58:20.659443Z","iopub.status.idle":"2024-08-04T23:58:36.657666Z","shell.execute_reply.started":"2024-08-04T23:58:20.659415Z","shell.execute_reply":"2024-08-04T23:58:36.656601Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'neural_medical_qa'...\nremote: Enumerating objects: 123, done.\u001b[K\nremote: Counting objects: 100% (123/123), done.\u001b[K\nremote: Compressing objects: 100% (116/116), done.\u001b[K\nremote: Total 123 (delta 57), reused 0 (delta 0), pack-reused 0\u001b[K\nReceiving objects: 100% (123/123), 1.78 MiB | 5.75 MiB/s, done.\nResolving deltas: 100% (57/57), done.\n/kaggle/working/neural_medical_qa\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.20.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->-r requirements.txt (line 1)) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.19.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets->-r requirements.txt (line 1)) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets->-r requirements.txt (line 1)) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 1)) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nfrom datasets import Dataset, DatasetDict, load_dataset\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\ndef load_bioasq_pubmedqa(bioasq_kaggle_path = '/kaggle/input/bioasq-training-12b/training12b_new.json', \n                         pubmed_kaggle_path='/kaggle/input/pubmed-qa/pubmed_qa_pga_labeled.parquet'):\n    # Load the JSON file\n    with open(bioasq_kaggle_path,'r') as f:\n        bioasq_data=json.load(f)\n    # Extract yes/no questions directly\n    bioasq_yesno = [{\n            'id':question['id'],\n            'question':question['body'],\n            'final_decision':question['exact_answer'],\n            'long_answer':question['ideal_answer'], \n            'documents':question['documents']\n        }\n        for question in bioasq_data['questions'] if question['type'] == 'yesno']\n    # Convert the list of yes/no questions to a Pandas DataFrame\n    bioasq_df = pd.DataFrame(bioasq_yesno)\n\n    # Convert the DataFrame to a Hugging Face Dataset\n    bioasq_dataset = Dataset.from_pandas(bioasq_df)\n    # Create a DatasetDict with the 'train' split\n    bioasq_data=DatasetDict({'train': bioasq_dataset})\n\n    # Read from parquet and translate to a dataset object\n    pubmed_df=pd.read_parquet(pubmed_kaggle_path)\n    dataset=Dataset.from_pandas(pubmed_df,preserve_index=False)\n    #Setting into similar format as from huggingface\n    pubmedqa_data = DatasetDict({'train': dataset})\n    \n    # Load the pubmedqa dataset\n    #pubmedqa_data=load_dataset(\"pubmed_qa\",\"pqa_labeled\") # unstable connection\n\n    #Encoding decisions \n    def decision_encode(question):\n        labels_map = {'no': 0, 'maybe': 1, 'yes': 2}\n        question['decision_encoded'] = labels_map[question['final_decision']]\n        return question\n\n    pubmedqa_data=pubmedqa_data.map(decision_encode)\n    bioasq_data=pubmedqa_data.map(decision_encode)\n\n    return bioasq_data, pubmedqa_data\n\n\ndef pubmed_train_test_split(datasetdict,train_size=0.75, \n                         strat_col='decision_encoded'):\n    #Convert dataset to pandas DataFrame\n    df = pd.DataFrame(datasetdict['train'])\n    test_size=(1-train_size)\n    # Define the stratification column\n    stratify_col=strat_col\n\n    #Split like normal\n    train_df, test_df = train_test_split(\n        df,\n        test_size=test_size,\n        stratify=df[stratify_col],\n        random_state=42)\n    # Convert DataFrames back to Dataset\n    train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n    test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n\n    return train_dataset, test_dataset\n\n\ndef train_val_test_split(datasetdict,train_size=0.75, \n                         val_test_ratio=0.6,\n                         strat_col='decision_encoded'):\n    #Convert dataset to pandas DataFrame\n    df = pd.DataFrame(datasetdict['train'])\n    test_size=(1-train_size)\n    # Define the stratification column\n    stratify_col=strat_col\n\n    #First, split for the train set\n    train_df, val_test_df = train_test_split(\n        df,\n        test_size=test_size,\n        stratify=df[stratify_col],\n        random_state=42)\n    #Then, split the remaining into validation and test\n    val_df, test_df = train_test_split(\n        val_test_df,\n        test_size=val_test_ratio,\n        stratify=val_test_df[stratify_col],\n        random_state=42)\n    # Convert DataFrames back to Dataset\n    train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n    val_dataset = Dataset.from_pandas(val_df, preserve_index=False)\n    test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n\n    return train_dataset, val_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:04:36.356668Z","iopub.execute_input":"2024-08-05T00:04:36.357407Z","iopub.status.idle":"2024-08-05T00:04:36.373394Z","shell.execute_reply.started":"2024-08-05T00:04:36.357375Z","shell.execute_reply":"2024-08-05T00:04:36.372422Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from import_datasets import load_bioasq_pubmedqa, train_test_split\n\nbioasq, pubmedqa = load_bioasq_pubmedqa()\n\n# Display the first few samples of the PubMedQA dataset\nprint(pubmedqa['train'].to_pandas().head())\n\nresponses = pubmedqa['train']['final_decision']\n# Counting the occurrences of each value\nyes_count = responses.count('yes')\nno_count = responses.count('no')\nmaybe_count = responses.count('maybe')\n\n# Display the counts\nprint(f\"Yes: {yes_count}\")\nprint(f\"No: {no_count}\")\nprint(f\"Maybe: {maybe_count}\")\n\npubmedqa_train, pubmedqa_test = pubmed_train_test_split(pubmedqa)\nprint(f\"Train size: {len(pubmedqa_train)}\")\nprint(f\"Test size: {len(pubmedqa_test)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:04:41.654344Z","iopub.execute_input":"2024-08-05T00:04:41.655004Z","iopub.status.idle":"2024-08-05T00:04:42.533637Z","shell.execute_reply.started":"2024-08-05T00:04:41.654971Z","shell.execute_reply":"2024-08-05T00:04:42.532548Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f2312e0adf4ca8a51cf066695f5201"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6df4cc292b11492e851ad31075509e72"}},"metadata":{}},{"name":"stdout","text":"      pubid                                           question  \\\n0  21645374  Do mitochondria play a role in remodelling lac...   \n1  16418930  Landolt C and snellen e acuity: differences in...   \n2   9488747  Syncope during bathing in infants, a pediatric...   \n3  17208539  Are the long-term results of the transanal pul...   \n4  10808977  Can tailored interventions increase mammograph...   \n\n                                             context  \\\n0  {'contexts': ['Programmed cell death (PCD) is ...   \n1  {'contexts': ['Assessment of visual acuity dep...   \n2  {'contexts': ['Apparent life-threatening event...   \n3  {'contexts': ['The transanal endorectal pull-t...   \n4  {'contexts': ['Telephone counseling and tailor...   \n\n                                         long_answer final_decision  \\\n0  Results depicted mitochondrial dynamics in viv...            yes   \n1  Using the charts described, there was only a s...             no   \n2  \"Aquagenic maladies\" could be a pediatric form...            yes   \n3  Our long-term study showed significantly bette...             no   \n4  The effects of the intervention were most pron...            yes   \n\n   decision_encoded  \n0                 2  \n1                 0  \n2                 2  \n3                 0  \n4                 2  \nYes: 552\nNo: 338\nMaybe: 110\nTrain size: 750\nTest size: 250\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import defaultdict\n# Initialize a defaultdict to hold the bucket counts\nlength_buckets = defaultdict(int)\n\n# Define the bucket size\nbucket_size = 128\n\n# Loop through each string in the list\nfor s in pubmedqa_train['long_answer']:\n    # Determine the bucket for the current string length\n    bucket = (len(s) // bucket_size) * bucket_size\n    # Increment the count for the appropriate bucket\n    length_buckets[bucket] += 1\n\n# Display the counts for each bucket\nfor bucket, count in sorted(length_buckets.items()):\n    print(f\"Length {bucket} - {bucket + bucket_size - 1}: {count} strings\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:08:36.119760Z","iopub.execute_input":"2024-08-05T00:08:36.120491Z","iopub.status.idle":"2024-08-05T00:08:36.129046Z","shell.execute_reply.started":"2024-08-05T00:08:36.120461Z","shell.execute_reply":"2024-08-05T00:08:36.128055Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Length 0 - 127: 66 strings\nLength 128 - 255: 326 strings\nLength 256 - 383: 244 strings\nLength 384 - 511: 82 strings\nLength 512 - 639: 25 strings\nLength 640 - 767: 4 strings\nLength 768 - 895: 3 strings\n","output_type":"stream"}]},{"cell_type":"code","source":"bioasq, pubmedqa_artificial = load_bioasq_pubmedqa(pubmed_kaggle_path='/kaggle/input/pubmed-qa/pubmed_qa_pga_artificial.parquet')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict, Dataset\nfrom sklearn.model_selection import train_test_split\n\ndf_artificial=pubmedqa_artificial['train'].to_pandas()\ndf_sample, _=train_test_split(df_artificial, test_size=0.95, random_state=42, stratify=df_artificial['decision_encoded'])   \ndf_sample=df_sample[['pubid', 'question', 'context', 'long_answer', 'final_decision', 'decision_encoded']]\ndata_art=Dataset.from_pandas(df_sample,preserve_index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert back to datasets\npubmedqa_arti = DatasetDict({'train': data_art})\npubmedqa_art_train,pubmedqa_art_val, pubmedqa_art_test = pubmed_train_test_split(pubmedqa_arti)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel, GPT2Tokenizer, GPT2Model\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n\nclass QAModel(nn.Module):\n    def __init__(self, model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # number of classes may vary between BioASQ (2 classes) and PubMedQA (3 classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nclass Trainandtest:\n\n    def __init__(self, df_train, df_test, stratify_col='decision_encoded'):\n        self.train_data = df_train\n        self.test_data = df_test\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.stratify_col = stratify_col\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.results={}\n\n    def initialize_tokenizer(self, model_name, source):\n        if 'GPT' in model_name:\n            tokenizer = GPT2Tokenizer.from_pretrained(source)\n            if tokenizer.pad_token is None:\n                tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n            return tokenizer\n        elif 'BioLinkBERT' in model_name:\n            return AutoTokenizer.from_pretrained(source)\n        else:\n            return BertTokenizer.from_pretrained(source)\n\n    def encode_data(self, df):\n        inputs = self.tokenizer(\n            text=df['question'], \n            text_pair=df['long_answer'], \n            padding=True, \n            truncation=True, \n            return_tensors='pt', \n            max_length=128*4\n        )\n        labels = torch.tensor(df[self.stratify_col])\n        return inputs, labels\n\n    def create_dataloader(self, inputs, labels, batch_size):\n        dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    def import_model(self, model_name, source, tokenizer):\n        if 'GPT' in model_name:\n            model = GPT2Model.from_pretrained(source)\n            model.resize_token_embeddings(len(tokenizer))\n            model = QAModel(model)\n        elif 'BioLinkBERT' in model_name or 'LinkBERT' in model_name:\n            model = AutoModel.from_pretrained(source)\n            model = QAModel(model)\n        else:\n            model = BertModel.from_pretrained(source)\n            model = QAModel(model)\n        return model\n    def model_compile(self, model_name, source, batch_size=64):\n        batch_size = 16 if 'GPT' in model_name else batch_size\n        tokenizer = self.initialize_tokenizer(model_name, source)\n        train_inputs, train_labels = self.encode_data(df_train)\n        test_inputs, test_labels = self.encode_data(df_test)\n        self.train_loader = self.create_dataloader(train_inputs, train_labels, batch_size)\n        self.test_loader = self.create_dataloader(test_inputs, test_labels, batch_size)\n        \n        self.model = self.import_model(model_name, source, tokenizer).to(self.device) \n        self.optimizer = optim.AdamW(self.model.parameters(), lr=2e-5)\n\n    \n    def training(self, epochs=10):\n        \n        self.model.train()\n        for epoch in range(epochs):\n            total_loss = 0\n            all_preds = []\n            all_labels = []\n        \n            for batch in self.train_loader:\n                b_input_ids, b_attention_mask, b_labels = [t.to(self.device) for t in batch]\n                self.optimizer.zero_grad()\n            \n                outputs = self.model(b_input_ids, b_attention_mask)\n                loss = self.loss_fn(outputs, b_labels)\n                loss.backward()\n                self.optimizer.step()\n            \n                total_loss += loss.item()\n            \n                preds = outputs.detach().cpu().numpy()\n                label_ids = b_labels.to('cpu').numpy()\n            \n                all_preds.append(preds)\n                all_labels.append(label_ids)\n        \n            avg_loss = total_loss / len(self.train_loader)\n            all_preds = np.concatenate(all_preds, axis=0)\n            all_labels = np.concatenate(all_labels, axis=0)\n            avg_f1_score = self.calculate_f1_score(all_preds, all_labels)\n        \n            print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n        \n        self.save_model()\n\n    def save_model(self):\n        os.makedirs('/kaggle/working/models', exist_ok=True)\n        model_path = f'/kaggle/working/models/{self.name}_model.pth'\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n        }, model_path)\n        print(f\"Model saved to {model_path}\")\n\n    def load_model(self, model_path):\n        checkpoint = torch.load(model_path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        print(f\"Model loaded from {model_path}\")\n\n    def calculate_f1_score(self, preds, labels):\n        preds_flat = np.argmax(preds, axis=1).flatten()\n        labels_flat = labels.flatten()\n        return f1_score(labels_flat, preds_flat, average='weighted')\n\n    def evaluate(self, dataloader):\n        self.model.eval()\n        total_loss = 0\n        predictions, true_labels = [], []\n    \n        with torch.no_grad():\n            for batch in dataloader:\n                b_input_ids, b_attention_mask, b_labels = [t.to(self.device) for t in batch]\n                outputs = self.model(b_input_ids, b_attention_mask)\n                logits = outputs.detach().cpu().numpy()\n                label_ids = b_labels.cpu().numpy()\n                predictions.extend(np.argmax(logits, axis=1))\n                true_labels.extend(label_ids)\n    \n        accuracy = accuracy_score(true_labels, predictions)\n        precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n        return accuracy, precision, recall, f1\n        \n\n    def val(self, load_model_path=None):\n        if load_model_path:\n            self.load_model(load_model_path)\n                \n        test_accuracy, test_precision, test_recall, test_f1 = self.evaluate(self.test_loader)\n        print(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")\n    \n        return {\n            'test': {\n                'accuracy': test_accuracy,\n                'precision': test_precision,\n                'recall': test_recall,\n                'f1': test_f1\n            }\n        }","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:38:40.088951Z","iopub.execute_input":"2024-08-05T01:38:40.089381Z","iopub.status.idle":"2024-08-05T01:38:40.123263Z","shell.execute_reply.started":"2024-08-05T01:38:40.089351Z","shell.execute_reply":"2024-08-05T01:38:40.122303Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"models = [\n    {\n        'model_name': 'BERT',\n        'source': 'bert-base-uncased',\n    },\n    {\n        'model_name': 'GPT',\n        'source': 'gpt2',\n    },\n    {\n        'model_name': 'ColBERT',\n        'source': 'colbert-ir/colbertv2.0',\n    },\n    {\n        'model_name': 'LinkBERT',\n        'source': 'michiyasunaga/LinkBERT-base',\n    },\n    {\n        'model_name': 'BiomedNLP',\n        'source': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract',\n    },\n    {\n        'model_name': 'BioLinkBERT',\n        'source': 'michiyasunaga/BioLinkBERT-base',\n    },\n\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:33:10.122091Z","iopub.execute_input":"2024-08-05T01:33:10.123016Z","iopub.status.idle":"2024-08-05T01:33:10.128694Z","shell.execute_reply.started":"2024-08-05T01:33:10.122982Z","shell.execute_reply":"2024-08-05T01:33:10.127631Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(models[0]['source'])","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:43:44.396340Z","iopub.execute_input":"2024-08-05T01:43:44.396720Z","iopub.status.idle":"2024-08-05T01:43:44.725772Z","shell.execute_reply.started":"2024-08-05T01:43:44.396689Z","shell.execute_reply":"2024-08-05T01:43:44.724936Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"trainer = Trainandtest(pubmedqa_train, pubmedqa_test)\n\nfor model in models:\n    model_name=model['model_name'],\n    source=model['source'],\n    trainer.model_compile(model_name,source)\n    # Train the model\n    trainer.training(epochs=1)\n    \n    # test the model\n    test_result = trainer.val()\n    trainer.results[model['model_name']] = test_result","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:41:13.124509Z","iopub.execute_input":"2024-08-05T01:41:13.125574Z","iopub.status.idle":"2024-08-05T01:41:13.329123Z","shell.execute_reply.started":"2024-08-05T01:41:13.125541Z","shell.execute_reply":"2024-08-05T01:41:13.327781Z"},"trusted":true},"execution_count":41,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '('bert-base-uncased',)'.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[41], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model_name\u001b[38;5;241m=\u001b[39mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m source\u001b[38;5;241m=\u001b[39mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtraining(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","Cell \u001b[0;32mIn[39], line 79\u001b[0m, in \u001b[0;36mTrainandtest.model_compile\u001b[0;34m(self, model_name, source, batch_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_compile\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name, source, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m):\n\u001b[1;32m     78\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPT\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name \u001b[38;5;28;01melse\u001b[39;00m batch_size\n\u001b[0;32m---> 79\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     train_inputs, train_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_data(df_train)\n\u001b[1;32m     81\u001b[0m     test_inputs, test_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_data(df_test)\n","Cell \u001b[0;32mIn[39], line 47\u001b[0m, in \u001b[0;36mTrainandtest.initialize_tokenizer\u001b[0;34m(self, model_name, source)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(source)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBertTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2082\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m vocab_files:\n\u001b[1;32m   2080\u001b[0m     \u001b[38;5;66;03m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[39;00m\n\u001b[1;32m   2081\u001b[0m     fast_tokenizer_file \u001b[38;5;241m=\u001b[39m FULL_TOKENIZER_FILE\n\u001b[0;32m-> 2082\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2083\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2084\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2094\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2095\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2097\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2098\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2099\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   2100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:466\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n","\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '('bert-base-uncased',)'. Please provide either the path to a local folder or the repo_id of a model on the Hub."],"ename":"OSError","evalue":"Incorrect path_or_model_id: '('bert-base-uncased',)'. Please provide either the path to a local folder or the repo_id of a model on the Hub.","output_type":"error"}]},{"cell_type":"code","source":"df = pd.DataFrame({\n    'Model': test_results.keys(),\n    'Accuracy': [test_results[model]['test']['accuracy'] for model in test_results],\n    'Precision': [test_results[model]['test']['precision'] for model in test_results],\n    'Recall': [test_results[model]['test']['recall'] for model in test_results],\n    'F1 Score': [test_results[model]['test']['f1'] for model in test_results]})\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T00:30:46.392766Z","iopub.execute_input":"2024-08-05T00:30:46.393436Z","iopub.status.idle":"2024-08-05T00:30:46.404929Z","shell.execute_reply.started":"2024-08-05T00:30:46.393402Z","shell.execute_reply":"2024-08-05T00:30:46.404013Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"         Model  Accuracy  Precision  Recall  F1 Score\n0         BERT     0.732   0.712725   0.732  0.721290\n1          GPT     0.552   0.304704   0.552  0.392660\n2      ColBERT     0.724   0.699425   0.724  0.708513\n3    BiomedNLP     0.772   0.781622   0.772  0.771634\n4  BioLinkBERT     0.804   0.768103   0.804  0.781757\n","output_type":"stream"}]}]}