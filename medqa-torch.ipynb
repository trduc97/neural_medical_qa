{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9012001,"sourceType":"datasetVersion","datasetId":5429851},{"sourceId":9062110,"sourceType":"datasetVersion","datasetId":5465014}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shutil\nimport os\n\n# Remove the directory if already exist \ndir_name = 'neural_medical_qa'\nif os.path.exists(dir_name):\n    shutil.rmtree(dir_name)\n\n#clone the repo from github\n!git clone https://github.com/trduc97/neural_medical_qa.git\n%cd neural_medical_qa\n# install the requirement\n!pip install -r requirements.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T00:22:52.638208Z","iopub.execute_input":"2024-08-04T00:22:52.639031Z","iopub.status.idle":"2024-08-04T00:23:08.248388Z","shell.execute_reply.started":"2024-08-04T00:22:52.638986Z","shell.execute_reply":"2024-08-04T00:23:08.246669Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'neural_medical_qa'...\nremote: Enumerating objects: 112, done.\u001b[K\nremote: Counting objects: 100% (112/112), done.\u001b[K\nremote: Compressing objects: 100% (105/105), done.\u001b[K\nremote: Total 112 (delta 50), reused 0 (delta 0), pack-reused 0\u001b[K\nReceiving objects: 100% (112/112), 1.77 MiB | 9.61 MiB/s, done.\nResolving deltas: 100% (50/50), done.\n/kaggle/working/neural_medical_qa\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.20.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->-r requirements.txt (line 1)) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.19.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets->-r requirements.txt (line 1)) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets->-r requirements.txt (line 1)) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 1)) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from import_datasets import load_bioasq_pubmedqa,  train_val_test_split\n\nbioasq, pubmedqa = load_bioasq_pubmedqa()\n\n# Display the first few samples of the PubMedQA dataset\nprint(pubmedqa['train'].to_pandas().head())\n\nresponses = pubmedqa['train']['final_decision']\n# Counting the occurrences of each value\nyes_count = responses.count('yes')\nno_count = responses.count('no')\nmaybe_count = responses.count('maybe')\n\n# Display the counts\nprint(f\"Yes: {yes_count}\")\nprint(f\"No: {no_count}\")\nprint(f\"Maybe: {maybe_count}\")\n\npubmedqa_train,pubmedqa_val, pubmedqa_test = train_val_test_split(pubmedqa)\nprint(f\"Train size: {len(pubmedqa_train)}\")\nprint(f\"Validation size: {len(pubmedqa_val)}\")\nprint(f\"Test size: {len(pubmedqa_test)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T00:23:08.251204Z","iopub.execute_input":"2024-08-04T00:23:08.252327Z","iopub.status.idle":"2024-08-04T00:23:12.049608Z","shell.execute_reply.started":"2024-08-04T00:23:08.252276Z","shell.execute_reply":"2024-08-04T00:23:12.048520Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e07dc1ceae1e4330aaf39573438c0bec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db96f6d9943c45c8a707507b042ca1af"}},"metadata":{}},{"name":"stdout","text":"      pubid                                           question  \\\n0  21645374  Do mitochondria play a role in remodelling lac...   \n1  16418930  Landolt C and snellen e acuity: differences in...   \n2   9488747  Syncope during bathing in infants, a pediatric...   \n3  17208539  Are the long-term results of the transanal pul...   \n4  10808977  Can tailored interventions increase mammograph...   \n\n                                             context  \\\n0  {'contexts': ['Programmed cell death (PCD) is ...   \n1  {'contexts': ['Assessment of visual acuity dep...   \n2  {'contexts': ['Apparent life-threatening event...   \n3  {'contexts': ['The transanal endorectal pull-t...   \n4  {'contexts': ['Telephone counseling and tailor...   \n\n                                         long_answer final_decision  \\\n0  Results depicted mitochondrial dynamics in viv...            yes   \n1  Using the charts described, there was only a s...             no   \n2  \"Aquagenic maladies\" could be a pediatric form...            yes   \n3  Our long-term study showed significantly bette...             no   \n4  The effects of the intervention were most pron...            yes   \n\n   decision_encoded  \n0                 2  \n1                 0  \n2                 2  \n3                 0  \n4                 2  \nYes: 552\nNo: 338\nMaybe: 110\nTrain size: 750\nValidation size: 100\nTest size: 150\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import defaultdict\n# Initialize a defaultdict to hold the bucket counts\nlength_buckets = defaultdict(int)\n\n# Define the bucket size\nbucket_size = 128\n\n# Loop through each string in the list\nfor s in pubmedqa_train['long_answer']:\n    # Determine the bucket for the current string length\n    bucket = (len(s) // bucket_size) * bucket_size\n    # Increment the count for the appropriate bucket\n    length_buckets[bucket] += 1\n\n# Display the counts for each bucket\nfor bucket, count in sorted(length_buckets.items()):\n    print(f\"Length {bucket} - {bucket + bucket_size - 1}: {count} strings\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T12:51:23.855673Z","iopub.execute_input":"2024-08-03T12:51:23.856431Z","iopub.status.idle":"2024-08-03T12:51:23.864493Z","shell.execute_reply.started":"2024-08-03T12:51:23.856400Z","shell.execute_reply":"2024-08-03T12:51:23.863602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bert-base","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\nstratify_col = 'decision_encoded'\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=64):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, bert_model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(bert_model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bert + artificial data","metadata":{}},{"cell_type":"code","source":"bioasq, pubmedqa_artificial = load_bioasq_pubmedqa(pubmed_kaggle_path='/kaggle/input/pubmed-qa/pubmed_qa_pga_artificial.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:07:20.245017Z","iopub.execute_input":"2024-08-03T13:07:20.245682Z","iopub.status.idle":"2024-08-03T13:08:13.980898Z","shell.execute_reply.started":"2024-08-03T13:07:20.245652Z","shell.execute_reply":"2024-08-03T13:08:13.979895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict, Dataset\nfrom sklearn.model_selection import train_test_split\n\ndf_artificial=pubmedqa_artificial['train'].to_pandas()\ndf_sample, _=train_test_split(df_artificial, test_size=0.95, random_state=42, stratify=df_artificial['decision_encoded'])   \ndf_sample=df_sample[['pubid', 'question', 'context', 'long_answer', 'final_decision', 'decision_encoded']]\ndata_art=Dataset.from_pandas(df_sample,preserve_index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:08:37.348269Z","iopub.execute_input":"2024-08-03T13:08:37.348631Z","iopub.status.idle":"2024-08-03T13:08:39.241379Z","shell.execute_reply.started":"2024-08-03T13:08:37.348605Z","shell.execute_reply":"2024-08-03T13:08:39.240379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert back to datasets\npubmedqa_arti = DatasetDict({'train': data_art})\npubmedqa_art_train,pubmedqa_art_val, pubmedqa_art_test = train_val_test_split(pubmedqa_arti)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:08:42.975727Z","iopub.execute_input":"2024-08-03T13:08:42.976095Z","iopub.status.idle":"2024-08-03T13:08:44.737023Z","shell.execute_reply.started":"2024-08-03T13:08:42.976065Z","shell.execute_reply":"2024-08-03T13:08:44.736123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\nstratify_col = 'decision_encoded'\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_art_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=16):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, bert_model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(bert_model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BioLinkBERT","metadata":{}},{"cell_type":"code","source":"# Clear GPU memory\n\n\ntorch.cuda.empty_cache()\ntorch.cuda.synchronize()\n\n# Reset GPU memory settings\nimport os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"michiyasunaga/BioLinkBERT-base\")\nmodel = AutoModel.from_pretrained(\"michiyasunaga/BioLinkBERT-base\")\nstratify_col = 'decision_encoded'\n\ntokenizer = AutoTokenizer.from_pretrained(\"michiyasunaga/BioLinkBERT-base\")\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=64):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = AutoModel.from_pretrained(\"michiyasunaga/BioLinkBERT-base\")\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, bert_model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(bert_model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GPT ","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2Model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2Model.from_pretrained('gpt2')\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel,AutoModelForCausalLM\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2Model\n\nimport gc\n\n#model.cpu()\n#del model, checkpoint\ngc.collect()\ntorch.cuda.empty_cache()\n\nstratify_col = 'decision_encoded'\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2Model.from_pretrained('gpt2')\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))\n\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=16):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=5):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BioGPT ","metadata":{}},{"cell_type":"code","source":"pip install sacremoses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel,AutoModelForCausalLM, GPT2Tokenizer, GPT2Model\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n\n# Load model directly\nfrom transformers import BioGptTokenizer, BioGptForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/biogpt\")\ngpt_model = AutoModelForCausalLM.from_pretrained(\"microsoft/biogpt\", output_hidden_states=True)\n\nstratify_col = 'decision_encoded'\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))\n\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=16):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.hidden_states[-1] # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(gpt_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numba import cuda\ncuda.select_device(0)\ncuda.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda.open()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\nfree_gpu_cache()                           \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom numba import cuda\ntorch.cuda.empty_cache()\ncuda.select_device(0)\ncuda.close()\ncuda.select_device(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BiomedNLP","metadata":{}},{"cell_type":"code","source":"# Move the model and tensor to CPU\nmodel.cpu()\n\n# Delete the model and tensor to free up memory\ndel model\n\n# Clear the GPU cache\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForMaskedLM\n\nbert_model = BertModel.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\nstratify_col = 'decision_encoded'\n\ntokenizer =  AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\")\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=64):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = BertModel.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\")\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, bert_model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(bert_model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :] # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# BIDAF","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel\n\nclass BiDAF(nn.Module):\n    def __init__(self, bert_model_name='bert-base-uncased', hidden_size=128, dropout_prob=0.2):\n        super(BiDAF, self).__init__()\n        self.hidden_size = hidden_size\n        self.dropout_prob = dropout_prob\n        \n        # Load pre-trained BERT model\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        bert_hidden_size = self.bert.config.hidden_size\n        \n        # Character embedding\n        self.char_emb = nn.Embedding(num_embeddings=94, embedding_dim=8, padding_idx=0)\n        self.char_conv = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(5, 8))\n        \n        # Highway network\n        self.highway = Highway(input_size=bert_hidden_size + 100, num_layers=2)\n        \n        # Contextual embedding layer\n        self.context_LSTM = nn.LSTM(input_size=bert_hidden_size + 100, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n        \n        # Attention flow layer\n        self.att_flow = AttentionFlowLayer(hidden_size)\n        \n        # Modeling layer\n        self.modeling_LSTM = nn.LSTM(input_size=hidden_size*8, hidden_size=hidden_size, num_layers=2, batch_first=True, bidirectional=True, dropout=dropout_prob)\n        \n        # Output layer\n        self.output_LSTM = nn.LSTM(input_size=hidden_size*2, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n        self.p1 = nn.Linear(hidden_size*10, 1)\n        self.p2 = nn.Linear(hidden_size*10, 1)\n\n    def forward(self, context_input_ids, context_attention_mask, query_input_ids, query_attention_mask, context_char_idxs, query_char_idxs):\n        # BERT embeddings\n        context_bert_output = self.bert(input_ids=context_input_ids, attention_mask=context_attention_mask)\n        query_bert_output = self.bert(input_ids=query_input_ids, attention_mask=query_attention_mask)\n        \n        context_word_emb = context_bert_output.last_hidden_state  # (batch, context_len, bert_hidden_size)\n        query_word_emb = query_bert_output.last_hidden_state  # (batch, query_len, bert_hidden_size)\n        \n        # Character embedding and convolution\n        context_char_emb = self.char_emb(context_char_idxs).unsqueeze(1)  # (batch, 1, context_len, char_emb_dim)\n        query_char_emb = self.char_emb(query_char_idxs).unsqueeze(1)  # (batch, 1, query_len, char_emb_dim)\n        \n        context_char_emb = self.char_conv(context_char_emb).squeeze()  # (batch, char_emb_dim, context_len)\n        query_char_emb = self.char_conv(query_char_emb).squeeze()  # (batch, char_emb_dim, query_len)\n        \n        context_emb = torch.cat([context_word_emb, context_char_emb], dim=-1)  # (batch, context_len, bert_hidden_size+char_emb_dim)\n        query_emb = torch.cat([query_word_emb, query_char_emb], dim=-1)  # (batch, query_len, bert_hidden_size+char_emb_dim)\n        \n        # Highway network\n        context_emb = self.highway(context_emb)\n        query_emb = self.highway(query_emb)\n        \n        # Contextual embedding layer\n        context_emb, _ = self.context_LSTM(context_emb)  # (batch, context_len, 2*hidden_size)\n        query_emb, _ = self.context_LSTM(query_emb)  # (batch, query_len, 2*hidden_size)\n        \n        # Attention flow layer\n        G = self.att_flow(context_emb, query_emb)  # (batch, context_len, 8*hidden_size)\n        \n        # Modeling layer\n        M, _ = self.modeling_LSTM(G)  # (batch, context_len, 2*hidden_size)\n        \n        # Output layer\n        M2, _ = self.output_LSTM(M)  # (batch, context_len, 2*hidden_size)\n        \n        p1 = self.p1(torch.cat([G, M], dim=-1)).squeeze()  # (batch, context_len)\n        p2 = self.p2(torch.cat([G, M2], dim=-1)).squeeze()  # (batch, context_len)\n        \n        return p1, p2\n\nclass Highway(nn.Module):\n    def __init__(self, input_size, num_layers=2):\n        super(Highway, self).__init__()\n        self.num_layers = num_layers\n        self.linear = nn.ModuleList([nn.Linear(input_size, input_size) for _ in range(num_layers)])\n        self.gate = nn.ModuleList([nn.Linear(input_size, input_size) for _ in range(num_layers)])\n\n    def forward(self, x):\n        for i in range(self.num_layers):\n            gate = torch.sigmoid(self.gate[i](x))\n            non_linear = F.relu(self.linear[i](x))\n            x = gate * non_linear + (1 - gate) * x\n        return x\n\nclass AttentionFlowLayer(nn.Module):\n    def __init__(self, hidden_size):\n        super(AttentionFlowLayer, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.Wc = nn.Linear(2 * hidden_size, 1, bias=False)\n        self.Wq = nn.Linear(2 * hidden_size, 1, bias=False)\n        self.Wcq = nn.Linear(2 * hidden_size, 1, bias=False)\n\n    def forward(self, context, query):\n        batch_size, context_len, _ = context.size()\n        query_len = query.size(1)\n        \n        context = context.unsqueeze(2).expand(-1, -1, query_len, -1)  # (batch, context_len, query_len, hidden_size*2)\n        query = query.unsqueeze(1).expand(-1, context_len, -1, -1)  # (batch, context_len, query_len, hidden_size*2)\n        \n        S = self.Wc(context) + self.Wq(query) + self.Wcq(context * query)  # (batch, context_len, query_len)\n        S = S.squeeze(-1)\n        \n        c2q = torch.bmm(F.softmax(S, dim=-1), query)  # (batch, context_len, hidden_size*2)\n        b = F.softmax(S.max(dim=-1)[0], dim=-1)  # (batch, context_len)\n        q2c = torch.bmm(b.unsqueeze(1), context).squeeze(1).unsqueeze(1).expand(-1, context_len, -1)  # (batch, context_len, hidden_size*2)\n        \n        G = torch.cat([context, c2q, context * c2q, context * q2c], dim=-1)  # (batch, context_len, hidden_size*8)\n        \n        return G\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Initialize the model\nmodel = BiDAF(bert_model_name='bert-base-uncased')\n\n# Move the model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\n# Initialize BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Example context and query\ncontext = \"The quick brown fox jumps over the lazy dog.\"\nquery = \"What does the fox do?\"\n\n# Tokenize the context and query\ncontext_encodings = tokenizer(context, return_tensors='pt', padding=True, truncation=True, max_length=512)\nquery_encodings = tokenizer(query, return_tensors='pt', padding=True, truncation=True, max_length=512)\n\n# Dummy character indices for context and query\n# (In practice, you need to create character indices based on your dataset)\ncontext_char_idxs = torch.randint(0, 94, (1, context_encodings['input_ids'].size(1), 10))\nquery_char_idxs = torch.randint(0, 94, (1, query_encodings['input_ids'].size(1), 10))\n\n# Move inputs to device\ncontext_input_ids = context_encodings['input_ids'].to(device)\ncontext_attention_mask = context_encodings['attention_mask'].to(device)\nquery_input_ids = query_encodings['input_ids'].to(device)\nquery_attention_mask = query_encodings['attention_mask'].to(device)\ncontext_char_idxs = context_char_idxs.to(device)\nquery_char_idxs = query_char_idxs.to(device)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Forward pass\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():\n    p1, p2 = model(context_input_ids, context_attention_mask, query_input_ids, query_attention_mask, context_char_idxs, query_char_idxs)\n\n# p1 and p2 are the start and end logits for the answer span\nprint(p1)\nprint(p2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\nstratify_col = 'decision_encoded'\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=64):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\n# Define the model\nclass BiDAF(nn.Module):\n    def __init__(self, bert_model_name='bert-base-uncased', hidden_size=128, dropout_prob=0.2):\n        super(BiDAF, self).__init__()\n        self.hidden_size = hidden_size\n        self.dropout_prob = dropout_prob\n        \n        # Load pre-trained BERT model\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        bert_hidden_size = self.bert.config.hidden_size\n        \n        # Character embedding\n        self.char_emb = nn.Embedding(num_embeddings=94, embedding_dim=8, padding_idx=0)\n        self.char_conv = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(5, 8))\n        \n        # Highway network\n        self.highway = Highway(input_size=word_vectors.size(1) + 100, num_layers=2)\n        \n        # Contextual embedding layer\n        self.context_LSTM = nn.LSTM(input_size=word_vectors.size(1) + 100, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n        \n        # Attention flow layer\n        self.att_flow = AttentionFlowLayer(hidden_size)\n        \n        # Modeling layer\n        self.modeling_LSTM = nn.LSTM(input_size=hidden_size*8, hidden_size=hidden_size, num_layers=2, batch_first=True, bidirectional=True, dropout=dropout_prob)\n        \n        # Output layer\n        self.output_LSTM = nn.LSTM(input_size=hidden_size*2, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n        self.p1 = nn.Linear(hidden_size*10, 1)\n        self.p2 = nn.Linear(hidden_size*10, 1)\n\n    def forward(self, context_input_ids, context_attention_mask, query_input_ids, query_attention_mask, context_char_idxs, query_char_idxs):\n        # BERT embeddings\n        context_bert_output = self.bert(input_ids=context_input_ids, attention_mask=context_attention_mask)\n        query_bert_output = self.bert(input_ids=query_input_ids, attention_mask=query_attention_mask)\n        \n        context_word_emb = context_bert_output.last_hidden_state  # (batch, context_len, bert_hidden_size)\n        query_word_emb = query_bert_output.last_hidden_state  # (batch, query_len, bert_hidden_size)\n        \n        # Character embedding and convolution\n        context_char_emb = self.char_emb(context_char_idxs).unsqueeze(1)  # (batch, 1, context_len, char_emb_dim)\n        query_char_emb = self.char_emb(query_char_idxs).unsqueeze(1)  # (batch, 1, query_len, char_emb_dim)\n        \n        context_char_emb = self.char_conv(context_char_emb).squeeze()  # (batch, char_emb_dim, context_len)\n        query_char_emb = self.char_conv(query_char_emb).squeeze()  # (batch, char_emb_dim, query_len)\n        \n        context_emb = torch.cat([context_word_emb, context_char_emb], dim=-1)  # (batch, context_len, bert_hidden_size+char_emb_dim)\n        query_emb = torch.cat([query_word_emb, query_char_emb], dim=-1)  # (batch, query_len, bert_hidden_size+char_emb_dim)\n         # Highway network\n        context_emb = self.highway(context_emb)\n        query_emb = self.highway(query_emb)\n        \n        # Contextual embedding layer\n        context_emb, _ = self.context_LSTM(context_emb)  # (batch, context_len, 2*hidden_size)\n        query_emb, _ = self.context_LSTM(query_emb)  # (batch, query_len, 2*hidden_size)\n        \n        # Attention flow layer\n        G = self.att_flow(context_emb, query_emb)  # (batch, context_len, 8*hidden_size)\n        \n        # Modeling layer\n        M, _ = self.modeling_LSTM(G)  # (batch, context_len, 2*hidden_size)\n        \n        # Output layer\n        M2, _ = self.output_LSTM(M)  # (batch, context_len, 2*hidden_size)\n        \n        p1 = self.p1(torch.cat([G, M], dim=-1)).squeeze()  # (batch, context_len)\n        p2 = self.p2(torch.cat([G, M2], dim=-1)).squeeze()  # (batch, context_len)\n        \n        return p1, p2\n\nclass Highway(nn.Module):\n    def __init__(self, input_size, num_layers=2):\n        super(Highway, self).__init__()\n        self.num_layers = num_layers\n        self.linear = nn.ModuleList([nn.Linear(input_size, input_size) for _ in range(num_layers)])\n        self.gate = nn.ModuleList([nn.Linear(input_size, input_size) for _ in range(num_layers)])\n\n    def forward(self, x):\n        for i in range(self.num_layers):\n            gate = torch.sigmoid(self.gate[i](x))\n            non_linear = F.relu(self.linear[i](x))\n            x = gate * non_linear + (1 - gate) * x\n        return x\n\nclass AttentionFlowLayer(nn.Module):\n    def __init__(self, hidden_size):\n        super(AttentionFlowLayer, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.Wc = nn.Linear(2 * hidden_size, 1, bias=False)\n        self.Wq = nn.Linear(2 * hidden_size, 1, bias=False)\n        self.Wcq = nn.Linear(2 * hidden_size, 1, bias=False)\n\n    def forward(self, context, query):\n        batch_size, context_len, _ = context.size()\n        query_len = query.size(1)\n        \n        context = context.unsqueeze(2).expand(-1, -1, query_len, -1)  # (batch, context_len, query_len, hidden_size*2)\n        query = query.unsqueeze(1).expand(-1, context_len, -1, -1)  # (batch, context_len, query_len, hidden_size*2)\n        \n        S = self.Wc(context) + self.Wq(query) + self.Wcq(context * query)  # (batch, context_len, query_len)\n        S = S.squeeze(-1)\n        \n        c2q = torch.bmm(F.softmax(S, dim=-1), query)  # (batch, context_len, hidden_size*2)\n        b = F.softmax(S.max(dim=-1)[0], dim=-1)  # (batch, context_len)\n        q2c = torch.bmm(b.unsqueeze(1), context).squeeze(1).unsqueeze(1).expand(-1, context_len, -1)  # (batch, context_len, hidden_size*2)\n        \n        G = torch.cat([context, c2q, context * c2q, context * q2c], dim=-1)  # (batch, context_len, hidden_size*8)\n        \n        return G\n\nmodel = BiDAF(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Initialize the model\nmodel = BiDAF(bert_model_name='bert-base-uncased')\n\n# Move the model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\nclass QAModel(nn.Module):\n    def __init__(self, model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.model_val = model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.model_val(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\n\nclass TrainandValidate:\n    def __init__(self, model_name, source, df_train,df_val,df_test,stratify_col = 'decision_encoded'):\n        self.name = model_name\n        self.source = source\n        if 'gpt2' in self.name or 'artificial' in self.name:\n            self.batch_size = 16\n        else:\n            self.batch_size = 64\n\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.tokenizer = self.initialize_tokenizer()\n        self.stratify_col = stratify_col\n\n        self.train_inputs, self.train_labels = self.encode_data(df_train)\n        self.validate_inputs, self.validate_labels = self.encode_data(df_val)\n        self.test_inputs, self.test_labels = self.encode_data(df_test)\n\n        self.train_loader = self.create_dataloader(self.train_inputs, self.train_labels)\n        self.validate_loader = self.create_dataloader(self.validate_inputs, self.validate_labels)\n        self.test_loader = self.create_dataloader(self.test_inputs, self.test_labels)\n\n        self.model = self.create_model().to(self.device)  \n        self.optimizer = optim.AdamW(self.model.parameters(), lr=2e-5)\n        self.loss_fn = nn.CrossEntropyLoss()\n\n\n    def initialize_tokenizer(self):\n        if 'gpt2' in self.name:\n            tokenizer = GPT2Tokenizer.from_pretrained(self.source)\n            if tokenizer.pad_token is None:\n                tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n            return tokenizer\n        elif 'BioLinkBERT' in self.name:\n            tokenizer =  AutoTokenizer.from_pretrained(self.source)\n            return tokenizer\n        else:\n            return BertTokenizer.from_pretrained(self.source)\n\n    def encode_data(self,df):\n        inputs=self.tokenizer(\n            text=df['question'], \n            text_pair=df['long_answer'], \n            padding=True, \n            truncation=True, \n            return_tensors='pt', \n            max_length=128*4\n        )\n        labels = torch.tensor(df[self.stratify_col])\n        return inputs, labels\n\n    def create_dataloader(self, inputs, labels):\n        dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n\n    def create_model(self):\n        if 'gpt2' in self.name:\n            model =  GPT2Model.from_pretrained(self.source)\n            model.resize_token_embeddings(len(self.tokenizer))\n            model = QAModel(model)\n        elif 'BioLinkBERT' in self.name:\n            model =  AutoModel.from_pretrained(self.source)\n            model = QAModel(model)\n        else:\n            model = BertModel.from_pretrained(self.source)\n            model = QAModel(model)\n\n        return model\n\n    def calculate_f1_score(self, preds, labels):\n        preds_flat = np.argmax(preds, axis=1).flatten()\n        labels_flat = labels.flatten()\n        return f1_score(labels_flat, preds_flat, average='weighted')\n\n    def evaluate(self, dataloader):\n        self.model.eval()\n        total_loss=0\n        predictions, true_labels = [], []\n    \n        with torch.no_grad():\n            for batch in dataloader:\n                b_input_ids, b_attention_mask, b_labels = [t.to(self.device) for t in batch]  # Move batch to GPU\n                outputs = self.model(b_input_ids, b_attention_mask)\n                logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n                label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n                predictions.extend(np.argmax(logits, axis=1))\n                true_labels.extend(label_ids)\n    \n        accuracy = accuracy_score(true_labels, predictions)\n        precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n        \n    \n        return accuracy, precision, recall, f1\n\n    def training(self, epochs=15):\n        self.model.train()\n        for epoch in range(epochs):\n            total_loss = 0\n            all_preds = []\n            all_labels = []\n        \n            for batch in self.train_loader:\n                b_input_ids, b_attention_mask, b_labels = [t.to(self.device) for t in batch]  # Move batch to GPU\n                self.optimizer.zero_grad()\n            \n                outputs = self.model(b_input_ids, b_attention_mask)\n                loss = self.loss_fn(outputs, b_labels)\n                loss.backward()\n                self.optimizer.step()\n            \n                total_loss += loss.item()\n            \n                # Collect predictions and true labels\n                preds = outputs.detach().cpu().numpy()\n                label_ids = b_labels.to('cpu').numpy()\n            \n                all_preds.append(preds)\n                all_labels.append(label_ids)\n        \n            # Calculate average loss and F1 score for the epoch\n            avg_loss = total_loss / len(self.train_loader)\n            all_preds = np.concatenate(all_preds, axis=0)\n            all_labels = np.concatenate(all_labels, axis=0)\n            avg_f1_score = self.calculate_f1_score(all_preds, all_labels)\n        \n            print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n        \n        \n    def val(self, epochs = 10):\n        val_accuracy, val_precision, val_recall, val_f1 = self.evaluate(self.validate_loader)\n        print(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\n\n        test_accuracy, test_precision, test_recall, test_f1=self.evaluate(self.test_loader)\n        print(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T12:52:39.743559Z","iopub.execute_input":"2024-08-03T12:52:39.744192Z","iopub.status.idle":"2024-08-03T12:52:39.776440Z","shell.execute_reply.started":"2024-08-03T12:52:39.744154Z","shell.execute_reply":"2024-08-03T12:52:39.775437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'BERT-artificial'\nsource = 'bert-base-uncased'\n\ntrainer = TrainandValidate(model_name,source,df_train = pubmedqa_art_train,df_val = pubmedqa_art_val, df_test = pubmedqa_art_test)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:07:08.191337Z","iopub.execute_input":"2024-08-03T13:07:08.191795Z","iopub.status.idle":"2024-08-03T13:07:08.504460Z","shell.execute_reply.started":"2024-08-03T13:07:08.191764Z","shell.execute_reply":"2024-08-03T13:07:08.503160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.training()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T12:52:57.678338Z","iopub.execute_input":"2024-08-03T12:52:57.678913Z","iopub.status.idle":"2024-08-03T12:55:51.905598Z","shell.execute_reply.started":"2024-08-03T12:52:57.678883Z","shell.execute_reply":"2024-08-03T12:55:51.904611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.val()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T12:56:49.677704Z","iopub.execute_input":"2024-08-03T12:56:49.678552Z","iopub.status.idle":"2024-08-03T12:56:50.973385Z","shell.execute_reply.started":"2024-08-03T12:56:49.678507Z","shell.execute_reply":"2024-08-03T12:56:50.972357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\n#model.cpu()\n#del model, checkpoint\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T12:58:10.490995Z","iopub.execute_input":"2024-08-03T12:58:10.491382Z","iopub.status.idle":"2024-08-03T12:58:10.661289Z","shell.execute_reply.started":"2024-08-03T12:58:10.491354Z","shell.execute_reply":"2024-08-03T12:58:10.660162Z"},"trusted":true},"execution_count":null,"outputs":[]}]}