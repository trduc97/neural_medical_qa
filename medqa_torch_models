{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9012001,"sourceType":"datasetVersion","datasetId":5429851},{"sourceId":9062110,"sourceType":"datasetVersion","datasetId":5465014}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/trungcnguyn/deprecated-bert-medqa-torch?scriptVersionId=190365454\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import shutil\nimport os\n\n# Remove the directory if already exist \ndir_name = 'neural_medical_qa'\nif os.path.exists(dir_name):\n    shutil.rmtree(dir_name)\n\n#clone the repo from github\n!git clone https://github.com/trduc97/neural_medical_qa.git\n%cd neural_medical_qa\n# install the requirement\n!pip install -r requirements.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-30T00:29:39.297625Z","iopub.execute_input":"2024-07-30T00:29:39.297939Z","iopub.status.idle":"2024-07-30T00:29:54.756973Z","shell.execute_reply.started":"2024-07-30T00:29:39.297913Z","shell.execute_reply":"2024-07-30T00:29:54.755831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from import_datasets import load_bioasq_pubmedqa,  train_val_test_split\n\nbioasq, pubmedqa = load_bioasq_pubmedqa()\n\n# Display the first few samples of the PubMedQA dataset\nprint(pubmedqa['train'].to_pandas().head())\n\nresponses = pubmedqa['train']['final_decision']\n# Counting the occurrences of each value\nyes_count = responses.count('yes')\nno_count = responses.count('no')\nmaybe_count = responses.count('maybe')\n\n# Display the counts\nprint(f\"Yes: {yes_count}\")\nprint(f\"No: {no_count}\")\nprint(f\"Maybe: {maybe_count}\")\n\npubmedqa_train,pubmedqa_val, pubmedqa_test = train_val_test_split(pubmedqa)\nprint(f\"Train size: {len(pubmedqa_train)}\")\nprint(f\"Validation size: {len(pubmedqa_val)}\")\nprint(f\"Test size: {len(pubmedqa_test)}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T00:29:54.758866Z","iopub.execute_input":"2024-07-30T00:29:54.75919Z","iopub.status.idle":"2024-07-30T00:29:58.266804Z","shell.execute_reply.started":"2024-07-30T00:29:54.759163Z","shell.execute_reply":"2024-07-30T00:29:58.26586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n# Initialize a defaultdict to hold the bucket counts\nlength_buckets = defaultdict(int)\n\n# Define the bucket size\nbucket_size = 128\n\n# Loop through each string in the list\nfor s in pubmedqa_train['long_answer']:\n    # Determine the bucket for the current string length\n    bucket = (len(s) // bucket_size) * bucket_size\n    # Increment the count for the appropriate bucket\n    length_buckets[bucket] += 1\n\n# Display the counts for each bucket\nfor bucket, count in sorted(length_buckets.items()):\n    print(f\"Length {bucket} - {bucket + bucket_size - 1}: {count} strings\")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T00:29:58.268669Z","iopub.execute_input":"2024-07-30T00:29:58.269044Z","iopub.status.idle":"2024-07-30T00:29:58.277195Z","shell.execute_reply.started":"2024-07-30T00:29:58.269011Z","shell.execute_reply":"2024-07-30T00:29:58.276311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bert-base","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\nstratify_col = 'decision_encoded'\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=64):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, bert_model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(bert_model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T00:40:56.460049Z","iopub.status.idle":"2024-07-28T00:40:56.460392Z","shell.execute_reply.started":"2024-07-28T00:40:56.460227Z","shell.execute_reply":"2024-07-28T00:40:56.460241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-28T00:38:41.760027Z","iopub.execute_input":"2024-07-28T00:38:41.760659Z","iopub.status.idle":"2024-07-28T00:38:43.069335Z","shell.execute_reply.started":"2024-07-28T00:38:41.760628Z","shell.execute_reply":"2024-07-28T00:38:43.068151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bert + artificial data","metadata":{}},{"cell_type":"code","source":"bioasq, pubmedqa_artificial = load_bioasq_pubmedqa(pubmed_kaggle_path='/kaggle/input/pubmed-qa/pubmed_qa_pga_artificial.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T00:30:08.859013Z","iopub.execute_input":"2024-07-30T00:30:08.859666Z","iopub.status.idle":"2024-07-30T00:30:59.207732Z","shell.execute_reply.started":"2024-07-30T00:30:08.859634Z","shell.execute_reply":"2024-07-30T00:30:59.206499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict, Dataset\nfrom sklearn.model_selection import train_test_split\n\ndf_artificial=pubmedqa_artificial['train'].to_pandas()\ndf_sample, _=train_test_split(df_artificial, test_size=0.95, random_state=42, stratify=df_artificial['decision_encoded'])   \ndf_sample=df_sample[['pubid', 'question', 'context', 'long_answer', 'final_decision', 'decision_encoded']]\ndata_art=Dataset.from_pandas(df_sample,preserve_index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T00:31:15.66123Z","iopub.execute_input":"2024-07-30T00:31:15.661607Z","iopub.status.idle":"2024-07-30T00:31:18.042858Z","shell.execute_reply.started":"2024-07-30T00:31:15.661576Z","shell.execute_reply":"2024-07-30T00:31:18.041876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert back to datasets\npubmedqa_arti = DatasetDict({'train': data_art})\npubmedqa_art_train,pubmedqa_art_val, pubmedqa_art_test = train_val_test_split(pubmedqa_arti)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T00:31:20.498838Z","iopub.execute_input":"2024-07-30T00:31:20.499214Z","iopub.status.idle":"2024-07-30T00:31:22.174847Z","shell.execute_reply.started":"2024-07-30T00:31:20.499182Z","shell.execute_reply":"2024-07-30T00:31:22.173868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-07-30T00:33:45.986455Z","iopub.execute_input":"2024-07-30T00:33:45.986818Z","iopub.status.idle":"2024-07-30T00:33:46.468409Z","shell.execute_reply.started":"2024-07-30T00:33:45.986791Z","shell.execute_reply":"2024-07-30T00:33:46.467602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\nstratify_col = 'decision_encoded'\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_art_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=16):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, bert_model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(bert_model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T00:33:51.925853Z","iopub.execute_input":"2024-07-30T00:33:51.926223Z","iopub.status.idle":"2024-07-30T01:44:43.441828Z","shell.execute_reply.started":"2024-07-30T00:33:51.926193Z","shell.execute_reply":"2024-07-30T01:44:43.44008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T01:44:43.444041Z","iopub.execute_input":"2024-07-30T01:44:43.444433Z","iopub.status.idle":"2024-07-30T01:44:44.797279Z","shell.execute_reply.started":"2024-07-30T01:44:43.444399Z","shell.execute_reply":"2024-07-30T01:44:44.796324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BioLinkBERT","metadata":{}},{"cell_type":"code","source":"# Clear GPU memory\n\n\ntorch.cuda.empty_cache()\ntorch.cuda.synchronize()\n\n# Reset GPU memory settings\nimport os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'","metadata":{"execution":{"iopub.status.busy":"2024-07-29T23:09:00.939596Z","iopub.execute_input":"2024-07-29T23:09:00.940307Z","iopub.status.idle":"2024-07-29T23:09:00.945131Z","shell.execute_reply.started":"2024-07-29T23:09:00.940275Z","shell.execute_reply":"2024-07-29T23:09:00.944065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"michiyasunaga/BioLinkBERT-base\")\nmodel = AutoModel.from_pretrained(\"michiyasunaga/BioLinkBERT-base\")\nstratify_col = 'decision_encoded'\n\ntokenizer = AutoTokenizer.from_pretrained(\"michiyasunaga/BioLinkBERT-base\")\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=64):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = AutoModel.from_pretrained(\"michiyasunaga/BioLinkBERT-base\")\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, bert_model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(bert_model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T23:17:41.840781Z","iopub.execute_input":"2024-07-29T23:17:41.841165Z","iopub.status.idle":"2024-07-29T23:20:17.516534Z","shell.execute_reply.started":"2024-07-29T23:17:41.841136Z","shell.execute_reply":"2024-07-29T23:20:17.515575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T17:05:27.555745Z","iopub.execute_input":"2024-07-29T17:05:27.55632Z","iopub.status.idle":"2024-07-29T17:05:28.725186Z","shell.execute_reply.started":"2024-07-29T17:05:27.556291Z","shell.execute_reply":"2024-07-29T17:05:28.724243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GPT ","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2Model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2Model.from_pretrained('gpt2')\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-07-29T19:02:08.181958Z","iopub.execute_input":"2024-07-29T19:02:08.182663Z","iopub.status.idle":"2024-07-29T19:02:11.765254Z","shell.execute_reply.started":"2024-07-29T19:02:08.182627Z","shell.execute_reply":"2024-07-29T19:02:11.764375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel,AutoModelForCausalLM\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2Model\n\nimport gc\n\n#model.cpu()\n#del model, checkpoint\ngc.collect()\ntorch.cuda.empty_cache()\n\nstratify_col = 'decision_encoded'\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2Model.from_pretrained('gpt2')\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))\n\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=16):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=5):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T22:50:17.828715Z","iopub.execute_input":"2024-07-29T22:50:17.829159Z","iopub.status.idle":"2024-07-29T22:51:39.209629Z","shell.execute_reply.started":"2024-07-29T22:50:17.829126Z","shell.execute_reply":"2024-07-29T22:51:39.208732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BioGPT ","metadata":{}},{"cell_type":"code","source":"pip install sacremoses","metadata":{"execution":{"iopub.status.busy":"2024-07-29T22:43:57.669055Z","iopub.execute_input":"2024-07-29T22:43:57.669329Z","iopub.status.idle":"2024-07-29T22:44:10.075051Z","shell.execute_reply.started":"2024-07-29T22:43:57.669306Z","shell.execute_reply":"2024-07-29T22:44:10.073921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-07-29T22:45:19.733395Z","iopub.execute_input":"2024-07-29T22:45:19.734245Z","iopub.status.idle":"2024-07-29T22:45:19.741807Z","shell.execute_reply.started":"2024-07-29T22:45:19.73421Z","shell.execute_reply":"2024-07-29T22:45:19.740802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel,AutoModelForCausalLM, GPT2Tokenizer, GPT2Model\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n\n# Load model directly\nfrom transformers import BioGptTokenizer, BioGptForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/biogpt\")\ngpt_model = AutoModelForCausalLM.from_pretrained(\"microsoft/biogpt\", output_hidden_states=True)\n\nstratify_col = 'decision_encoded'\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))\n\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=16):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.hidden_states[-1] # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(gpt_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T22:52:59.973634Z","iopub.execute_input":"2024-07-29T22:52:59.974543Z","iopub.status.idle":"2024-07-29T22:53:03.658615Z","shell.execute_reply.started":"2024-07-29T22:52:59.974509Z","shell.execute_reply":"2024-07-29T22:53:03.657265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numba import cuda\ncuda.select_device(0)\ncuda.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T22:30:04.459129Z","iopub.execute_input":"2024-07-29T22:30:04.459846Z","iopub.status.idle":"2024-07-29T22:30:05.943101Z","shell.execute_reply.started":"2024-07-29T22:30:04.459813Z","shell.execute_reply":"2024-07-29T22:30:05.942267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda.open()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T22:31:16.038449Z","iopub.execute_input":"2024-07-29T22:31:16.039537Z","iopub.status.idle":"2024-07-29T22:31:16.07473Z","shell.execute_reply.started":"2024-07-29T22:31:16.039503Z","shell.execute_reply":"2024-07-29T22:31:16.073634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\nfree_gpu_cache()                           \n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T22:30:12.840977Z","iopub.execute_input":"2024-07-29T22:30:12.841342Z","iopub.status.idle":"2024-07-29T22:30:27.936306Z","shell.execute_reply.started":"2024-07-29T22:30:12.841315Z","shell.execute_reply":"2024-07-29T22:30:27.935137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom numba import cuda\ntorch.cuda.empty_cache()\ncuda.select_device(0)\ncuda.close()\ncuda.select_device(0)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T22:18:25.278161Z","iopub.execute_input":"2024-07-29T22:18:25.27855Z","iopub.status.idle":"2024-07-29T22:18:26.608951Z","shell.execute_reply.started":"2024-07-29T22:18:25.278518Z","shell.execute_reply":"2024-07-29T22:18:26.607958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BiomedNLP","metadata":{}},{"cell_type":"code","source":"# Move the model and tensor to CPU\nmodel.cpu()\n\n# Delete the model and tensor to free up memory\ndel model\n\n# Clear the GPU cache\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T17:06:29.921637Z","iopub.execute_input":"2024-07-29T17:06:29.922527Z","iopub.status.idle":"2024-07-29T17:06:30.867489Z","shell.execute_reply.started":"2024-07-29T17:06:29.922491Z","shell.execute_reply":"2024-07-29T17:06:30.866475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForMaskedLM\n\nbert_model = BertModel.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T17:13:08.751465Z","iopub.execute_input":"2024-07-29T17:13:08.752414Z","iopub.status.idle":"2024-07-29T17:13:09.632017Z","shell.execute_reply.started":"2024-07-29T17:13:08.752375Z","shell.execute_reply":"2024-07-29T17:13:09.631247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\nstratify_col = 'decision_encoded'\n\ntokenizer =  AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\")\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=64):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = BertModel.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\")\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, bert_model, classes=3, dropout_prob=0.5):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.dropout1 = nn.Dropout(dropout_prob)\n        self.linear1 = nn.Linear(bert_model.config.hidden_size, 128)\n        self.dropout2 = nn.Dropout(dropout_prob)\n        self.linear2 = nn.Linear(128, classes)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :] # CLS token\n        cls_output = self.dropout1(cls_output)  # Apply first dropout\n        cls_output = self.linear1(cls_output)  # Apply first linear layer\n        cls_output = self.dropout2(cls_output)  # Apply second dropout\n        logits = self.linear2(cls_output)  # Apply second linear layer\n        return logits\n\nmodel = QAModel(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndef calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T17:15:10.852042Z","iopub.execute_input":"2024-07-29T17:15:10.852954Z","iopub.status.idle":"2024-07-29T17:17:56.447258Z","shell.execute_reply.started":"2024-07-29T17:15:10.852919Z","shell.execute_reply":"2024-07-29T17:17:56.44629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T17:18:33.466559Z","iopub.execute_input":"2024-07-29T17:18:33.46735Z","iopub.status.idle":"2024-07-29T17:18:34.632397Z","shell.execute_reply.started":"2024-07-29T17:18:33.467299Z","shell.execute_reply":"2024-07-29T17:18:34.631436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# BIDAF","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel\n\nclass BiDAF(nn.Module):\n    def __init__(self, bert_model_name='bert-base-uncased', hidden_size=128, dropout_prob=0.2):\n        super(BiDAF, self).__init__()\n        self.hidden_size = hidden_size\n        self.dropout_prob = dropout_prob\n        \n        # Load pre-trained BERT model\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        bert_hidden_size = self.bert.config.hidden_size\n        \n        # Character embedding\n        self.char_emb = nn.Embedding(num_embeddings=94, embedding_dim=8, padding_idx=0)\n        self.char_conv = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(5, 8))\n        \n        # Highway network\n        self.highway = Highway(input_size=bert_hidden_size + 100, num_layers=2)\n        \n        # Contextual embedding layer\n        self.context_LSTM = nn.LSTM(input_size=bert_hidden_size + 100, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n        \n        # Attention flow layer\n        self.att_flow = AttentionFlowLayer(hidden_size)\n        \n        # Modeling layer\n        self.modeling_LSTM = nn.LSTM(input_size=hidden_size*8, hidden_size=hidden_size, num_layers=2, batch_first=True, bidirectional=True, dropout=dropout_prob)\n        \n        # Output layer\n        self.output_LSTM = nn.LSTM(input_size=hidden_size*2, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n        self.p1 = nn.Linear(hidden_size*10, 1)\n        self.p2 = nn.Linear(hidden_size*10, 1)\n\n    def forward(self, context_input_ids, context_attention_mask, query_input_ids, query_attention_mask, context_char_idxs, query_char_idxs):\n        # BERT embeddings\n        context_bert_output = self.bert(input_ids=context_input_ids, attention_mask=context_attention_mask)\n        query_bert_output = self.bert(input_ids=query_input_ids, attention_mask=query_attention_mask)\n        \n        context_word_emb = context_bert_output.last_hidden_state  # (batch, context_len, bert_hidden_size)\n        query_word_emb = query_bert_output.last_hidden_state  # (batch, query_len, bert_hidden_size)\n        \n        # Character embedding and convolution\n        context_char_emb = self.char_emb(context_char_idxs).unsqueeze(1)  # (batch, 1, context_len, char_emb_dim)\n        query_char_emb = self.char_emb(query_char_idxs).unsqueeze(1)  # (batch, 1, query_len, char_emb_dim)\n        \n        context_char_emb = self.char_conv(context_char_emb).squeeze()  # (batch, char_emb_dim, context_len)\n        query_char_emb = self.char_conv(query_char_emb).squeeze()  # (batch, char_emb_dim, query_len)\n        \n        context_emb = torch.cat([context_word_emb, context_char_emb], dim=-1)  # (batch, context_len, bert_hidden_size+char_emb_dim)\n        query_emb = torch.cat([query_word_emb, query_char_emb], dim=-1)  # (batch, query_len, bert_hidden_size+char_emb_dim)\n        \n        # Highway network\n        context_emb = self.highway(context_emb)\n        query_emb = self.highway(query_emb)\n        \n        # Contextual embedding layer\n        context_emb, _ = self.context_LSTM(context_emb)  # (batch, context_len, 2*hidden_size)\n        query_emb, _ = self.context_LSTM(query_emb)  # (batch, query_len, 2*hidden_size)\n        \n        # Attention flow layer\n        G = self.att_flow(context_emb, query_emb)  # (batch, context_len, 8*hidden_size)\n        \n        # Modeling layer\n        M, _ = self.modeling_LSTM(G)  # (batch, context_len, 2*hidden_size)\n        \n        # Output layer\n        M2, _ = self.output_LSTM(M)  # (batch, context_len, 2*hidden_size)\n        \n        p1 = self.p1(torch.cat([G, M], dim=-1)).squeeze()  # (batch, context_len)\n        p2 = self.p2(torch.cat([G, M2], dim=-1)).squeeze()  # (batch, context_len)\n        \n        return p1, p2\n\nclass Highway(nn.Module):\n    def __init__(self, input_size, num_layers=2):\n        super(Highway, self).__init__()\n        self.num_layers = num_layers\n        self.linear = nn.ModuleList([nn.Linear(input_size, input_size) for _ in range(num_layers)])\n        self.gate = nn.ModuleList([nn.Linear(input_size, input_size) for _ in range(num_layers)])\n\n    def forward(self, x):\n        for i in range(self.num_layers):\n            gate = torch.sigmoid(self.gate[i](x))\n            non_linear = F.relu(self.linear[i](x))\n            x = gate * non_linear + (1 - gate) * x\n        return x\n\nclass AttentionFlowLayer(nn.Module):\n    def __init__(self, hidden_size):\n        super(AttentionFlowLayer, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.Wc = nn.Linear(2 * hidden_size, 1, bias=False)\n        self.Wq = nn.Linear(2 * hidden_size, 1, bias=False)\n        self.Wcq = nn.Linear(2 * hidden_size, 1, bias=False)\n\n    def forward(self, context, query):\n        batch_size, context_len, _ = context.size()\n        query_len = query.size(1)\n        \n        context = context.unsqueeze(2).expand(-1, -1, query_len, -1)  # (batch, context_len, query_len, hidden_size*2)\n        query = query.unsqueeze(1).expand(-1, context_len, -1, -1)  # (batch, context_len, query_len, hidden_size*2)\n        \n        S = self.Wc(context) + self.Wq(query) + self.Wcq(context * query)  # (batch, context_len, query_len)\n        S = S.squeeze(-1)\n        \n        c2q = torch.bmm(F.softmax(S, dim=-1), query)  # (batch, context_len, hidden_size*2)\n        b = F.softmax(S.max(dim=-1)[0], dim=-1)  # (batch, context_len)\n        q2c = torch.bmm(b.unsqueeze(1), context).squeeze(1).unsqueeze(1).expand(-1, context_len, -1)  # (batch, context_len, hidden_size*2)\n        \n        G = torch.cat([context, c2q, context * c2q, context * q2c], dim=-1)  # (batch, context_len, hidden_size*8)\n        \n        return G\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T02:15:21.573981Z","iopub.execute_input":"2024-07-27T02:15:21.574945Z","iopub.status.idle":"2024-07-27T02:15:21.604613Z","shell.execute_reply.started":"2024-07-27T02:15:21.574909Z","shell.execute_reply":"2024-07-27T02:15:21.603599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Initialize the model\nmodel = BiDAF(bert_model_name='bert-base-uncased')\n\n# Move the model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T02:17:34.95855Z","iopub.execute_input":"2024-07-27T02:17:34.958968Z","iopub.status.idle":"2024-07-27T02:17:35.458844Z","shell.execute_reply.started":"2024-07-27T02:17:34.958933Z","shell.execute_reply":"2024-07-27T02:17:35.457695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\n# Initialize BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Example context and query\ncontext = \"The quick brown fox jumps over the lazy dog.\"\nquery = \"What does the fox do?\"\n\n# Tokenize the context and query\ncontext_encodings = tokenizer(context, return_tensors='pt', padding=True, truncation=True, max_length=512)\nquery_encodings = tokenizer(query, return_tensors='pt', padding=True, truncation=True, max_length=512)\n\n# Dummy character indices for context and query\n# (In practice, you need to create character indices based on your dataset)\ncontext_char_idxs = torch.randint(0, 94, (1, context_encodings['input_ids'].size(1), 10))\nquery_char_idxs = torch.randint(0, 94, (1, query_encodings['input_ids'].size(1), 10))\n\n# Move inputs to device\ncontext_input_ids = context_encodings['input_ids'].to(device)\ncontext_attention_mask = context_encodings['attention_mask'].to(device)\nquery_input_ids = query_encodings['input_ids'].to(device)\nquery_attention_mask = query_encodings['attention_mask'].to(device)\ncontext_char_idxs = context_char_idxs.to(device)\nquery_char_idxs = query_char_idxs.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T02:17:40.471347Z","iopub.execute_input":"2024-07-27T02:17:40.472188Z","iopub.status.idle":"2024-07-27T02:17:40.574162Z","shell.execute_reply.started":"2024-07-27T02:17:40.472151Z","shell.execute_reply":"2024-07-27T02:17:40.572995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Forward pass\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():\n    p1, p2 = model(context_input_ids, context_attention_mask, query_input_ids, query_attention_mask, context_char_idxs, query_char_idxs)\n\n# p1 and p2 are the start and end logits for the answer span\nprint(p1)\nprint(p2)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T02:17:43.05637Z","iopub.execute_input":"2024-07-27T02:17:43.057497Z","iopub.status.idle":"2024-07-27T02:17:43.665595Z","shell.execute_reply.started":"2024-07-27T02:17:43.057459Z","shell.execute_reply":"2024-07-27T02:17:43.66406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim\nfrom linear_model import QAModel\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nimport torch\n\nstratify_col = 'decision_encoded'\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(pubmedqa_train, tokenizer)\nvalidate_inputs, validate_labels = encode_data(pubmedqa_val, tokenizer)\ntest_inputs, test_labels = encode_data(pubmedqa_test, tokenizer)\n\n# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=64):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)\n\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\n# Define the model\nclass BiDAF(nn.Module):\n    def __init__(self, bert_model_name='bert-base-uncased', hidden_size=128, dropout_prob=0.2):\n        super(BiDAF, self).__init__()\n        self.hidden_size = hidden_size\n        self.dropout_prob = dropout_prob\n        \n        # Load pre-trained BERT model\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        bert_hidden_size = self.bert.config.hidden_size\n        \n        # Character embedding\n        self.char_emb = nn.Embedding(num_embeddings=94, embedding_dim=8, padding_idx=0)\n        self.char_conv = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(5, 8))\n        \n        # Highway network\n        self.highway = Highway(input_size=word_vectors.size(1) + 100, num_layers=2)\n        \n        # Contextual embedding layer\n        self.context_LSTM = nn.LSTM(input_size=word_vectors.size(1) + 100, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n        \n        # Attention flow layer\n        self.att_flow = AttentionFlowLayer(hidden_size)\n        \n        # Modeling layer\n        self.modeling_LSTM = nn.LSTM(input_size=hidden_size*8, hidden_size=hidden_size, num_layers=2, batch_first=True, bidirectional=True, dropout=dropout_prob)\n        \n        # Output layer\n        self.output_LSTM = nn.LSTM(input_size=hidden_size*2, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n        self.p1 = nn.Linear(hidden_size*10, 1)\n        self.p2 = nn.Linear(hidden_size*10, 1)\n\n    def forward(self, context_input_ids, context_attention_mask, query_input_ids, query_attention_mask, context_char_idxs, query_char_idxs):\n        # BERT embeddings\n        context_bert_output = self.bert(input_ids=context_input_ids, attention_mask=context_attention_mask)\n        query_bert_output = self.bert(input_ids=query_input_ids, attention_mask=query_attention_mask)\n        \n        context_word_emb = context_bert_output.last_hidden_state  # (batch, context_len, bert_hidden_size)\n        query_word_emb = query_bert_output.last_hidden_state  # (batch, query_len, bert_hidden_size)\n        \n        # Character embedding and convolution\n        context_char_emb = self.char_emb(context_char_idxs).unsqueeze(1)  # (batch, 1, context_len, char_emb_dim)\n        query_char_emb = self.char_emb(query_char_idxs).unsqueeze(1)  # (batch, 1, query_len, char_emb_dim)\n        \n        context_char_emb = self.char_conv(context_char_emb).squeeze()  # (batch, char_emb_dim, context_len)\n        query_char_emb = self.char_conv(query_char_emb).squeeze()  # (batch, char_emb_dim, query_len)\n        \n        context_emb = torch.cat([context_word_emb, context_char_emb], dim=-1)  # (batch, context_len, bert_hidden_size+char_emb_dim)\n        query_emb = torch.cat([query_word_emb, query_char_emb], dim=-1)  # (batch, query_len, bert_hidden_size+char_emb_dim)\n         # Highway network\n        context_emb = self.highway(context_emb)\n        query_emb = self.highway(query_emb)\n        \n        # Contextual embedding layer\n        context_emb, _ = self.context_LSTM(context_emb)  # (batch, context_len, 2*hidden_size)\n        query_emb, _ = self.context_LSTM(query_emb)  # (batch, query_len, 2*hidden_size)\n        \n        # Attention flow layer\n        G = self.att_flow(context_emb, query_emb)  # (batch, context_len, 8*hidden_size)\n        \n        # Modeling layer\n        M, _ = self.modeling_LSTM(G)  # (batch, context_len, 2*hidden_size)\n        \n        # Output layer\n        M2, _ = self.output_LSTM(M)  # (batch, context_len, 2*hidden_size)\n        \n        p1 = self.p1(torch.cat([G, M], dim=-1)).squeeze()  # (batch, context_len)\n        p2 = self.p2(torch.cat([G, M2], dim=-1)).squeeze()  # (batch, context_len)\n        \n        return p1, p2\n\nclass Highway(nn.Module):\n    def __init__(self, input_size, num_layers=2):\n        super(Highway, self).__init__()\n        self.num_layers = num_layers\n        self.linear = nn.ModuleList([nn.Linear(input_size, input_size) for _ in range(num_layers)])\n        self.gate = nn.ModuleList([nn.Linear(input_size, input_size) for _ in range(num_layers)])\n\n    def forward(self, x):\n        for i in range(self.num_layers):\n            gate = torch.sigmoid(self.gate[i](x))\n            non_linear = F.relu(self.linear[i](x))\n            x = gate * non_linear + (1 - gate) * x\n        return x\n\nclass AttentionFlowLayer(nn.Module):\n    def __init__(self, hidden_size):\n        super(AttentionFlowLayer, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.Wc = nn.Linear(2 * hidden_size, 1, bias=False)\n        self.Wq = nn.Linear(2 * hidden_size, 1, bias=False)\n        self.Wcq = nn.Linear(2 * hidden_size, 1, bias=False)\n\n    def forward(self, context, query):\n        batch_size, context_len, _ = context.size()\n        query_len = query.size(1)\n        \n        context = context.unsqueeze(2).expand(-1, -1, query_len, -1)  # (batch, context_len, query_len, hidden_size*2)\n        query = query.unsqueeze(1).expand(-1, context_len, -1, -1)  # (batch, context_len, query_len, hidden_size*2)\n        \n        S = self.Wc(context) + self.Wq(query) + self.Wcq(context * query)  # (batch, context_len, query_len)\n        S = S.squeeze(-1)\n        \n        c2q = torch.bmm(F.softmax(S, dim=-1), query)  # (batch, context_len, hidden_size*2)\n        b = F.softmax(S.max(dim=-1)[0], dim=-1)  # (batch, context_len)\n        q2c = torch.bmm(b.unsqueeze(1), context).squeeze(1).unsqueeze(1).expand(-1, context_len, -1)  # (batch, context_len, hidden_size*2)\n        \n        G = torch.cat([context, c2q, context * c2q, context * q2c], dim=-1)  # (batch, context_len, hidden_size*8)\n        \n        return G\n\nmodel = BiDAF(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T02:12:36.403271Z","iopub.execute_input":"2024-07-27T02:12:36.403691Z","iopub.status.idle":"2024-07-27T02:12:40.999692Z","shell.execute_reply.started":"2024-07-27T02:12:36.40366Z","shell.execute_reply":"2024-07-27T02:12:40.998073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Initialize the model\nmodel = BiDAF(bert_model_name='bert-base-uncased')\n\n# Move the model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_f1_score(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss=0\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    \n    return accuracy, precision, recall, f1\n# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n        \n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            \n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n            # Collect predictions and true labels\n            preds = outputs.detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n            \n            all_preds.append(preds)\n            all_labels.append(label_ids)\n        \n        # Calculate average loss and F1 score for the epoch\n        avg_loss = total_loss / len(train_loader)\n        all_preds = np.concatenate(all_preds, axis=0)\n        all_labels = np.concatenate(all_labels, axis=0)\n        avg_f1_score = calculate_f1_score(all_preds, all_labels)\n        \n        print(f\"Epoch {epoch+1}, Loss: {avg_loss}, F1 Score: {avg_f1_score}\")\n\n# Assuming `model` and `device` are already defined\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{},"execution_count":null,"outputs":[]}]}