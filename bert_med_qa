{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9012001,"sourceType":"datasetVersion","datasetId":5429851}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. Dataset","metadata":{}},{"cell_type":"code","source":"bioasq_data['questions'][0].keys()","metadata":{"execution":{"iopub.status.busy":"2024-07-22T18:00:41.429319Z","iopub.execute_input":"2024-07-22T18:00:41.429665Z","iopub.status.idle":"2024-07-22T18:00:41.435756Z","shell.execute_reply.started":"2024-07-22T18:00:41.429639Z","shell.execute_reply":"2024-07-22T18:00:41.434824Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"dict_keys(['body', 'documents', 'ideal_answer', 'concepts', 'type', 'id', 'snippets'])"},"metadata":{}}]},{"cell_type":"code","source":"import json\nimport pandas as pd\n\n# Load the JSON file\nwith open('/kaggle/input/bioasq-training-12b/training12b_new.json', 'r') as f:\n    bioasq_data = json.load(f)\n\n# Initialize a list to store yes/no questions\nbioasq_yesno = []\n\n# Iterate through the dataset to extract yes/no questions\nfor question in bioasq_data['questions']:\n    if question['type'] == 'yesno':\n        bioasq_yesno.append({\n            'id': question['id'],\n            'body': question['body'],\n            'exact_answer': question['exact_answer'],\n            'ideal_answer': question['ideal_answer'],\n            'documents': question['documents']\n        })\n\n# Convert the list of yes/no questions to a DataFrame for easier analysis\nbioasq_df = pd.DataFrame(bioasq_yesno)\n\n# Display the DataFrame\nprint(bioasq_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-22T18:32:50.321281Z","iopub.execute_input":"2024-07-22T18:32:50.321732Z","iopub.status.idle":"2024-07-22T18:32:50.710691Z","shell.execute_reply.started":"2024-07-22T18:32:50.321699Z","shell.execute_reply":"2024-07-22T18:32:50.709812Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"                         id                                            body  \\\n0  54e25eaaae9738404b000017                Is the protein Papilin secreted?   \n1  535d292a9a4572de6f000003               Are long non coding RNAs spliced?   \n2  55262a9787ecba3764000009               Is RANKL secreted from the cells?   \n3  51406e6223fec90375000009  Does metformin interfere thyroxine absorption?   \n4  52bf1db603868f1b06000011    Has Denosumab (Prolia) been approved by FDA?   \n\n  exact_answer                                       ideal_answer  \\\n0          yes              [Yes,  papilin is a secreted protein]   \n1          yes  [Long non coding RNAs appear to be spliced thr...   \n2          yes  [Receptor activator of nuclear factor κB ligan...   \n3           no  [No. There are not reported data indicating th...   \n4          yes  [Yes, Denosumab was approved by the FDA in 2010.]   \n\n                                           documents  \n0  [http://www.ncbi.nlm.nih.gov/pubmed/3320045, h...  \n1  [http://www.ncbi.nlm.nih.gov/pubmed/22955988, ...  \n2  [http://www.ncbi.nlm.nih.gov/pubmed/22948539, ...  \n3      [http://www.ncbi.nlm.nih.gov/pubmed/26191653]  \n4  [http://www.ncbi.nlm.nih.gov/pubmed/24126422, ...  \n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the PubMedQA dataset\npubmedqa = load_dataset(\"pubmed_qa\", \"pqa_labeled\")\n\n# Display the dataset information\nprint(pubmedqa)\n\n# Display the first few samples of the PubMedQA dataset\nprint(pubmedqa['train'].to_pandas().head())\n\nresponses = pubmedqa['train']['final_decision']\n# Counting the occurrences of each value\nyes_count = responses.count('yes')\nno_count = responses.count('no')\nmaybe_count = responses.count('maybe')\n\n# Display the counts\nprint(f\"Yes: {yes_count}\")\nprint(f\"No: {no_count}\")\nprint(f\"Maybe: {maybe_count}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-22T18:33:00.482245Z","iopub.execute_input":"2024-07-22T18:33:00.483051Z","iopub.status.idle":"2024-07-22T18:33:12.339883Z","shell.execute_reply.started":"2024-07-22T18:33:00.483018Z","shell.execute_reply":"2024-07-22T18:33:12.338994Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a416da61985b49e799b7955cfc630ab3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"318b72db50c44500a59fc45bae1e7de2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22f3bf8ea97e48e9a2ddcb4f3a1e10c9"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['pubid', 'question', 'context', 'long_answer', 'final_decision'],\n        num_rows: 1000\n    })\n})\n      pubid                                           question  \\\n0  21645374  Do mitochondria play a role in remodelling lac...   \n1  16418930  Landolt C and snellen e acuity: differences in...   \n2   9488747  Syncope during bathing in infants, a pediatric...   \n3  17208539  Are the long-term results of the transanal pul...   \n4  10808977  Can tailored interventions increase mammograph...   \n\n                                             context  \\\n0  {'contexts': ['Programmed cell death (PCD) is ...   \n1  {'contexts': ['Assessment of visual acuity dep...   \n2  {'contexts': ['Apparent life-threatening event...   \n3  {'contexts': ['The transanal endorectal pull-t...   \n4  {'contexts': ['Telephone counseling and tailor...   \n\n                                         long_answer final_decision  \n0  Results depicted mitochondrial dynamics in viv...            yes  \n1  Using the charts described, there was only a s...             no  \n2  \"Aquagenic maladies\" could be a pediatric form...            yes  \n3  Our long-term study showed significantly bette...             no  \n4  The effects of the intervention were most pron...            yes  \nYes: 552\nNo: 338\nMaybe: 110\n","output_type":"stream"}]},{"cell_type":"code","source":"pubmedqa['train']['final_decision'][0:5]\n# Define a custom function to encode labels\ndef encode_labels(example):\n    label_mapping = {'no': 0, 'maybe': 1, 'yes': 2}\n    example['final_decision_encoded'] = label_mapping[example['final_decision']]\n    return example\n\n# Apply the encoding function to the train dataset\npubmedqa = pubmedqa.map(encode_labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:39:16.413705Z","iopub.execute_input":"2024-07-20T23:39:16.414174Z","iopub.status.idle":"2024-07-20T23:39:16.544209Z","shell.execute_reply.started":"2024-07-20T23:39:16.414138Z","shell.execute_reply":"2024-07-20T23:39:16.543393Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9b1032ed38345fd9ae504e9565a451a"}},"metadata":{}}]},{"cell_type":"markdown","source":"# 1. Split the dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import load_dataset,Dataset\nfrom sklearn.model_selection import train_test_split\n\n# Convert train dataset to pandas DataFrame\ndf = pd.DataFrame(pubmedqa['train'])\n\n# Define the stratification column\nstratify_col = 'final_decision_encoded'\n\n# First, split off the test set\ntrain_val_df, test_df = train_test_split(\n    df,\n    test_size=0.2,\n    stratify=df[stratify_col],\n    random_state=42  # Set a random seed for reproducibility\n)\n\n# Then, split the remaining data into train and validation sets\ntrain_df, val_df = train_test_split(\n    train_val_df,\n    test_size=0.125,  # 5% of the original dataset is 10% of the remaining data\n    stratify=train_val_df[stratify_col],\n    random_state=42  # Set a random seed for reproducibility\n)\n\n# Convert DataFrames back to Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\nprint(f\"Train size: {len(train_dataset)}\")\nprint(f\"Validation size: {len(val_dataset)}\")\nprint(f\"Test size: {len(test_dataset)}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:39:24.893145Z","iopub.execute_input":"2024-07-20T23:39:24.893789Z","iopub.status.idle":"2024-07-20T23:39:25.320631Z","shell.execute_reply.started":"2024-07-20T23:39:24.893759Z","shell.execute_reply":"2024-07-20T23:39:25.319721Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Train size: 700\nValidation size: 100\nTest size: 200\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. EDA","metadata":{}},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"markdown","source":"## 3.1. Text representation","metadata":{}},{"cell_type":"markdown","source":"### 3.1.1. TF-IDF","metadata":{}},{"cell_type":"markdown","source":"### 3.1.2. Embedding layer","metadata":{}},{"cell_type":"markdown","source":"### 3.1.3. ELMo ","metadata":{}},{"cell_type":"markdown","source":"### 3.1.4. BERT (base-uncased)","metadata":{}},{"cell_type":"markdown","source":"### 3.1.5. PubMedBert","metadata":{}},{"cell_type":"markdown","source":"## 3.2. Models ","metadata":{}},{"cell_type":"markdown","source":"### 3.2.1. Dense layer ","metadata":{}},{"cell_type":"markdown","source":"# 3.2.2. Match-LSTM","metadata":{}},{"cell_type":"markdown","source":"### 3.2.3. BiDAF","metadata":{}},{"cell_type":"markdown","source":"## A. Elmo","metadata":{}},{"cell_type":"code","source":"pip install tensorflow allennlp pandas","metadata":{"execution":{"iopub.status.busy":"2024-07-21T00:12:52.147537Z","iopub.execute_input":"2024-07-21T00:12:52.148304Z","iopub.status.idle":"2024-07-21T00:16:31.617250Z","shell.execute_reply.started":"2024-07-21T00:12:52.148273Z","shell.execute_reply":"2024-07-21T00:16:31.616042Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nCollecting allennlp\n  Downloading allennlp-2.10.1-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting torch<1.13.0,>=1.10.0 (from allennlp)\n  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\nCollecting torchvision<0.14.0,>=0.8.1 (from allennlp)\n  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\nCollecting cached-path<1.2.0,>=1.1.3 (from allennlp)\n  Downloading cached_path-1.1.6-py3-none-any.whl.metadata (6.0 kB)\nCollecting fairscale==0.4.6 (from allennlp)\n  Downloading fairscale-0.4.6.tar.gz (248 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting nltk>=3.6.5 (from allennlp)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting spacy<3.4,>=2.1.0 (from allennlp)\n  Downloading spacy-3.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\nRequirement already satisfied: tensorboardX>=1.2 in /opt/conda/lib/python3.10/site-packages (from allennlp) (2.6.2.2)\nRequirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.10/site-packages (from allennlp) (2.32.3)\nRequirement already satisfied: tqdm>=4.62 in /opt/conda/lib/python3.10/site-packages (from allennlp) (4.66.4)\nRequirement already satisfied: scikit-learn>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from allennlp) (1.2.2)\nRequirement already satisfied: scipy>=1.7.3 in /opt/conda/lib/python3.10/site-packages (from allennlp) (1.11.4)\nRequirement already satisfied: pytest>=6.2.5 in /opt/conda/lib/python3.10/site-packages (from allennlp) (8.2.2)\nCollecting transformers<4.21,>=4.1 (from allennlp)\n  Downloading transformers-4.20.1-py3-none-any.whl.metadata (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.96 in /opt/conda/lib/python3.10/site-packages (from allennlp) (0.2.0)\nCollecting filelock<3.8,>=3.3 (from allennlp)\n  Downloading filelock-3.7.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting lmdb>=1.2.1 (from allennlp)\n  Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: more-itertools>=8.12.0 in /opt/conda/lib/python3.10/site-packages (from allennlp) (10.2.0)\nCollecting termcolor>=1.1.0 (from tensorflow)\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting wandb<0.13.0,>=0.10.0 (from allennlp)\n  Downloading wandb-0.12.21-py2.py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: huggingface-hub>=0.0.16 in /opt/conda/lib/python3.10/site-packages (from allennlp) (0.23.4)\nRequirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from allennlp) (0.3.8)\nCollecting base58>=2.1.1 (from allennlp)\n  Downloading base58-2.1.1-py3-none-any.whl.metadata (3.1 kB)\nCollecting sacremoses (from allennlp)\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: typer>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from allennlp) (0.12.3)\nRequirement already satisfied: traitlets>5.1.1 in /opt/conda/lib/python3.10/site-packages (from allennlp) (5.9.0)\nCollecting jsonnet>=0.10.0 (from allennlp)\n  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nCollecting rich<13.0,>=12.1 (from cached-path<1.2.0,>=1.1.3->allennlp)\n  Downloading rich-12.6.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: boto3<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (1.26.100)\nRequirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (1.44.0)\nCollecting huggingface-hub>=0.0.16 (from allennlp)\n  Downloading huggingface_hub-0.10.1-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.0.16->allennlp) (6.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>=3.6.5->allennlp) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>=3.6.5->allennlp) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>=3.6.5->allennlp) (2023.12.25)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest>=6.2.5->allennlp) (2.0.0)\nRequirement already satisfied: pluggy<2.0,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest>=6.2.5->allennlp) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest>=6.2.5->allennlp) (1.2.0)\nRequirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest>=6.2.5->allennlp) (2.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->allennlp) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->allennlp) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->allennlp) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->allennlp) (2024.7.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.1->allennlp) (3.2.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.9)\nCollecting thinc<8.1.0,>=8.0.14 (from spacy<3.4,>=2.1.0->allennlp)\n  Downloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.10)\nCollecting wasabi<1.1.0,>=0.9.1 (from spacy<3.4,>=2.1.0->allennlp)\n  Downloading wasabi-0.10.1-py3-none-any.whl.metadata (28 kB)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.10)\nCollecting typer>=0.4.1 (from allennlp)\n  Downloading typer-0.4.2-py3-none-any.whl.metadata (12 kB)\nCollecting pathy>=0.3.5 (from spacy<3.4,>=2.1.0->allennlp)\n  Downloading pathy-0.11.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (6.4.0)\nCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from spacy<3.4,>=2.1.0->allennlp)\n  Downloading pydantic-1.8.2-py3-none-any.whl.metadata (103 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.2)\nCollecting typing-extensions>=3.6.6 (from tensorflow)\n  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.4,>=2.1.0->allennlp) (3.4.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (9.5.0)\nCollecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers<4.21,>=4.1->allennlp)\n  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\nRequirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (3.1.41)\nRequirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.10/site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\nCollecting shortuuid>=0.5.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.8.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (0.4.0)\nCollecting pathtools (from wandb<0.13.0,>=0.10.0->allennlp)\n  Downloading pathtools-0.1.2.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.3.3)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.6.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (4.0.11)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.11.1)\nRequirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.4.1)\nRequirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.7.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.4,>=2.1.0->allennlp) (1.2.0)\nCollecting pathlib-abc==0.1.1 (from pathy>=0.3.5->spacy<3.4,>=2.1.0->allennlp)\n  Downloading pathlib_abc-0.1.1-py3-none-any.whl.metadata (18 kB)\nCollecting commonmark<0.10.0,>=0.9.0 (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp)\n  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp) (5.0.1)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.62.0)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.5.0)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.4,>=2.1.0->allennlp) (1.1.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading base58-2.1.1-py3-none-any.whl (5.6 kB)\nDownloading cached_path-1.1.6-py3-none-any.whl (26 kB)\nDownloading filelock-3.7.1-py3-none-any.whl (10 kB)\nDownloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading spacy-3.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading typer-0.4.2-py3-none-any.whl (27 kB)\nDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nDownloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathy-0.11.0-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\nDownloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rich-12.6.0-py3-none-any.whl (237 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\nDownloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (659 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading wasabi-0.10.1-py3-none-any.whl (26 kB)\nDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fairscale, termcolor, jsonnet, pathtools\n  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307221 sha256=2844dcba0263386d9fe85780232388406adc6f13bbafbf32e2c049d62d57fb07\n  Stored in directory: /root/.cache/pip/wheels/a1/58/3d/e114952ab4a8f31eb9dae230658450afff986b211a5b1f2256\n  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=81be4221f5c6b302fd3d994d8c82df51d1733fbc6ce42e5f163a57a49c26eada\n  Stored in directory: /root/.cache/pip/wheels/a1/49/46/1b13a65d8da11238af9616b00fdde6d45b0f95d9291bac8452\n  Building wheel for jsonnet (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp310-cp310-linux_x86_64.whl size=6604947 sha256=d519d2ffbd91a5455eeb98926ba83bb7b8610b4fa5239c8923d982b20fc91bc8\n  Stored in directory: /root/.cache/pip/wheels/63/0d/6b/5467dd1db9332ba4bd5cf4153e2870c5f89bb4db473d989cc2\n  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8793 sha256=b675768b52df09bb6a114f0f3a27b0a8c2978014d70e93e4d647380cc9d4aba9\n  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\nSuccessfully built fairscale termcolor jsonnet pathtools\nInstalling collected packages: wasabi, tokenizers, termcolor, pathtools, lmdb, jsonnet, commonmark, typing-extensions, typer, shortuuid, sacremoses, rich, pathlib-abc, nltk, keras, filelock, base58, torch, pydantic, pathy, huggingface-hub, botocore, wandb, transformers, torchvision, thinc, fairscale, spacy, cached-path, allennlp\n  Attempting uninstall: wasabi\n    Found existing installation: wasabi 1.1.2\n    Uninstalling wasabi-1.1.2:\n      Successfully uninstalled wasabi-1.1.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: termcolor\n    Found existing installation: termcolor 2.4.0\n    Uninstalling termcolor-2.4.0:\n      Successfully uninstalled termcolor-2.4.0\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.9.0\n    Uninstalling typing_extensions-4.9.0:\n      Successfully uninstalled typing_extensions-4.9.0\n  Attempting uninstall: typer\n    Found existing installation: typer 0.12.3\n    Uninstalling typer-0.12.3:\n      Successfully uninstalled typer-0.12.3\n  Attempting uninstall: rich\n    Found existing installation: rich 13.7.0\n    Uninstalling rich-13.7.0:\n      Successfully uninstalled rich-13.7.0\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n  Attempting uninstall: filelock\n    Found existing installation: filelock 3.13.1\n    Uninstalling filelock-3.13.1:\n      Successfully uninstalled filelock-3.13.1\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.23.4\n    Uninstalling huggingface-hub-0.23.4:\n      Successfully uninstalled huggingface-hub-0.23.4\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.131\n    Uninstalling botocore-1.34.131:\n      Successfully uninstalled botocore-1.34.131\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.17.4\n    Uninstalling wandb-0.17.4:\n      Successfully uninstalled wandb-0.17.4\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.42.3\n    Uninstalling transformers-4.42.3:\n      Successfully uninstalled transformers-4.42.3\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.16.2\n    Uninstalling torchvision-0.16.2:\n      Successfully uninstalled torchvision-0.16.2\n  Attempting uninstall: thinc\n    Found existing installation: thinc 8.2.3\n    Uninstalling thinc-8.2.3:\n      Successfully uninstalled thinc-8.2.3\n  Attempting uninstall: spacy\n    Found existing installation: spacy 3.7.5\n    Uninstalling spacy-3.7.5:\n      Successfully uninstalled spacy-3.7.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nsqlalchemy 2.0.25 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\naiobotocore 2.13.1 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\naiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndatasets 2.20.0 requires huggingface-hub>=0.21.2, but you have huggingface-hub 0.10.1 which is incompatible.\nemoji 2.12.1 requires typing-extensions>=4.7.0, but you have typing-extensions 4.5.0 which is incompatible.\nen-core-web-lg 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.3.3 which is incompatible.\nen-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.3.3 which is incompatible.\nfastapi 0.108.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkaggle-environments 1.14.15 requires transformers>=4.33.1, but you have transformers 4.20.1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\npydantic-core 2.14.6 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\npytorch-lightning 2.3.3 requires torch>=2.0.0, but you have torch 1.12.1 which is incompatible.\nstable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.12.1 which is incompatible.\ntorchdata 0.7.1 requires torch>=2, but you have torch 1.12.1 which is incompatible.\ntypeguard 4.1.5 requires typing-extensions>=4.7.0; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.8.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed allennlp-2.10.1 base58-2.1.1 botocore-1.29.165 cached-path-1.1.6 commonmark-0.9.1 fairscale-0.4.6 filelock-3.7.1 huggingface-hub-0.10.1 jsonnet-0.20.0 keras-2.15.0 lmdb-1.5.1 nltk-3.8.1 pathlib-abc-0.1.1 pathtools-0.1.2 pathy-0.11.0 pydantic-1.8.2 rich-12.6.0 sacremoses-0.1.1 shortuuid-1.0.13 spacy-3.3.3 termcolor-1.1.0 thinc-8.0.17 tokenizers-0.12.1 torch-1.12.1 torchvision-0.13.1 transformers-4.20.1 typer-0.4.2 typing-extensions-4.5.0 wandb-0.12.21 wasabi-0.10.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-07-21T00:18:02.001085Z","iopub.execute_input":"2024-07-21T00:18:02.001518Z","iopub.status.idle":"2024-07-21T00:18:02.043717Z","shell.execute_reply.started":"2024-07-21T00:18:02.001484Z","shell.execute_reply":"2024-07-21T00:18:02.042750Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"        pubid                                           question  \\\n454  25982163  Appendectomy timing: Will delayed surgery incr...   \n690  16266387    Fast foods - are they a risk factor for asthma?   \n171  11970923  Convulsions and retinal haemorrhage: should we...   \n638  19923859  Can T-cell deficiency affect spatial learning ...   \n994  10456814  Does desflurane alter left ventricular functio...   \n..        ...                                                ...   \n481  10798511  Blunt trauma in intoxicated patients: is compu...   \n447  23389866  Chemoradiotherapy in the management of locally...   \n33   26298839  Is Acupuncture Efficacious for Treating Phonot...   \n215  21214884  Can 'high-risk' human papillomaviruses (HPVs) ...   \n391  11759976  Advanced epithelial ovarian carcinoma in Thai ...   \n\n                                               context  \\\n454  {'contexts': ['This study investigated whether...   \n690  {'contexts': ['Lifestyle changes over the last...   \n171  {'contexts': ['The prevalence of retinal haemo...   \n638  {'contexts': ['The present studywas designed t...   \n994  {'contexts': ['Although desflurane is commonly...   \n..                                                 ...   \n481  {'contexts': ['Physical examination to detect ...   \n447  {'contexts': ['The present study aims to evalu...   \n33   {'contexts': ['To investigate the effectivenes...   \n215  {'contexts': ['Using polymerase chain reaction...   \n391  {'contexts': ['To determine survival among pat...   \n\n                                           long_answer final_decision  \\\n454  In our study, it was observed that although lo...             no   \n690  Frequent consumption of hamburgers showed a do...            yes   \n171  Retinal haemorrhages following a convulsive ep...            yes   \n638  These results indicate that T-cell deficiency ...            yes   \n994  This study demonstrates that in patients at ri...             no   \n..                                                 ...            ...   \n481  The incidence of abdominal injury in intoxicat...             no   \n447  The study suggests that there is no difference...             no   \n33   The findings showed that acupuncture of voice-...            yes   \n215  This preliminary case-control study indicates ...             no   \n391  The second-look laparotomy doesn't have a favo...             no   \n\n     final_decision_encoded  \n454                       0  \n690                       2  \n171                       2  \n638                       2  \n994                       0  \n..                      ...  \n481                       0  \n447                       0  \n33                        2  \n215                       0  \n391                       0  \n\n[700 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pubid</th>\n      <th>question</th>\n      <th>context</th>\n      <th>long_answer</th>\n      <th>final_decision</th>\n      <th>final_decision_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>454</th>\n      <td>25982163</td>\n      <td>Appendectomy timing: Will delayed surgery incr...</td>\n      <td>{'contexts': ['This study investigated whether...</td>\n      <td>In our study, it was observed that although lo...</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>690</th>\n      <td>16266387</td>\n      <td>Fast foods - are they a risk factor for asthma?</td>\n      <td>{'contexts': ['Lifestyle changes over the last...</td>\n      <td>Frequent consumption of hamburgers showed a do...</td>\n      <td>yes</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>11970923</td>\n      <td>Convulsions and retinal haemorrhage: should we...</td>\n      <td>{'contexts': ['The prevalence of retinal haemo...</td>\n      <td>Retinal haemorrhages following a convulsive ep...</td>\n      <td>yes</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>638</th>\n      <td>19923859</td>\n      <td>Can T-cell deficiency affect spatial learning ...</td>\n      <td>{'contexts': ['The present studywas designed t...</td>\n      <td>These results indicate that T-cell deficiency ...</td>\n      <td>yes</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>994</th>\n      <td>10456814</td>\n      <td>Does desflurane alter left ventricular functio...</td>\n      <td>{'contexts': ['Although desflurane is commonly...</td>\n      <td>This study demonstrates that in patients at ri...</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>10798511</td>\n      <td>Blunt trauma in intoxicated patients: is compu...</td>\n      <td>{'contexts': ['Physical examination to detect ...</td>\n      <td>The incidence of abdominal injury in intoxicat...</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>447</th>\n      <td>23389866</td>\n      <td>Chemoradiotherapy in the management of locally...</td>\n      <td>{'contexts': ['The present study aims to evalu...</td>\n      <td>The study suggests that there is no difference...</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>26298839</td>\n      <td>Is Acupuncture Efficacious for Treating Phonot...</td>\n      <td>{'contexts': ['To investigate the effectivenes...</td>\n      <td>The findings showed that acupuncture of voice-...</td>\n      <td>yes</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>21214884</td>\n      <td>Can 'high-risk' human papillomaviruses (HPVs) ...</td>\n      <td>{'contexts': ['Using polymerase chain reaction...</td>\n      <td>This preliminary case-control study indicates ...</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>11759976</td>\n      <td>Advanced epithelial ovarian carcinoma in Thai ...</td>\n      <td>{'contexts': ['To determine survival among pat...</td>\n      <td>The second-look laparotomy doesn't have a favo...</td>\n      <td>no</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>700 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## A.2. Embedding the text using elmo ","metadata":{}},{"cell_type":"code","source":"from allennlp.commands.elmo import ElmoEmbedder\n\nelmo = ElmoEmbedder()\n\ndef elmo_embedding(text):\n    return elmo.embed_sentence(text)\n\ntrain_df['Question_Elmo'] = train_df['Question'].apply(elmo_embedding)\n#train_df['Context_Elmo'] = train_df['Context'].apply(elmo_embedding)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T00:19:04.239633Z","iopub.execute_input":"2024-07-21T00:19:04.240601Z","iopub.status.idle":"2024-07-21T00:19:47.438014Z","shell.execute_reply.started":"2024-07-21T00:19:04.240569Z","shell.execute_reply":"2024-07-21T00:19:47.436874Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"2024-07-21 00:19:07.493505: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-21 00:19:07.493614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-21 00:19:07.630151: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs\n  warn(f\"Failed to load image Python extension: {e}\")\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommands\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01melmo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElmoEmbedder\n\u001b[1;32m      3\u001b[0m elmo \u001b[38;5;241m=\u001b[39m ElmoEmbedder()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melmo_embedding\u001b[39m(text):\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp.commands.elmo'"],"ename":"ModuleNotFoundError","evalue":"No module named 'allennlp.commands.elmo'","output_type":"error"}]},{"cell_type":"markdown","source":"# B. BERT ","metadata":{}},{"cell_type":"code","source":"!pip install datasets\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:38:42.170865Z","iopub.execute_input":"2024-07-20T23:38:42.171267Z","iopub.status.idle":"2024-07-20T23:39:07.725714Z","shell.execute_reply.started":"2024-07-20T23:38:42.171236Z","shell.execute_reply":"2024-07-20T23:39:07.724630Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Prepare the dataset for BERT ","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\n# Initialize a defaultdict to hold the bucket counts\nlength_buckets = defaultdict(int)\n\n# Define the bucket size\nbucket_size = 128\n\n# Loop through each string in the list\nfor s in train_dataset['long_answer']:\n    # Determine the bucket for the current string length\n    bucket = (len(s) // bucket_size) * bucket_size\n    # Increment the count for the appropriate bucket\n    length_buckets[bucket] += 1\n\n# Display the counts for each bucket\nfor bucket, count in sorted(length_buckets.items()):\n    print(f\"Length {bucket} - {bucket + bucket_size - 1}: {count} strings\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:39:32.310035Z","iopub.execute_input":"2024-07-20T23:39:32.310623Z","iopub.status.idle":"2024-07-20T23:39:32.319703Z","shell.execute_reply.started":"2024-07-20T23:39:32.310590Z","shell.execute_reply":"2024-07-20T23:39:32.318892Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Length 0 - 127: 63 strings\nLength 128 - 255: 289 strings\nLength 256 - 383: 239 strings\nLength 384 - 511: 81 strings\nLength 512 - 639: 21 strings\nLength 640 - 767: 4 strings\nLength 768 - 895: 3 strings\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndef encode_data(df, tokenizer):\n    inputs=tokenizer(\n        text=df['question'], \n        text_pair=df['long_answer'], \n        padding=True, \n        truncation=True, \n        return_tensors='pt', \n        max_length=128*4\n    )\n    labels = torch.tensor(df[stratify_col])\n    return inputs, labels\n\ntrain_inputs, train_labels = encode_data(train_dataset, tokenizer)\nvalidate_inputs, validate_labels = encode_data(val_dataset, tokenizer)\ntest_inputs, test_labels = encode_data(test_dataset, tokenizer)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:39:34.955309Z","iopub.execute_input":"2024-07-20T23:39:34.956025Z","iopub.status.idle":"2024-07-20T23:39:42.094518Z","shell.execute_reply.started":"2024-07-20T23:39:34.955992Z","shell.execute_reply":"2024-07-20T23:39:42.093540Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46866f0efa7d4fe882dd821860d5c442"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17714ddcb7914617a6fed78eefd6cb0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea538055d294470db86e5c9b3c2794cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"140ff138c75b4d1eb3f954779e7bc9e0"}},"metadata":{}}]},{"cell_type":"code","source":"train_inputs['input_ids'].shape","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:39:42.315623Z","iopub.execute_input":"2024-07-20T23:39:42.316142Z","iopub.status.idle":"2024-07-20T23:39:42.322722Z","shell.execute_reply.started":"2024-07-20T23:39:42.316113Z","shell.execute_reply":"2024-07-20T23:39:42.321866Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.Size([700, 176])"},"metadata":{}}]},{"cell_type":"markdown","source":"# 4. Build and train the model","metadata":{}},{"cell_type":"code","source":"# Create DataLoader\ndef create_dataloader(inputs, labels, batch_size=64):\n    dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Assuming train_inputs, train_labels, validate_inputs, validate_labels, test_inputs, and test_labels are already defined\ntrain_loader = create_dataloader(train_inputs, train_labels)\nvalidate_loader = create_dataloader(validate_inputs, validate_labels)\ntest_loader = create_dataloader(test_inputs, test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:40:03.405438Z","iopub.execute_input":"2024-07-20T23:40:03.405799Z","iopub.status.idle":"2024-07-20T23:40:03.412113Z","shell.execute_reply.started":"2024-07-20T23:40:03.405770Z","shell.execute_reply":"2024-07-20T23:40:03.411154Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import BertModel\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define the model\nclass QAModel(nn.Module):\n    def __init__(self, bert_model):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.linear = nn.Linear(bert_model.config.hidden_size, 3)  # Assuming 3 classes\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        logits = self.linear(cls_output)\n        return logits\n\nbert_model = BertModel.from_pretrained('bert-base-uncased')\nmodel = QAModel(bert_model)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:39:47.067445Z","iopub.execute_input":"2024-07-20T23:39:47.067804Z","iopub.status.idle":"2024-07-20T23:39:49.459597Z","shell.execute_reply.started":"2024-07-20T23:39:47.067776Z","shell.execute_reply":"2024-07-20T23:39:49.458637Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f603b352ecdd47408c7f43ba56f7d16c"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"QAModel(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (linear): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define optimizer and loss function\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()\n\n# Training loop\ndef train(model, train_loader, optimizer, loss_fn, epochs=15):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for batch in train_loader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            optimizer.zero_grad()\n            outputs = model(b_input_ids, b_attention_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n\ntrain(model, train_loader, optimizer, loss_fn)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:42:10.427978Z","iopub.execute_input":"2024-07-20T23:42:10.428337Z","iopub.status.idle":"2024-07-20T23:44:53.199011Z","shell.execute_reply.started":"2024-07-20T23:42:10.428310Z","shell.execute_reply":"2024-07-20T23:44:53.198062Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.5650150071490895\nEpoch 2, Loss: 0.4310607666319067\nEpoch 3, Loss: 0.3237678097053008\nEpoch 4, Loss: 0.2126214937730269\nEpoch 5, Loss: 0.13880649683150378\nEpoch 6, Loss: 0.0920837904241952\nEpoch 7, Loss: 0.0825937966054136\nEpoch 8, Loss: 0.05801608701321212\nEpoch 9, Loss: 0.04964838684959845\nEpoch 10, Loss: 0.043868728998032486\nEpoch 11, Loss: 0.024940957230600445\nEpoch 12, Loss: 0.01875793298875744\nEpoch 13, Loss: 0.011498705018311739\nEpoch 14, Loss: 0.0067034488416869535\nEpoch 15, Loss: 0.005088367520577528\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5 Evaluate the model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport torch\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]  # Move batch to GPU\n            outputs = model(b_input_ids, b_attention_mask)\n            logits = outputs.detach().cpu().numpy()  # Move outputs to CPU before converting to numpy\n            label_ids = b_labels.cpu().numpy()  # Move labels to CPU before converting to numpy\n            predictions.extend(np.argmax(logits, axis=1))\n            true_labels.extend(label_ids)\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n    \n    return accuracy, precision, recall, f1\n\n# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Assuming validate_loader and test_loader are already defined\nval_accuracy, val_precision, val_recall, val_f1 = evaluate(model, validate_loader, device)\ntest_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, device)\n\nprint(f\"Validation - Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}, F1-Score: {val_f1}\")\nprint(f\"Test - Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, F1-Score: {test_f1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T23:44:53.200946Z","iopub.execute_input":"2024-07-20T23:44:53.201617Z","iopub.status.idle":"2024-07-20T23:44:54.752761Z","shell.execute_reply.started":"2024-07-20T23:44:53.201581Z","shell.execute_reply":"2024-07-20T23:44:54.751762Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Validation - Accuracy: 0.64, Precision: 0.6920506454816286, Recall: 0.64, F1-Score: 0.6625818399044207\nTest - Accuracy: 0.74, Precision: 0.7550204017576898, Recall: 0.74, F1-Score: 0.7432791486914008\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# -----------------------------------------------------------------------------------------------------------\n# Testing with the MS Marco v1.1","metadata":{}},{"cell_type":"code","source":"def score(query_embeddings, doc_embeddings):\n    scores = torch.matmul(query_embeddings, doc_embeddings.transpose(2, 1))  # [batch_size, query_len, doc_len]\n    scores, _ = scores.max(dim=2)  # Max over document tokens\n    scores = scores.sum(dim=1)  # Sum over query tokens\n    return scores","metadata":{"execution":{"iopub.status.busy":"2024-07-18T19:33:32.551032Z","iopub.execute_input":"2024-07-18T19:33:32.551393Z","iopub.status.idle":"2024-07-18T19:33:32.557127Z","shell.execute_reply.started":"2024-07-18T19:33:32.551361Z","shell.execute_reply":"2024-07-18T19:33:32.555935Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('ms_marco', 'v1.1')\nds_test = load_dataset('ms_marco', 'v1.1', split='test')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T19:33:32.558773Z","iopub.execute_input":"2024-07-18T19:33:32.559239Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/9.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a05c3ed8a4a8457cbd96d2d64b8b6667"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/21.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11aa240b71ab4219a4a601df518b0829"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/175M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e538985e45f4b82a19842d31bf38043"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34ff3a5e255a4303ae0cfcb5d93c3dd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10047 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"526e8d37c87f4569a88546d4ab9108bc"}},"metadata":{}}]},{"cell_type":"code","source":"ds_test[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model\ncolbert = ColBERT()\n\ndef rerank_passages(query, passages,model):\n    # Tokenize the query\n    query_tokens = tokenize([query])\n        # Forward pass through the model\n    with torch.no_grad():\n        query_embeddings = model(query_tokens['input_ids'], query_tokens['attention_mask'])\n    true_index = passages['is_selected'].index(1)\n    # Tokenize the document\n    scores={}\n    for index, passage in enumerate(passages['passage_text'], start=1):\n        with torch.no_grad():\n            doc_tokens = tokenize([passage])\n            doc_embeddings = model(doc_tokens['input_ids'], doc_tokens['attention_mask'])\n        # Calculate the score\n        similarity_score = score(query_embeddings, doc_embeddings)\n        scores[index] = similarity_score\n        \n    sorted_passage = sorted(scores, key=scores.get, reverse=True)\n    rank = sorted_passage.index(true_index) \n    return 1/rank","metadata":{"execution":{"iopub.status.busy":"2024-07-18T01:41:36.772320Z","iopub.execute_input":"2024-07-18T01:41:36.772715Z","iopub.status.idle":"2024-07-18T01:41:37.155808Z","shell.execute_reply.started":"2024-07-18T01:41:36.772687Z","shell.execute_reply":"2024-07-18T01:41:37.154716Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model\ncolbert = ColBERT()\n\ndef rerank_passages(query, passages, model):\n    # Tokenize the query\n    query_tokens = tokenize([query])\n    # Forward pass through the model\n    with torch.no_grad():\n        query_embeddings = model(query_tokens['input_ids'], query_tokens['attention_mask'])\n        \n    true_index = passages['is_selected'].index(1)\n    \n    # Batch tokenize the passages\n    doc_tokens = tokenize(passages['passage_text'])\n    \n    # Forward pass through the model for all passages\n    with torch.no_grad():\n        doc_embeddings = model(doc_tokens['input_ids'], doc_tokens['attention_mask'])\n        \n    # Calculate scores and store them with their index\n    scores = {}\n    for index, doc_emb in enumerate(doc_embeddings):\n        similarity_score = score(query_embeddings, doc_emb)\n        scores[index + 1] = similarity_score\n    \n    # Sort the scores and find the rank of the true passage\n    sorted_passages = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n    rank = next((i for i, (idx, _) in enumerate(sorted_passages) if idx == true_index), len(sorted_passages))\n    \n    return 1 / (rank + 1)  # Return the reciprocal of the rank (1-based indexing)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T01:43:21.242412Z","iopub.execute_input":"2024-07-18T01:43:21.242833Z","iopub.status.idle":"2024-07-18T01:43:21.624053Z","shell.execute_reply.started":"2024-07-18T01:43:21.242791Z","shell.execute_reply":"2024-07-18T01:43:21.622383Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"sam_query = ds_test['query'][0]\nsam_passages = ds_test['passages'][0]\nmrr_score.append(rerank_passages(sam_query, sam_passages,colbert))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T01:44:28.773175Z","iopub.execute_input":"2024-07-18T01:44:28.774058Z","iopub.status.idle":"2024-07-18T01:44:30.512505Z","shell.execute_reply.started":"2024-07-18T01:44:28.774018Z","shell.execute_reply":"2024-07-18T01:44:30.511102Z"},"trusted":true},"execution_count":88,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[88], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sam_query \u001b[38;5;241m=\u001b[39m ds_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m sam_passages \u001b[38;5;241m=\u001b[39m ds_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m mrr_score\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrerank_passages\u001b[49m\u001b[43m(\u001b[49m\u001b[43msam_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msam_passages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolbert\u001b[49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[86], line 23\u001b[0m, in \u001b[0;36mrerank_passages\u001b[0;34m(query, passages, model)\u001b[0m\n\u001b[1;32m     21\u001b[0m scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, doc_emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(doc_embeddings):\n\u001b[0;32m---> 23\u001b[0m     similarity_score \u001b[38;5;241m=\u001b[39m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     scores[index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m similarity_score\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Sort the scores and find the rank of the true passage\u001b[39;00m\n","Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(query_embeddings, doc_embeddings)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(query_embeddings, doc_embeddings):\n\u001b[0;32m----> 2\u001b[0m     scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(query_embeddings, \u001b[43mdoc_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# [batch_size, query_len, doc_len]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     scores, _ \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Max over document tokens\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Sum over query tokens\u001b[39;00m\n","\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"],"ename":"IndexError","evalue":"Dimension out of range (expected to be in range of [-2, 1], but got 2)","output_type":"error"}]}]}